{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Fine Tuning Training"]},{"cell_type":"markdown","metadata":{},"source":["## Install Coqui TTS"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"execution":{"iopub.execute_input":"2024-06-21T21:07:14.340215Z","iopub.status.busy":"2024-06-21T21:07:14.339963Z","iopub.status.idle":"2024-06-21T21:09:51.689701Z","shell.execute_reply":"2024-06-21T21:09:51.688551Z","shell.execute_reply.started":"2024-06-21T21:07:14.340192Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\n","Collecting pip\n","  Downloading pip-24.1-py3-none-any.whl.metadata (3.6 kB)\n","Downloading pip-24.1-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 23.3.2\n","    Uninstalling pip-23.3.2:\n","      Successfully uninstalled pip-23.3.2\n","Successfully installed pip-24.1\n","Collecting TTS\n","  Downloading TTS-0.22.0-cp310-cp310-manylinux1_x86_64.whl.metadata (21 kB)\n","Requirement already satisfied: cython>=0.29.30 in /opt/conda/lib/python3.10/site-packages (from TTS) (3.0.8)\n","Requirement already satisfied: scipy>=1.11.2 in /opt/conda/lib/python3.10/site-packages (from TTS) (1.11.4)\n","Requirement already satisfied: torch>=2.1 in /opt/conda/lib/python3.10/site-packages (from TTS) (2.1.2)\n","Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from TTS) (2.1.2)\n","Requirement already satisfied: soundfile>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from TTS) (0.12.1)\n","Requirement already satisfied: librosa>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from TTS) (0.10.2.post1)\n","Collecting scikit-learn>=1.3.0 (from TTS)\n","  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Collecting inflect>=5.6.0 (from TTS)\n","  Downloading inflect-7.3.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: tqdm>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from TTS) (4.66.4)\n","Collecting anyascii>=0.3.0 (from TTS)\n","  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: pyyaml>=6.0 in /opt/conda/lib/python3.10/site-packages (from TTS) (6.0.1)\n","Requirement already satisfied: fsspec>=2023.6.0 in /opt/conda/lib/python3.10/site-packages (from TTS) (2024.3.1)\n","Requirement already satisfied: aiohttp>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from TTS) (3.9.1)\n","Collecting packaging>=23.1 (from TTS)\n","  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: flask>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from TTS) (3.0.3)\n","Collecting pysbd>=0.3.4 (from TTS)\n","  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: umap-learn>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from TTS) (0.5.6)\n","Collecting pandas<2.0,>=1.4 (from TTS)\n","  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: matplotlib>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from TTS) (3.7.5)\n","Collecting trainer>=0.0.32 (from TTS)\n","  Downloading trainer-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n","Collecting coqpit>=0.0.16 (from TTS)\n","  Downloading coqpit-0.0.17-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: jieba in /opt/conda/lib/python3.10/site-packages (from TTS) (0.42.1)\n","Collecting pypinyin (from TTS)\n","  Downloading pypinyin-0.51.0-py2.py3-none-any.whl.metadata (12 kB)\n","Collecting hangul-romanize (from TTS)\n","  Downloading hangul_romanize-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n","Collecting gruut==2.2.3 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut-2.2.3.tar.gz (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting jamo (from TTS)\n","  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from TTS) (3.2.4)\n","Collecting g2pkk>=0.1.1 (from TTS)\n","  Downloading g2pkk-0.1.2-py3-none-any.whl.metadata (2.0 kB)\n","Collecting bangla (from TTS)\n","  Downloading bangla-0.0.2-py2.py3-none-any.whl.metadata (4.5 kB)\n","Collecting bnnumerizer (from TTS)\n","  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting bnunicodenormalizer (from TTS)\n","  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n","Collecting einops>=0.6.0 (from TTS)\n","  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: transformers>=4.33.0 in /opt/conda/lib/python3.10/site-packages (from TTS) (4.41.2)\n","Collecting encodec>=0.1.1 (from TTS)\n","  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting unidecode>=1.3.2 (from TTS)\n","  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n","Collecting num2words (from TTS)\n","  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: spacy>=3 in /opt/conda/lib/python3.10/site-packages (from spacy[ja]>=3->TTS) (3.7.3)\n","Collecting numpy==1.22.0 (from TTS)\n","  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n","Requirement already satisfied: numba>=0.57.0 in /opt/conda/lib/python3.10/site-packages (from TTS) (0.58.1)\n","Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.14.0)\n","Collecting dateparser~=1.1.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n","Collecting gruut-ipa<1.0,>=0.12.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting gruut_lang_en~=2.0.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting jsonlines~=1.2.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting networkx<3.0.0,>=2.5.0 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n","Collecting python-crfsuite~=0.9.7 (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.8.1->TTS) (4.0.3)\n","Requirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS) (3.0.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS) (3.1.2)\n","Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS) (8.1.7)\n","Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from flask>=2.0.1->TTS) (1.8.2)\n","Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from inflect>=5.6.0->TTS) (10.2.0)\n","Requirement already satisfied: typeguard>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from inflect>=5.6.0->TTS) (4.1.5)\n","Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (3.0.1)\n","INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n","Collecting librosa>=0.10.0 (from TTS)\n","  Downloading librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n","  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n","  Downloading librosa-0.10.0.post2-py3-none-any.whl.metadata (8.3 kB)\n","  Downloading librosa-0.10.0.post1-py3-none-any.whl.metadata (8.3 kB)\n","  Downloading librosa-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (5.1.1)\n","Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (1.8.1)\n","Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (0.3.7)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (4.9.0)\n","Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (0.3)\n","Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->TTS) (1.0.7)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (4.47.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (9.5.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->TTS) (2.9.0.post0)\n","Requirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from num2words->TTS) (0.6.2)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.57.0->TTS) (0.41.1)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0,>=1.4->TTS) (2023.3.post1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.0->TTS) (3.2.0)\n","Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.0->TTS) (1.16.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (8.2.3)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.9.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (6.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.5.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (69.0.3)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.4.0)\n","Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS)\n","  Downloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting sudachidict-core>=20211220 (from spacy[ja]>=3->TTS)\n","  Downloading SudachiDict_core-20240409-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.1->TTS) (3.13.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.1->TTS) (1.12.1)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from trainer>=0.0.32->TTS) (5.9.3)\n","Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from trainer>=0.0.32->TTS) (2.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.33.0->TTS) (0.23.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.33.0->TTS) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.33.0->TTS) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.33.0->TTS) (0.4.3)\n","Requirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.10/site-packages (from umap-learn>=0.5.1->TTS) (0.5.12)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->TTS) (1.16.0)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.21)\n","Collecting tzlocal (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS)\n","  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask>=2.0.1->TTS) (2.1.3)\n","Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.2.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa>=0.10.0->TTS) (3.11.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (2.14.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2024.2.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS) (0.7.10)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->spacy[ja]>=3->TTS) (0.1.4)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (0.16.0)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.1->TTS) (1.3.0)\n","Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (1.59.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (2.26.1)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (3.5.2)\n","Requirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (3.20.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.32->TTS) (1.3.1)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.1.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->trainer>=0.0.32->TTS) (3.2.2)\n","Downloading TTS-0.22.0-cp310-cp310-manylinux1_x86_64.whl (938 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n","Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n","Downloading inflect-7.3.0-py3-none-any.whl (34 kB)\n","Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading num2words-0.5.13-py3-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading trainer-0.0.36-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n","Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n","Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n","Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n","Downloading pypinyin-0.51.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading SudachiDict_core-20240409-py3-none-any.whl (72.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading tzlocal-5.2-py3-none-any.whl (17 kB)\n","Building wheels for collected packages: gruut, encodec, bnnumerizer, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr\n","  Building wheel for gruut (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75792 sha256=caad20960eaa16001c3dad807f93753dc5ab1ad3704cf52a0fef29004c039a50\n","  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n","  Building wheel for encodec (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=f85237becc8dda795e32c57f146376334bbd0c2c4dc397e718afdbe12a886586\n","  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n","  Building wheel for bnnumerizer (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5259 sha256=8c2cd7955ff9579786295fda90374d9e32dd092a1f9aef5d05af768ab21c0904\n","  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n","  Building wheel for gruut-ipa (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104873 sha256=cd926fdd1d93e9b82c8e2a0964ffcaceb68648e23a57d22e00d29121e6854471\n","  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n","  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498182 sha256=4705712178f042ec47e0e8d5a19d34ffb249d0b5f5822e5353724564ff8189f1\n","  Stored in directory: /root/.cache/pip/wheels/95/9a/05/cfce98f0c41a1a540f15708c4a02df190b82d84cf91ef6bc7f\n","  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297179 sha256=b2cd75fc7fd630d3c5573a0f01c6103cd33f28959d1e807afb41cfc893f61383\n","  Stored in directory: /root/.cache/pip/wheels/10/9c/fb/77c655a9fbd78cdb9935d0ab65d80ddd0a3bcf7dbe18261650\n","  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173797 sha256=57699c88cf913c68dd3c2d09fff5e74dcf33b9d7c213f6a4eeac96fde76fd127\n","  Stored in directory: /root/.cache/pip/wheels/9b/0a/90/788d92c07744b329b9283e37b29b064f5db6b1bb0442a1a19b\n","  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968767 sha256=d1ab41e2527288a2e513adf72c144ebe00c8f2d27a0d30205f92edc3f9fdca9d\n","  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n","Successfully built gruut encodec bnnumerizer gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr\n","Installing collected packages: sudachipy, python-crfsuite, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, bnunicodenormalizer, bnnumerizer, bangla, unidecode, tzlocal, sudachidict-core, pysbd, pypinyin, packaging, numpy, num2words, networkx, jsonlines, gruut-ipa, einops, coqpit, anyascii, pandas, inflect, g2pkk, dateparser, scikit-learn, gruut, librosa, encodec, trainer, TTS\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.2.1\n","    Uninstalling networkx-3.2.1:\n","      Successfully uninstalled networkx-3.2.1\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.1\n","    Uninstalling pandas-2.2.1:\n","      Successfully uninstalled pandas-2.2.1\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","  Attempting uninstall: librosa\n","    Found existing installation: librosa 0.10.2.post1\n","    Uninstalling librosa-0.10.2.post1:\n","      Successfully uninstalled librosa-0.10.2.post1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.4.1 requires cubinlinker, which is not installed.\n","cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.4.1 requires ptxcompiler, which is not installed.\n","cuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","keras-cv 0.9.0 requires keras-core, which is not installed.\n","keras-nlp 0.12.1 requires keras-core, which is not installed.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","albumentations 1.4.0 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\n","arviz 0.18.0 requires numpy<2.0,>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n","astropy 6.1.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n","beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.1 which is incompatible.\n","chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n","cudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n","cudf 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","cudf 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","dask-cuda 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","dask-cudf 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","dask-cudf 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","dask-expr 1.1.2 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n","dipy 1.9.0 requires numpy>=1.22.4, but you have numpy 1.22.0 which is incompatible.\n","distributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n","featuretools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.22.0 which is incompatible.\n","featuretools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n","inequality 1.0.1 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n","jupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","mapclassify 2.6.1 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n","mizani 0.11.4 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n","mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n","momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n","plotnine 0.13.6 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n","plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n","pyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.22.0 which is incompatible.\n","pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","pylibraft 24.4.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n","pylibraft 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","pywavelets 1.5.0 requires numpy<2.0,>=1.22.4, but you have numpy 1.22.0 which is incompatible.\n","raft-dask 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","rapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n","rapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\n","rmm 24.4.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n","rmm 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","spglm 1.1.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n","spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","spreg 1.4.2 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\n","tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.22.0 which is incompatible.\n","tensorstore 0.1.60 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n","ucx-py 0.37.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n","woodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.22.0 which is incompatible.\n","woodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","xarray 2024.5.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n","xarray 2024.5.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed TTS-0.22.0 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.7 coqpit-0.0.17 dateparser-1.1.8 einops-0.8.0 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 gruut_lang_es-2.0.0 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 inflect-7.3.0 jamo-0.4.1 jsonlines-1.2.0 librosa-0.10.0 networkx-2.8.8 num2words-0.5.13 numpy-1.22.0 packaging-24.1 pandas-1.5.3 pypinyin-0.51.0 pysbd-0.3.4 python-crfsuite-0.9.10 scikit-learn-1.5.0 sudachidict-core-20240409 sudachipy-0.6.8 trainer-0.0.36 tzlocal-5.2 unidecode-1.3.8\n","Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\n","Collecting tensorflow\n","  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n","Collecting ml-dtypes~=0.3.1 (from tensorflow)\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.59.3)\n","Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n","  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\n","Collecting numpy<2.0.0,>=1.23.5 (from tensorflow)\n","  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n","Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.0)\n","Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n","Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, tensorboard, ml-dtypes, tensorflow\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.0\n","    Uninstalling numpy-1.22.0:\n","      Successfully uninstalled numpy-1.22.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.1\n","    Uninstalling tensorboard-2.15.1:\n","      Successfully uninstalled tensorboard-2.15.1\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.2.0\n","    Uninstalling ml-dtypes-0.2.0:\n","      Successfully uninstalled ml-dtypes-0.2.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.4.1 requires cubinlinker, which is not installed.\n","cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.4.1 requires ptxcompiler, which is not installed.\n","cuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","keras-nlp 0.12.1 requires keras-core, which is not installed.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","tts 0.22.0 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 1.26.4 which is incompatible.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\n","cudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n","cudf 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","dask-cudf 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","featuretools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n","momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n","plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n","pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","pylibraft 24.4.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n","rmm 24.4.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n","spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","tensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.16.1 which is incompatible.\n","tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.16.1 which is incompatible.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\n","woodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","xarray 2024.5.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed ml-dtypes-0.3.2 numpy-1.26.4 tensorboard-2.16.2 tensorflow-2.16.1\n"]}],"source":["# upgrade pip, install tts, and upgrade tensorflow\n","! pip install -U pip\n","! pip install TTS\n","! pip install -U tensorflow"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":29,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-21T23:03:32.083030Z","iopub.status.busy":"2024-06-21T23:03:32.082612Z","iopub.status.idle":"2024-06-21T23:03:32.089083Z","shell.execute_reply":"2024-06-21T23:03:32.088089Z","shell.execute_reply.started":"2024-06-21T23:03:32.083000Z"},"trusted":true},"outputs":[],"source":["# import the necessary libraries\n","import os\n","import glob\n","import IPython\n","\n","from trainer import Trainer, TrainerArgs\n","\n","from TTS.utils.audio import AudioProcessor\n","from TTS.tts.datasets import load_tts_samples\n","from TTS.tts.configs.vits_config import VitsConfig\n","from TTS.tts.models.vits import Vits, VitsAudioConfig\n","from TTS.tts.utils.text.tokenizer import TTSTokenizer\n","from TTS.tts.configs.shared_configs import BaseDatasetConfig"]},{"cell_type":"markdown","metadata":{},"source":["## Pretrained Model"]},{"cell_type":"code","execution_count":3,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-21T21:09:51.699592Z","iopub.status.busy":"2024-06-21T21:09:51.699177Z","iopub.status.idle":"2024-06-21T21:10:00.634083Z","shell.execute_reply":"2024-06-21T21:10:00.633197Z","shell.execute_reply.started":"2024-06-21T21:09:51.699554Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n","The following NEW packages will be installed:\n","  espeak-ng espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n","0 upgraded, 5 newly installed, 0 to remove and 75 not upgraded.\n","Need to get 4215 kB of archives.\n","After this operation, 12.0 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libpcaudio0 amd64 1.1-4 [7908 B]\n","Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libsonic0 amd64 0.2.0-8 [13.1 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 espeak-ng-data amd64 1.50+dfsg-6 [3682 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libespeak-ng1 amd64 1.50+dfsg-6 [189 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu focal/universe amd64 espeak-ng amd64 1.50+dfsg-6 [322 kB]\n","Fetched 4215 kB in 1s (4677 kB/s)   \n","Selecting previously unselected package libpcaudio0:amd64.\n","(Reading database ... 113807 files and directories currently installed.)\n","Preparing to unpack .../libpcaudio0_1.1-4_amd64.deb ...\n","Unpacking libpcaudio0:amd64 (1.1-4) ...\n","Selecting previously unselected package libsonic0:amd64.\n","Preparing to unpack .../libsonic0_0.2.0-8_amd64.deb ...\n","Unpacking libsonic0:amd64 (0.2.0-8) ...\n","Selecting previously unselected package espeak-ng-data:amd64.\n","Preparing to unpack .../espeak-ng-data_1.50+dfsg-6_amd64.deb ...\n","Unpacking espeak-ng-data:amd64 (1.50+dfsg-6) ...\n","Selecting previously unselected package libespeak-ng1:amd64.\n","Preparing to unpack .../libespeak-ng1_1.50+dfsg-6_amd64.deb ...\n","Unpacking libespeak-ng1:amd64 (1.50+dfsg-6) ...\n","Selecting previously unselected package espeak-ng.\n","Preparing to unpack .../espeak-ng_1.50+dfsg-6_amd64.deb ...\n","Unpacking espeak-ng (1.50+dfsg-6) ...\n","Setting up libpcaudio0:amd64 (1.1-4) ...\n","Setting up libsonic0:amd64 (0.2.0-8) ...\n","Setting up espeak-ng-data:amd64 (1.50+dfsg-6) ...\n","Setting up libespeak-ng1:amd64 (1.50+dfsg-6) ...\n","Setting up espeak-ng (1.50+dfsg-6) ...\n","Processing triggers for man-db (2.9.1-1) ...\n","Processing triggers for libc-bin (2.31-0ubuntu9.14) ...\n"]}],"source":["# install package needed for the tts model to work\n","! sudo apt-get install -y espeak-ng"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-21T21:10:00.636311Z","iopub.status.busy":"2024-06-21T21:10:00.636022Z","iopub.status.idle":"2024-06-21T21:10:29.123515Z","shell.execute_reply":"2024-06-21T21:10:29.122385Z","shell.execute_reply.started":"2024-06-21T21:10:00.636283Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" > Downloading model to /root/.local/share/tts/tts_models--en--vctk--vits\n"," 98%|██████████████████████████████████████ | 144M/148M [00:02<00:00, 53.7MiB/s] > Model's license - apache 2.0\n"," > Check https://choosealicense.com/licenses/apache-2.0/ for more info.\n"," > Using model: vits\n"," > Setting up Audio Processor...\n"," | > sample_rate:22050\n"," | > resample:False\n"," | > num_mels:80\n"," | > log_func:np.log10\n"," | > min_level_db:0\n"," | > frame_shift_ms:None\n"," | > frame_length_ms:None\n"," | > ref_level_db:None\n"," | > fft_size:1024\n"," | > power:None\n"," | > preemphasis:0.0\n"," | > griffin_lim_iters:None\n"," | > signal_norm:None\n"," | > symmetric_norm:None\n"," | > mel_fmin:0\n"," | > mel_fmax:None\n"," | > pitch_fmin:None\n"," | > pitch_fmax:None\n"," | > spec_gain:20.0\n"," | > stft_pad_mode:reflect\n"," | > max_norm:1.0\n"," | > clip_norm:True\n"," | > do_trim_silence:False\n"," | > trim_db:60\n"," | > do_sound_norm:False\n"," | > do_amp_to_db_linear:True\n"," | > do_amp_to_db_mel:True\n"," | > do_rms_norm:False\n"," | > db_level:None\n"," | > stats_path:None\n"," | > base:10\n"," | > hop_length:256\n"," | > win_length:1024\n"," > initialization of speaker-embedding layers.\n"," > Text: Downloading the pretrained model.\n"," > Text splitted to sentences.\n","['Downloading the pretrained model.']\n"," > Processing time: 0.976496696472168\n"," > Real-time factor: 0.41015986279357103\n"," > Saving output to tts_output.wav\n","100%|███████████████████████████████████████| 148M/148M [00:06<00:00, 23.3MiB/s]\n"]}],"source":["# download the pretrained model, using a sample text and defining\n","# a speaker id for the multispeaker model\n","! tts --text \"Downloading the pretrained model.\" \\\n","      --model_name tts_models/en/vctk/vits \\\n","      --speaker_idx p225"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-21T21:44:04.675323Z","iopub.status.busy":"2024-06-21T21:44:04.674450Z","iopub.status.idle":"2024-06-21T21:44:05.653283Z","shell.execute_reply":"2024-06-21T21:44:05.652130Z","shell.execute_reply.started":"2024-06-21T21:44:04.675288Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["config.json  model_file.pth  speaker_ids.json\n"]}],"source":["# list the downloaded model files in the directory\n","! ls /root/.local/share/tts/tts_models--en--vctk--vits"]},{"cell_type":"markdown","metadata":{},"source":["## Load Dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-21T21:44:07.546998Z","iopub.status.busy":"2024-06-21T21:44:07.546609Z","iopub.status.idle":"2024-06-21T21:44:07.552933Z","shell.execute_reply":"2024-06-21T21:44:07.552037Z","shell.execute_reply.started":"2024-06-21T21:44:07.546966Z"},"trusted":true},"outputs":[],"source":["# set output path\n","output_path = \"tts_train_dir\"\n","if not os.path.exists(output_path):\n","    os.makedirs(output_path)\n","\n","# set the dataset configuration\n","# ljspeech dataset was chosen, but only one speaker (002) will be used\n","dataset_config = BaseDatasetConfig(\n","    formatter=\"ljspeech\", meta_file_train=\"/kaggle/input/ljspeech-002/metadata.csv\", path=\"/kaggle/input/ljspeech-002\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Config"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-21T21:44:15.002818Z","iopub.status.busy":"2024-06-21T21:44:15.002113Z","iopub.status.idle":"2024-06-21T21:44:15.014122Z","shell.execute_reply":"2024-06-21T21:44:15.012948Z","shell.execute_reply.started":"2024-06-21T21:44:15.002770Z"},"trusted":true},"outputs":[],"source":["# model architecture and configuration\n","# 50 epochs will be trained with 32 training batch size\n","# learning rate lowered to 0.0001 for fine-tuning\n","audio_config = VitsAudioConfig(\n","    sample_rate=22050,\n","    win_length=1024,\n","    hop_length=256,\n","    num_mels=80,\n","    mel_fmin=0,\n","    mel_fmax=None\n",")\n","\n","config = VitsConfig(\n","    audio=audio_config,\n","    run_name=\"vits_ljspeech_finetune\",\n","    batch_size=32,\n","    eval_batch_size=16,\n","    batch_group_size=5,\n","    num_loader_workers=8,\n","    num_eval_loader_workers=4,\n","    run_eval=True,\n","    test_delay_epochs=-1,\n","    epochs=50,\n","    text_cleaner=\"english_cleaners\",\n","    use_phonemes=True,\n","    phoneme_language=\"en-us\",\n","    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n","    compute_input_seq_cache=True,\n","    print_step=25,\n","    print_eval=True,\n","    mixed_precision=True,\n","    output_path=output_path,\n","    datasets=[dataset_config],\n","    cudnn_benchmark=False,\n","    lr=0.0001\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Audio Processor"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-21T21:44:19.699341Z","iopub.status.busy":"2024-06-21T21:44:19.698676Z","iopub.status.idle":"2024-06-21T21:44:19.708159Z","shell.execute_reply":"2024-06-21T21:44:19.707148Z","shell.execute_reply.started":"2024-06-21T21:44:19.699308Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" > Setting up Audio Processor...\n"," | > sample_rate:22050\n"," | > resample:False\n"," | > num_mels:80\n"," | > log_func:np.log10\n"," | > min_level_db:0\n"," | > frame_shift_ms:None\n"," | > frame_length_ms:None\n"," | > ref_level_db:None\n"," | > fft_size:1024\n"," | > power:None\n"," | > preemphasis:0.0\n"," | > griffin_lim_iters:None\n"," | > signal_norm:None\n"," | > symmetric_norm:None\n"," | > mel_fmin:0\n"," | > mel_fmax:None\n"," | > pitch_fmin:None\n"," | > pitch_fmax:None\n"," | > spec_gain:20.0\n"," | > stft_pad_mode:reflect\n"," | > max_norm:1.0\n"," | > clip_norm:True\n"," | > do_trim_silence:False\n"," | > trim_db:60\n"," | > do_sound_norm:False\n"," | > do_amp_to_db_linear:True\n"," | > do_amp_to_db_mel:True\n"," | > do_rms_norm:False\n"," | > db_level:None\n"," | > stats_path:None\n"," | > base:10\n"," | > hop_length:256\n"," | > win_length:1024\n"]}],"source":["# audio processor for feature extraction and audio input/output\n","ap = AudioProcessor.init_from_config(config)"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenizer"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-21T21:44:22.115532Z","iopub.status.busy":"2024-06-21T21:44:22.114623Z","iopub.status.idle":"2024-06-21T21:44:22.143176Z","shell.execute_reply":"2024-06-21T21:44:22.142413Z","shell.execute_reply.started":"2024-06-21T21:44:22.115498Z"},"trusted":true},"outputs":[],"source":["# tokenizer for converting text to sequences of token ids\n","tokenizer, config = TTSTokenizer.init_from_config(config)"]},{"cell_type":"markdown","metadata":{},"source":["## Load Data Samples"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-21T21:44:24.652218Z","iopub.status.busy":"2024-06-21T21:44:24.651556Z","iopub.status.idle":"2024-06-21T21:44:24.685382Z","shell.execute_reply":"2024-06-21T21:44:24.684575Z","shell.execute_reply.started":"2024-06-21T21:44:24.652187Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" | > Found 337 files in /kaggle/input/ljspeech-002\n"]}],"source":["# load the training and evaluation samples from the dataset\n","# each sample is a list of [text, audio_file_path, speaker_name]\n","train_samples, eval_samples = load_tts_samples(\n","    dataset_config,\n","    eval_split=True,\n","    eval_split_max_size=config.eval_split_max_size,\n","    eval_split_size=config.eval_split_size,\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-21T21:44:26.706274Z","iopub.status.busy":"2024-06-21T21:44:26.705917Z","iopub.status.idle":"2024-06-21T21:44:34.442102Z","shell.execute_reply":"2024-06-21T21:44:34.441128Z","shell.execute_reply.started":"2024-06-21T21:44:26.706246Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["fatal: not a git repository (or any parent up to mount point /kaggle)\n","Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n","fatal: not a git repository (or any parent up to mount point /kaggle)\n","Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"," > Training Environment:\n"," | > Backend: Torch\n"," | > Mixed precision: True\n"," | > Precision: fp16\n"," | > Current device: 0\n"," | > Num. of GPUs: 1\n"," | > Num. of CPUs: 4\n"," | > Num. of Torch Threads: 2\n"," | > Torch seed: 54321\n"," | > Torch CUDNN: True\n"," | > Torch CUDNN deterministic: False\n"," | > Torch CUDNN benchmark: False\n"," | > Torch TF32 MatMul: False\n"," > Start Tensorboard: tensorboard --logdir=tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n"," > Restoring from model_file.pth ...\n"," > Restoring Model...\n"," > Partial model initialization...\n"," | > Layer missing in the model definition: emb_g.weight\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.0.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.0.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.1.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.1.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.2.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.2.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.3.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.3.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.4.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.4.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.5.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.5.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.6.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.6.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.7.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.7.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.8.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.8.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.9.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.9.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.10.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.10.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.11.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.11.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.12.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.12.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.13.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.13.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.14.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.14.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.15.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.in_layers.15.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.0.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.0.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.1.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.1.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.2.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.2.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.3.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.3.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.4.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.4.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.5.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.5.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.6.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.6.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.7.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.7.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.8.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.8.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.9.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.9.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.10.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.10.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.11.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.11.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.12.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.12.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.13.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.13.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.14.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.14.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.15.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.res_skip_layers.15.weight_v\n"," | > Layer missing in the model definition: posterior_encoder.enc.cond_layer.bias\n"," | > Layer missing in the model definition: posterior_encoder.enc.cond_layer.weight_g\n"," | > Layer missing in the model definition: posterior_encoder.enc.cond_layer.weight_v\n"," | > Layer missing in the model definition: flow.flows.0.enc.in_layers.0.weight_g\n"," | > Layer missing in the model definition: flow.flows.0.enc.in_layers.0.weight_v\n"," | > Layer missing in the model definition: flow.flows.0.enc.in_layers.1.weight_g\n"," | > Layer missing in the model definition: flow.flows.0.enc.in_layers.1.weight_v\n"," | > Layer missing in the model definition: flow.flows.0.enc.in_layers.2.weight_g\n"," | > Layer missing in the model definition: flow.flows.0.enc.in_layers.2.weight_v\n"," | > Layer missing in the model definition: flow.flows.0.enc.in_layers.3.weight_g\n"," | > Layer missing in the model definition: flow.flows.0.enc.in_layers.3.weight_v\n"," | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.0.weight_g\n"," | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.0.weight_v\n"," | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.1.weight_g\n"," | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.1.weight_v\n"," | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.2.weight_g\n"," | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.2.weight_v\n"," | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.3.weight_g\n"," | > Layer missing in the model definition: flow.flows.0.enc.res_skip_layers.3.weight_v\n"," | > Layer missing in the model definition: flow.flows.0.enc.cond_layer.bias\n"," | > Layer missing in the model definition: flow.flows.0.enc.cond_layer.weight_g\n"," | > Layer missing in the model definition: flow.flows.0.enc.cond_layer.weight_v\n"," | > Layer missing in the model definition: flow.flows.1.enc.in_layers.0.weight_g\n"," | > Layer missing in the model definition: flow.flows.1.enc.in_layers.0.weight_v\n"," | > Layer missing in the model definition: flow.flows.1.enc.in_layers.1.weight_g\n"," | > Layer missing in the model definition: flow.flows.1.enc.in_layers.1.weight_v\n"," | > Layer missing in the model definition: flow.flows.1.enc.in_layers.2.weight_g\n"," | > Layer missing in the model definition: flow.flows.1.enc.in_layers.2.weight_v\n"," | > Layer missing in the model definition: flow.flows.1.enc.in_layers.3.weight_g\n"," | > Layer missing in the model definition: flow.flows.1.enc.in_layers.3.weight_v\n"," | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.0.weight_g\n"," | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.0.weight_v\n"," | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.1.weight_g\n"," | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.1.weight_v\n"," | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.2.weight_g\n"," | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.2.weight_v\n"," | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.3.weight_g\n"," | > Layer missing in the model definition: flow.flows.1.enc.res_skip_layers.3.weight_v\n"," | > Layer missing in the model definition: flow.flows.1.enc.cond_layer.bias\n"," | > Layer missing in the model definition: flow.flows.1.enc.cond_layer.weight_g\n"," | > Layer missing in the model definition: flow.flows.1.enc.cond_layer.weight_v\n"," | > Layer missing in the model definition: flow.flows.2.enc.in_layers.0.weight_g\n"," | > Layer missing in the model definition: flow.flows.2.enc.in_layers.0.weight_v\n"," | > Layer missing in the model definition: flow.flows.2.enc.in_layers.1.weight_g\n"," | > Layer missing in the model definition: flow.flows.2.enc.in_layers.1.weight_v\n"," | > Layer missing in the model definition: flow.flows.2.enc.in_layers.2.weight_g\n"," | > Layer missing in the model definition: flow.flows.2.enc.in_layers.2.weight_v\n"," | > Layer missing in the model definition: flow.flows.2.enc.in_layers.3.weight_g\n"," | > Layer missing in the model definition: flow.flows.2.enc.in_layers.3.weight_v\n"," | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.0.weight_g\n"," | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.0.weight_v\n"," | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.1.weight_g\n"," | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.1.weight_v\n"," | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.2.weight_g\n"," | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.2.weight_v\n"," | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.3.weight_g\n"," | > Layer missing in the model definition: flow.flows.2.enc.res_skip_layers.3.weight_v\n"," | > Layer missing in the model definition: flow.flows.2.enc.cond_layer.bias\n"," | > Layer missing in the model definition: flow.flows.2.enc.cond_layer.weight_g\n"," | > Layer missing in the model definition: flow.flows.2.enc.cond_layer.weight_v\n"," | > Layer missing in the model definition: flow.flows.3.enc.in_layers.0.weight_g\n"," | > Layer missing in the model definition: flow.flows.3.enc.in_layers.0.weight_v\n"," | > Layer missing in the model definition: flow.flows.3.enc.in_layers.1.weight_g\n"," | > Layer missing in the model definition: flow.flows.3.enc.in_layers.1.weight_v\n"," | > Layer missing in the model definition: flow.flows.3.enc.in_layers.2.weight_g\n"," | > Layer missing in the model definition: flow.flows.3.enc.in_layers.2.weight_v\n"," | > Layer missing in the model definition: flow.flows.3.enc.in_layers.3.weight_g\n"," | > Layer missing in the model definition: flow.flows.3.enc.in_layers.3.weight_v\n"," | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.0.weight_g\n"," | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.0.weight_v\n"," | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.1.weight_g\n"," | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.1.weight_v\n"," | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.2.weight_g\n"," | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.2.weight_v\n"," | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.3.weight_g\n"," | > Layer missing in the model definition: flow.flows.3.enc.res_skip_layers.3.weight_v\n"," | > Layer missing in the model definition: flow.flows.3.enc.cond_layer.bias\n"," | > Layer missing in the model definition: flow.flows.3.enc.cond_layer.weight_g\n"," | > Layer missing in the model definition: flow.flows.3.enc.cond_layer.weight_v\n"," | > Layer missing in the model definition: duration_predictor.cond.weight\n"," | > Layer missing in the model definition: duration_predictor.cond.bias\n"," | > Layer missing in the model definition: waveform_decoder.ups.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.ups.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.ups.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.ups.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.ups.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.ups.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.ups.3.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.ups.3.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs1.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.0.convs2.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs1.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.1.convs2.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs1.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.2.convs2.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs1.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.3.convs2.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs1.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.4.convs2.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs1.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.5.convs2.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs1.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.6.convs2.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs1.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.7.convs2.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs1.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.8.convs2.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs1.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.9.convs2.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs1.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.10.convs2.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs1.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.0.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.0.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.1.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.1.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.2.weight_g\n"," | > Layer missing in the model definition: waveform_decoder.resblocks.11.convs2.2.weight_v\n"," | > Layer missing in the model definition: waveform_decoder.cond_layer.weight\n"," | > Layer missing in the model definition: waveform_decoder.cond_layer.bias\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.4.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.4.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.5.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.5.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.6.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.6.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.7.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.7.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.8.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.8.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.9.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.9.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.10.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.10.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.11.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.11.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.12.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.12.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.13.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.13.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.14.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.14.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.15.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.in_layers.15.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.4.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.4.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.5.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.5.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.6.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.6.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.7.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.7.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.8.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.8.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.9.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.9.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.10.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.10.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.11.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.11.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.12.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.12.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.13.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.13.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.14.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.14.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.15.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: posterior_encoder.enc.res_skip_layers.15.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.in_layers.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.0.enc.res_skip_layers.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.in_layers.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.1.enc.res_skip_layers.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.in_layers.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.2.enc.res_skip_layers.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.in_layers.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: flow.flows.3.enc.res_skip_layers.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.ups.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.ups.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.ups.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.ups.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.ups.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.ups.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.ups.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.ups.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs1.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.0.convs2.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs1.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.1.convs2.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs1.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.2.convs2.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs1.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.3.convs2.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs1.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.4.convs2.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs1.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.5.convs2.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs1.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.6.convs2.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs1.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.7.convs2.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs1.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.8.convs2.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs1.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.9.convs2.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs1.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.10.convs2.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs1.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: waveform_decoder.resblocks.11.convs2.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.0.bias\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.1.bias\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.2.bias\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.3.bias\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.4.bias\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.4.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.4.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.5.bias\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.5.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.0.convs.5.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.0.conv_post.bias\n"," | > Layer missing in the checkpoint: disc.nets.0.conv_post.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.0.conv_post.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.0.bias\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.1.bias\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.2.bias\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.3.bias\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.4.bias\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.4.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.1.convs.4.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.1.conv_post.bias\n"," | > Layer missing in the checkpoint: disc.nets.1.conv_post.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.1.conv_post.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.0.bias\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.1.bias\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.2.bias\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.3.bias\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.4.bias\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.4.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.2.convs.4.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.2.conv_post.bias\n"," | > Layer missing in the checkpoint: disc.nets.2.conv_post.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.2.conv_post.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.0.bias\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.1.bias\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.2.bias\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.3.bias\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.4.bias\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.4.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.3.convs.4.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.3.conv_post.bias\n"," | > Layer missing in the checkpoint: disc.nets.3.conv_post.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.3.conv_post.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.0.bias\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.1.bias\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.2.bias\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.3.bias\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.4.bias\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.4.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.4.convs.4.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.4.conv_post.bias\n"," | > Layer missing in the checkpoint: disc.nets.4.conv_post.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.4.conv_post.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.0.bias\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.0.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.0.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.1.bias\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.1.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.1.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.2.bias\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.2.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.2.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.3.bias\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.3.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.3.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.4.bias\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.4.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.5.convs.4.parametrizations.weight.original1\n"," | > Layer missing in the checkpoint: disc.nets.5.conv_post.bias\n"," | > Layer missing in the checkpoint: disc.nets.5.conv_post.parametrizations.weight.original0\n"," | > Layer missing in the checkpoint: disc.nets.5.conv_post.parametrizations.weight.original1\n"," | > Layer dimention missmatch between model definition and checkpoint: text_encoder.emb.weight\n"," | > 557 / 949 layers are restored.\n"," > Model restored from step 1000000\n","\n"," > Model has 83059180 parameters\n"]}],"source":["# model initialization with configuration, audio processor, tokenizer, and no speaker manager\n","model = Vits(config, ap, tokenizer, speaker_manager=None)\n","\n","# trainer generic api for training the model\n","# here, we also restore the pretrained model and start fine tuning\n","trainer = Trainer(\n","    TrainerArgs(restore_path=\"/root/.local/share/tts/tts_models--en--vctk--vits/model_file.pth\"),\n","    config,\n","    output_path,\n","    model=model,\n","    train_samples=train_samples,\n","    eval_samples=eval_samples,\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-06-21T21:44:55.568854Z","iopub.status.busy":"2024-06-21T21:44:55.568470Z","iopub.status.idle":"2024-06-21T22:15:43.518021Z","shell.execute_reply":"2024-06-21T22:15:43.517198Z","shell.execute_reply.started":"2024-06-21T21:44:55.568820Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","\u001b[4m\u001b[1m > EPOCH: 0/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n"]},{"name":"stdout","output_type":"stream","text":["[*] Pre-computing phonemes...\n"]},{"name":"stderr","output_type":"stream","text":[" 61%|██████    | 203/334 [00:06<00:04, 32.71it/s]"]},{"name":"stdout","output_type":"stream","text":["ðə lˈæɾɚ tˈuː bˌiːɪŋ ˈɔːlsoʊ ɐ pɹˈɪzən fɔːɹ fˈɛlənz ænd vˈeɪɡɹənts ɚɹˈɛstᵻd wɪðˌɪn sˈɜːʔn̩ lˈɪmɪts.,,,,,,,,,,,\n"," [!] Character '̩' not found in the vocabulary. Discarding it.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 334/334 [00:10<00:00, 31.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","> DataLoader initialization\n","| > Tokenizer:\n","\t| > add_blank: True\n","\t| > use_eos_bos: False\n","\t| > use_phonemes: True\n","\t| > phonemizer:\n","\t\t| > phoneme language: en-us\n","\t\t| > phoneme backend: espeak\n","\t| > 1 not found characters:\n","\t| > ̩\n","| > Number of instances : 334\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\n","\u001b[1m > TRAINING (2024-06-21 21:45:07) \u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":[" | > Preprocessing samples\n"," | > Max text length: 179\n"," | > Min text length: 32\n"," | > Avg text length: 107.95808383233533\n"," | \n"," | > Max audio length: 222643.0\n"," | > Min audio length: 33971.0\n"," | > Avg audio length: 146823.3113772455\n"," | > Num. instances discarded samples: 0\n"," | > Batch group size: 160.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/site-packages/torch/functional.py:650: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n","Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/SpectralOps.cpp:863.)\n","  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","> DataLoader initialization\n","| > Tokenizer:\n","\t| > add_blank: True\n","\t| > use_eos_bos: False\n","\t| > use_phonemes: True\n","\t| > phonemizer:\n","\t\t| > phoneme language: en-us\n","\t\t| > phoneme backend: espeak\n","\t| > 1 not found characters:\n","\t| > ̩\n","| > Number of instances : 3\n"," | > Preprocessing samples\n"," | > Max text length: 148\n"," | > Min text length: 85\n"," | > Avg text length: 125.66666666666667\n"," | \n"," | > Max audio length: 208051.0\n"," | > Min audio length: 103603.0\n"," | > Avg audio length: 168029.66666666666\n"," | > Num. instances discarded samples: 0\n"," | > Batch group size: 0.\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 3.1341679096221924  (3.1341679096221924)\n","     | > loss_disc_real_0: 0.33351945877075195  (0.33351945877075195)\n","     | > loss_disc_real_1: 0.285697340965271  (0.285697340965271)\n","     | > loss_disc_real_2: 0.283451646566391  (0.283451646566391)\n","     | > loss_disc_real_3: 0.2941950857639313  (0.2941950857639313)\n","     | > loss_disc_real_4: 0.31735214591026306  (0.31735214591026306)\n","     | > loss_disc_real_5: 0.4365796148777008  (0.4365796148777008)\n","     | > loss_0: 3.1341679096221924  (3.1341679096221924)\n","     | > loss_gen: 1.9558554887771606  (1.9558554887771606)\n","     | > loss_kl: 5.994731426239014  (5.994731426239014)\n","     | > loss_feat: 0.33294597268104553  (0.33294597268104553)\n","     | > loss_mel: 29.92041778564453  (29.92041778564453)\n","     | > loss_duration: 1.348130702972412  (1.348130702972412)\n","     | > loss_1: 39.55208206176758  (39.55208206176758)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/TTS/tts/models/vits.py:1455: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\n","  test_figures[\"{}-alignment\".format(idx)] = plot_alignment(alignment.T, output_fig=False)\n","\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time: 0.3557913303375244 \u001b[0m(+0)\n","     | > avg_loss_disc: 3.1341679096221924 \u001b[0m(+0)\n","     | > avg_loss_disc_real_0: 0.33351945877075195 \u001b[0m(+0)\n","     | > avg_loss_disc_real_1: 0.285697340965271 \u001b[0m(+0)\n","     | > avg_loss_disc_real_2: 0.283451646566391 \u001b[0m(+0)\n","     | > avg_loss_disc_real_3: 0.2941950857639313 \u001b[0m(+0)\n","     | > avg_loss_disc_real_4: 0.31735214591026306 \u001b[0m(+0)\n","     | > avg_loss_disc_real_5: 0.4365796148777008 \u001b[0m(+0)\n","     | > avg_loss_0: 3.1341679096221924 \u001b[0m(+0)\n","     | > avg_loss_gen: 1.9558554887771606 \u001b[0m(+0)\n","     | > avg_loss_kl: 5.994731426239014 \u001b[0m(+0)\n","     | > avg_loss_feat: 0.33294597268104553 \u001b[0m(+0)\n","     | > avg_loss_mel: 29.92041778564453 \u001b[0m(+0)\n","     | > avg_loss_duration: 1.348130702972412 \u001b[0m(+0)\n","     | > avg_loss_1: 39.55208206176758 \u001b[0m(+0)\n","\n"," > BEST MODEL : tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000/best_model_1000012.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 1/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:45:51) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 3.0646491050720215  (3.0646491050720215)\n","     | > loss_disc_real_0: 0.2646934986114502  (0.2646934986114502)\n","     | > loss_disc_real_1: 0.25568097829818726  (0.25568097829818726)\n","     | > loss_disc_real_2: 0.2692498564720154  (0.2692498564720154)\n","     | > loss_disc_real_3: 0.29238051176071167  (0.29238051176071167)\n","     | > loss_disc_real_4: 0.2759823799133301  (0.2759823799133301)\n","     | > loss_disc_real_5: 0.2768558859825134  (0.2768558859825134)\n","     | > loss_0: 3.0646491050720215  (3.0646491050720215)\n","     | > loss_gen: 1.6343883275985718  (1.6343883275985718)\n","     | > loss_kl: 4.5430521965026855  (4.5430521965026855)\n","     | > loss_feat: 0.17291885614395142  (0.17291885614395142)\n","     | > loss_mel: 22.366931915283203  (22.366931915283203)\n","     | > loss_duration: 1.6150779724121094  (1.6150779724121094)\n","     | > loss_1: 30.332368850708008  (30.332368850708008)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.21172809600830078 \u001b[0m(-0.14406323432922363)\n","     | > avg_loss_disc:\u001b[92m 3.0646491050720215 \u001b[0m(-0.0695188045501709)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.2646934986114502 \u001b[0m(-0.06882596015930176)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.25568097829818726 \u001b[0m(-0.03001636266708374)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2692498564720154 \u001b[0m(-0.01420179009437561)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.29238051176071167 \u001b[0m(-0.0018145740032196045)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.2759823799133301 \u001b[0m(-0.04136976599693298)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.2768558859825134 \u001b[0m(-0.15972372889518738)\n","     | > avg_loss_0:\u001b[92m 3.0646491050720215 \u001b[0m(-0.0695188045501709)\n","     | > avg_loss_gen:\u001b[92m 1.6343883275985718 \u001b[0m(-0.32146716117858887)\n","     | > avg_loss_kl:\u001b[92m 4.5430521965026855 \u001b[0m(-1.4516792297363281)\n","     | > avg_loss_feat:\u001b[92m 0.17291885614395142 \u001b[0m(-0.16002711653709412)\n","     | > avg_loss_mel:\u001b[92m 22.366931915283203 \u001b[0m(-7.553485870361328)\n","     | > avg_loss_duration:\u001b[91m 1.6150779724121094 \u001b[0m(+0.26694726943969727)\n","     | > avg_loss_1:\u001b[92m 30.332368850708008 \u001b[0m(-9.21971321105957)\n","\n"," > BEST MODEL : tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000/best_model_1000023.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 2/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:46:30) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 21:46:39 -- STEP: 2/11 -- GLOBAL_STEP: 1000025\u001b[0m\n","     | > loss_disc: 3.056227684020996  (3.0582449436187744)\n","     | > loss_disc_real_0: 0.28391146659851074  (0.2807975560426712)\n","     | > loss_disc_real_1: 0.28161293268203735  (0.27700217068195343)\n","     | > loss_disc_real_2: 0.28100961446762085  (0.28164947032928467)\n","     | > loss_disc_real_3: 0.2829184830188751  (0.28767380118370056)\n","     | > loss_disc_real_4: 0.2919429540634155  (0.29148779809474945)\n","     | > loss_disc_real_5: 0.24591918289661407  (0.24768085777759552)\n","     | > loss_0: 3.056227684020996  (3.0582449436187744)\n","     | > grad_norm_0: tensor(0.7553, device='cuda:0')  (tensor(0.7314, device='cuda:0'))\n","     | > loss_gen: 1.6189136505126953  (1.6436651349067688)\n","     | > loss_kl: 4.253173351287842  (4.30230975151062)\n","     | > loss_feat: 0.30748337507247925  (0.3315485864877701)\n","     | > loss_mel: 23.988548278808594  (23.649361610412598)\n","     | > loss_duration: 1.5255470275878906  (1.5436832904815674)\n","     | > amp_scaler: 1024.0  (1024.0)\n","     | > loss_1: 31.693666458129883  (31.470568656921387)\n","     | > grad_norm_1: tensor(57.8095, device='cuda:0')  (tensor(66.1864, device='cuda:0'))\n","     | > current_lr_0: 0.000199950003125 \n","     | > current_lr_1: 0.000199950003125 \n","     | > step_time: 2.2598  (2.246083378791809)\n","     | > loader_time: 0.0133  (0.013780593872070312)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 3.0226690769195557  (3.0226690769195557)\n","     | > loss_disc_real_0: 0.26199692487716675  (0.26199692487716675)\n","     | > loss_disc_real_1: 0.2587396204471588  (0.2587396204471588)\n","     | > loss_disc_real_2: 0.2629722058773041  (0.2629722058773041)\n","     | > loss_disc_real_3: 0.29289597272872925  (0.29289597272872925)\n","     | > loss_disc_real_4: 0.2729080021381378  (0.2729080021381378)\n","     | > loss_disc_real_5: 0.27279940247535706  (0.27279940247535706)\n","     | > loss_0: 3.0226690769195557  (3.0226690769195557)\n","     | > loss_gen: 1.6313973665237427  (1.6313973665237427)\n","     | > loss_kl: 4.378574371337891  (4.378574371337891)\n","     | > loss_feat: 0.16859479248523712  (0.16859479248523712)\n","     | > loss_mel: 21.850093841552734  (21.850093841552734)\n","     | > loss_duration: 1.6382546424865723  (1.6382546424865723)\n","     | > loss_1: 29.666913986206055  (29.666913986206055)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.21521425247192383 \u001b[0m(+0.003486156463623047)\n","     | > avg_loss_disc:\u001b[92m 3.0226690769195557 \u001b[0m(-0.04198002815246582)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.26199692487716675 \u001b[0m(-0.0026965737342834473)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.2587396204471588 \u001b[0m(+0.0030586421489715576)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2629722058773041 \u001b[0m(-0.006277650594711304)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.29289597272872925 \u001b[0m(+0.0005154609680175781)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.2729080021381378 \u001b[0m(-0.0030743777751922607)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.27279940247535706 \u001b[0m(-0.004056483507156372)\n","     | > avg_loss_0:\u001b[92m 3.0226690769195557 \u001b[0m(-0.04198002815246582)\n","     | > avg_loss_gen:\u001b[92m 1.6313973665237427 \u001b[0m(-0.0029909610748291016)\n","     | > avg_loss_kl:\u001b[92m 4.378574371337891 \u001b[0m(-0.16447782516479492)\n","     | > avg_loss_feat:\u001b[92m 0.16859479248523712 \u001b[0m(-0.004324063658714294)\n","     | > avg_loss_mel:\u001b[92m 21.850093841552734 \u001b[0m(-0.5168380737304688)\n","     | > avg_loss_duration:\u001b[91m 1.6382546424865723 \u001b[0m(+0.02317667007446289)\n","     | > avg_loss_1:\u001b[92m 29.666913986206055 \u001b[0m(-0.6654548645019531)\n","\n"," > BEST MODEL : tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000/best_model_1000034.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 3/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:47:08) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9684340953826904  (2.9684340953826904)\n","     | > loss_disc_real_0: 0.2560758590698242  (0.2560758590698242)\n","     | > loss_disc_real_1: 0.21899335086345673  (0.21899335086345673)\n","     | > loss_disc_real_2: 0.22623716294765472  (0.22623716294765472)\n","     | > loss_disc_real_3: 0.23454473912715912  (0.23454473912715912)\n","     | > loss_disc_real_4: 0.2057403177022934  (0.2057403177022934)\n","     | > loss_disc_real_5: 0.22032111883163452  (0.22032111883163452)\n","     | > loss_0: 2.9684340953826904  (2.9684340953826904)\n","     | > loss_gen: 1.4170348644256592  (1.4170348644256592)\n","     | > loss_kl: 3.888604164123535  (3.888604164123535)\n","     | > loss_feat: 0.5969963073730469  (0.5969963073730469)\n","     | > loss_mel: 23.48583221435547  (23.48583221435547)\n","     | > loss_duration: 1.6462461948394775  (1.6462461948394775)\n","     | > loss_1: 31.034711837768555  (31.034711837768555)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.21616196632385254 \u001b[0m(+0.0009477138519287109)\n","     | > avg_loss_disc:\u001b[92m 2.9684340953826904 \u001b[0m(-0.054234981536865234)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.2560758590698242 \u001b[0m(-0.005921065807342529)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.21899335086345673 \u001b[0m(-0.03974626958370209)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.22623716294765472 \u001b[0m(-0.03673504292964935)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.23454473912715912 \u001b[0m(-0.05835123360157013)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.2057403177022934 \u001b[0m(-0.06716768443584442)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.22032111883163452 \u001b[0m(-0.052478283643722534)\n","     | > avg_loss_0:\u001b[92m 2.9684340953826904 \u001b[0m(-0.054234981536865234)\n","     | > avg_loss_gen:\u001b[92m 1.4170348644256592 \u001b[0m(-0.2143625020980835)\n","     | > avg_loss_kl:\u001b[92m 3.888604164123535 \u001b[0m(-0.48997020721435547)\n","     | > avg_loss_feat:\u001b[91m 0.5969963073730469 \u001b[0m(+0.42840151488780975)\n","     | > avg_loss_mel:\u001b[91m 23.48583221435547 \u001b[0m(+1.6357383728027344)\n","     | > avg_loss_duration:\u001b[91m 1.6462461948394775 \u001b[0m(+0.007991552352905273)\n","     | > avg_loss_1:\u001b[91m 31.034711837768555 \u001b[0m(+1.3677978515625)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 4/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:47:43) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 21:48:00 -- STEP: 5/11 -- GLOBAL_STEP: 1000050\u001b[0m\n","     | > loss_disc: 2.994170665740967  (2.9904372692108154)\n","     | > loss_disc_real_0: 0.2541835904121399  (0.2531597375869751)\n","     | > loss_disc_real_1: 0.27251872420310974  (0.2577587366104126)\n","     | > loss_disc_real_2: 0.2565024197101593  (0.2530395179986954)\n","     | > loss_disc_real_3: 0.2535128593444824  (0.246024888753891)\n","     | > loss_disc_real_4: 0.2730353772640228  (0.25484422147274016)\n","     | > loss_disc_real_5: 0.2636374533176422  (0.25292442739009857)\n","     | > loss_0: 2.994170665740967  (2.9904372692108154)\n","     | > grad_norm_0: tensor(0.6351, device='cuda:0')  (tensor(0.6311, device='cuda:0'))\n","     | > loss_gen: 1.495055913925171  (1.5307932138442992)\n","     | > loss_kl: 3.6357035636901855  (3.6520846366882322)\n","     | > loss_feat: 0.4028322696685791  (0.39372982978820803)\n","     | > loss_mel: 21.64521598815918  (21.984533309936523)\n","     | > loss_duration: 1.6567379236221313  (1.5964152336120605)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 28.835546493530273  (29.15755615234375)\n","     | > grad_norm_1: tensor(56.7294, device='cuda:0')  (tensor(59.2076, device='cuda:0'))\n","     | > current_lr_0: 0.00019990001874843754 \n","     | > current_lr_1: 0.00019990001874843754 \n","     | > step_time: 2.8011  (2.354214096069336)\n","     | > loader_time: 0.0185  (0.014545154571533204)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 3.0118916034698486  (3.0118916034698486)\n","     | > loss_disc_real_0: 0.2535555064678192  (0.2535555064678192)\n","     | > loss_disc_real_1: 0.28053170442581177  (0.28053170442581177)\n","     | > loss_disc_real_2: 0.3080150783061981  (0.3080150783061981)\n","     | > loss_disc_real_3: 0.276613712310791  (0.276613712310791)\n","     | > loss_disc_real_4: 0.2858763337135315  (0.2858763337135315)\n","     | > loss_disc_real_5: 0.2863113284111023  (0.2863113284111023)\n","     | > loss_0: 3.0118916034698486  (3.0118916034698486)\n","     | > loss_gen: 1.7001837491989136  (1.7001837491989136)\n","     | > loss_kl: 3.60066294670105  (3.60066294670105)\n","     | > loss_feat: 0.26017507910728455  (0.26017507910728455)\n","     | > loss_mel: 22.052722930908203  (22.052722930908203)\n","     | > loss_duration: 1.6650960445404053  (1.6650960445404053)\n","     | > loss_1: 29.278841018676758  (29.278841018676758)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.21638989448547363 \u001b[0m(+0.00022792816162109375)\n","     | > avg_loss_disc:\u001b[91m 3.0118916034698486 \u001b[0m(+0.0434575080871582)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.2535555064678192 \u001b[0m(-0.002520352602005005)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.28053170442581177 \u001b[0m(+0.06153835356235504)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.3080150783061981 \u001b[0m(+0.0817779153585434)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.276613712310791 \u001b[0m(+0.0420689731836319)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.2858763337135315 \u001b[0m(+0.0801360160112381)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2863113284111023 \u001b[0m(+0.06599020957946777)\n","     | > avg_loss_0:\u001b[91m 3.0118916034698486 \u001b[0m(+0.0434575080871582)\n","     | > avg_loss_gen:\u001b[91m 1.7001837491989136 \u001b[0m(+0.2831488847732544)\n","     | > avg_loss_kl:\u001b[92m 3.60066294670105 \u001b[0m(-0.28794121742248535)\n","     | > avg_loss_feat:\u001b[92m 0.26017507910728455 \u001b[0m(-0.33682122826576233)\n","     | > avg_loss_mel:\u001b[92m 22.052722930908203 \u001b[0m(-1.4331092834472656)\n","     | > avg_loss_duration:\u001b[91m 1.6650960445404053 \u001b[0m(+0.018849849700927734)\n","     | > avg_loss_1:\u001b[92m 29.278841018676758 \u001b[0m(-1.7558708190917969)\n","\n"," > BEST MODEL : tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000/best_model_1000056.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 5/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:48:22) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.97525691986084  (2.97525691986084)\n","     | > loss_disc_real_0: 0.2437475174665451  (0.2437475174665451)\n","     | > loss_disc_real_1: 0.23066158592700958  (0.23066158592700958)\n","     | > loss_disc_real_2: 0.22285909950733185  (0.22285909950733185)\n","     | > loss_disc_real_3: 0.24568229913711548  (0.24568229913711548)\n","     | > loss_disc_real_4: 0.24052320420742035  (0.24052320420742035)\n","     | > loss_disc_real_5: 0.24347980320453644  (0.24347980320453644)\n","     | > loss_0: 2.97525691986084  (2.97525691986084)\n","     | > loss_gen: 1.4617277383804321  (1.4617277383804321)\n","     | > loss_kl: 3.374586343765259  (3.374586343765259)\n","     | > loss_feat: 0.5355410575866699  (0.5355410575866699)\n","     | > loss_mel: 22.41930389404297  (22.41930389404297)\n","     | > loss_duration: 1.637404203414917  (1.637404203414917)\n","     | > loss_1: 29.42856216430664  (29.42856216430664)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.2218778133392334 \u001b[0m(+0.005487918853759766)\n","     | > avg_loss_disc:\u001b[92m 2.97525691986084 \u001b[0m(-0.03663468360900879)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.2437475174665451 \u001b[0m(-0.009807989001274109)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.23066158592700958 \u001b[0m(-0.049870118498802185)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.22285909950733185 \u001b[0m(-0.08515597879886627)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.24568229913711548 \u001b[0m(-0.030931413173675537)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.24052320420742035 \u001b[0m(-0.045353129506111145)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.24347980320453644 \u001b[0m(-0.04283152520656586)\n","     | > avg_loss_0:\u001b[92m 2.97525691986084 \u001b[0m(-0.03663468360900879)\n","     | > avg_loss_gen:\u001b[92m 1.4617277383804321 \u001b[0m(-0.23845601081848145)\n","     | > avg_loss_kl:\u001b[92m 3.374586343765259 \u001b[0m(-0.22607660293579102)\n","     | > avg_loss_feat:\u001b[91m 0.5355410575866699 \u001b[0m(+0.2753659784793854)\n","     | > avg_loss_mel:\u001b[91m 22.41930389404297 \u001b[0m(+0.3665809631347656)\n","     | > avg_loss_duration:\u001b[92m 1.637404203414917 \u001b[0m(-0.02769184112548828)\n","     | > avg_loss_1:\u001b[91m 29.42856216430664 \u001b[0m(+0.1497211456298828)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 6/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:48:57) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 21:49:22 -- STEP: 8/11 -- GLOBAL_STEP: 1000075\u001b[0m\n","     | > loss_disc: 3.0014383792877197  (2.9866307377815247)\n","     | > loss_disc_real_0: 0.24240100383758545  (0.24896552227437496)\n","     | > loss_disc_real_1: 0.23734226822853088  (0.25218589045107365)\n","     | > loss_disc_real_2: 0.2361384481191635  (0.2515459209680557)\n","     | > loss_disc_real_3: 0.22628043591976166  (0.24861366860568523)\n","     | > loss_disc_real_4: 0.22702835500240326  (0.2488065604120493)\n","     | > loss_disc_real_5: 0.25099122524261475  (0.2520042173564434)\n","     | > loss_0: 3.0014383792877197  (2.9866307377815247)\n","     | > grad_norm_0: tensor(0.8823, device='cuda:0')  (tensor(0.8450, device='cuda:0'))\n","     | > loss_gen: 1.4007258415222168  (1.5183301270008087)\n","     | > loss_kl: 3.227062463760376  (3.287060886621475)\n","     | > loss_feat: 0.36069774627685547  (0.42539288848638535)\n","     | > loss_mel: 20.818885803222656  (21.2455472946167)\n","     | > loss_duration: 1.6763296127319336  (1.6395248770713806)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 27.48370361328125  (28.115856409072876)\n","     | > grad_norm_1: tensor(93.5170, device='cuda:0')  (tensor(67.4622, device='cuda:0'))\n","     | > current_lr_0: 0.0001998500468671882 \n","     | > current_lr_1: 0.0001998500468671882 \n","     | > step_time: 2.7979  (2.516969621181488)\n","     | > loader_time: 0.0203  (0.016109853982925415)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9314370155334473  (2.9314370155334473)\n","     | > loss_disc_real_0: 0.24032287299633026  (0.24032287299633026)\n","     | > loss_disc_real_1: 0.2443883866071701  (0.2443883866071701)\n","     | > loss_disc_real_2: 0.24067510664463043  (0.24067510664463043)\n","     | > loss_disc_real_3: 0.2329247146844864  (0.2329247146844864)\n","     | > loss_disc_real_4: 0.23567159473896027  (0.23567159473896027)\n","     | > loss_disc_real_5: 0.25890183448791504  (0.25890183448791504)\n","     | > loss_0: 2.9314370155334473  (2.9314370155334473)\n","     | > loss_gen: 1.5266138315200806  (1.5266138315200806)\n","     | > loss_kl: 3.3990135192871094  (3.3990135192871094)\n","     | > loss_feat: 0.6357367038726807  (0.6357367038726807)\n","     | > loss_mel: 24.56687355041504  (24.56687355041504)\n","     | > loss_duration: 1.6305925846099854  (1.6305925846099854)\n","     | > loss_1: 31.75882911682129  (31.75882911682129)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.22855448722839355 \u001b[0m(+0.006676673889160156)\n","     | > avg_loss_disc:\u001b[92m 2.9314370155334473 \u001b[0m(-0.04381990432739258)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.24032287299633026 \u001b[0m(-0.0034246444702148438)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.2443883866071701 \u001b[0m(+0.013726800680160522)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.24067510664463043 \u001b[0m(+0.017816007137298584)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.2329247146844864 \u001b[0m(-0.01275758445262909)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.23567159473896027 \u001b[0m(-0.004851609468460083)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.25890183448791504 \u001b[0m(+0.015422031283378601)\n","     | > avg_loss_0:\u001b[92m 2.9314370155334473 \u001b[0m(-0.04381990432739258)\n","     | > avg_loss_gen:\u001b[91m 1.5266138315200806 \u001b[0m(+0.06488609313964844)\n","     | > avg_loss_kl:\u001b[91m 3.3990135192871094 \u001b[0m(+0.024427175521850586)\n","     | > avg_loss_feat:\u001b[91m 0.6357367038726807 \u001b[0m(+0.10019564628601074)\n","     | > avg_loss_mel:\u001b[91m 24.56687355041504 \u001b[0m(+2.1475696563720703)\n","     | > avg_loss_duration:\u001b[92m 1.6305925846099854 \u001b[0m(-0.006811618804931641)\n","     | > avg_loss_1:\u001b[91m 31.75882911682129 \u001b[0m(+2.3302669525146484)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 7/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:49:33) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 3.017777919769287  (3.017777919769287)\n","     | > loss_disc_real_0: 0.20986084640026093  (0.20986084640026093)\n","     | > loss_disc_real_1: 0.2337556779384613  (0.2337556779384613)\n","     | > loss_disc_real_2: 0.2117554396390915  (0.2117554396390915)\n","     | > loss_disc_real_3: 0.1984851062297821  (0.1984851062297821)\n","     | > loss_disc_real_4: 0.181248277425766  (0.181248277425766)\n","     | > loss_disc_real_5: 0.19856178760528564  (0.19856178760528564)\n","     | > loss_0: 3.017777919769287  (3.017777919769287)\n","     | > loss_gen: 1.2676827907562256  (1.2676827907562256)\n","     | > loss_kl: 3.164653778076172  (3.164653778076172)\n","     | > loss_feat: 0.5429477691650391  (0.5429477691650391)\n","     | > loss_mel: 22.022634506225586  (22.022634506225586)\n","     | > loss_duration: 1.6474398374557495  (1.6474398374557495)\n","     | > loss_1: 28.64535903930664  (28.64535903930664)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.2230844497680664 \u001b[0m(-0.0054700374603271484)\n","     | > avg_loss_disc:\u001b[91m 3.017777919769287 \u001b[0m(+0.08634090423583984)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.20986084640026093 \u001b[0m(-0.030462026596069336)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.2337556779384613 \u001b[0m(-0.010632708668708801)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2117554396390915 \u001b[0m(-0.02891966700553894)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.1984851062297821 \u001b[0m(-0.034439608454704285)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.181248277425766 \u001b[0m(-0.054423317313194275)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.19856178760528564 \u001b[0m(-0.060340046882629395)\n","     | > avg_loss_0:\u001b[91m 3.017777919769287 \u001b[0m(+0.08634090423583984)\n","     | > avg_loss_gen:\u001b[92m 1.2676827907562256 \u001b[0m(-0.258931040763855)\n","     | > avg_loss_kl:\u001b[92m 3.164653778076172 \u001b[0m(-0.2343597412109375)\n","     | > avg_loss_feat:\u001b[92m 0.5429477691650391 \u001b[0m(-0.0927889347076416)\n","     | > avg_loss_mel:\u001b[92m 22.022634506225586 \u001b[0m(-2.544239044189453)\n","     | > avg_loss_duration:\u001b[91m 1.6474398374557495 \u001b[0m(+0.01684725284576416)\n","     | > avg_loss_1:\u001b[92m 28.64535903930664 \u001b[0m(-3.1134700775146484)\n","\n"," > BEST MODEL : tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000/best_model_1000089.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 8/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:50:11) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.974846363067627  (2.974846363067627)\n","     | > loss_disc_real_0: 0.24928995966911316  (0.24928995966911316)\n","     | > loss_disc_real_1: 0.24725067615509033  (0.24725067615509033)\n","     | > loss_disc_real_2: 0.26731517910957336  (0.26731517910957336)\n","     | > loss_disc_real_3: 0.2670329213142395  (0.2670329213142395)\n","     | > loss_disc_real_4: 0.23073379695415497  (0.23073379695415497)\n","     | > loss_disc_real_5: 0.2594957649707794  (0.2594957649707794)\n","     | > loss_0: 2.974846363067627  (2.974846363067627)\n","     | > loss_gen: 1.5510566234588623  (1.5510566234588623)\n","     | > loss_kl: 2.5713605880737305  (2.5713605880737305)\n","     | > loss_feat: 0.49663442373275757  (0.49663442373275757)\n","     | > loss_mel: 22.42435073852539  (22.42435073852539)\n","     | > loss_duration: 1.6086575984954834  (1.6086575984954834)\n","     | > loss_1: 28.65205955505371  (28.65205955505371)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.241926908493042 \u001b[0m(+0.018842458724975586)\n","     | > avg_loss_disc:\u001b[92m 2.974846363067627 \u001b[0m(-0.042931556701660156)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.24928995966911316 \u001b[0m(+0.039429113268852234)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.24725067615509033 \u001b[0m(+0.013494998216629028)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.26731517910957336 \u001b[0m(+0.05555973947048187)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.2670329213142395 \u001b[0m(+0.0685478150844574)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.23073379695415497 \u001b[0m(+0.04948551952838898)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2594957649707794 \u001b[0m(+0.060933977365493774)\n","     | > avg_loss_0:\u001b[92m 2.974846363067627 \u001b[0m(-0.042931556701660156)\n","     | > avg_loss_gen:\u001b[91m 1.5510566234588623 \u001b[0m(+0.2833738327026367)\n","     | > avg_loss_kl:\u001b[92m 2.5713605880737305 \u001b[0m(-0.5932931900024414)\n","     | > avg_loss_feat:\u001b[92m 0.49663442373275757 \u001b[0m(-0.046313345432281494)\n","     | > avg_loss_mel:\u001b[91m 22.42435073852539 \u001b[0m(+0.4017162322998047)\n","     | > avg_loss_duration:\u001b[92m 1.6086575984954834 \u001b[0m(-0.03878223896026611)\n","     | > avg_loss_1:\u001b[91m 28.65205955505371 \u001b[0m(+0.0067005157470703125)\n","\n"," > BEST MODEL : tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000/best_model_1000100.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 9/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:50:50) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 21:50:54 -- STEP: 0/11 -- GLOBAL_STEP: 1000100\u001b[0m\n","     | > loss_disc: 3.002713203430176  (3.002713203430176)\n","     | > loss_disc_real_0: 0.25294363498687744  (0.25294363498687744)\n","     | > loss_disc_real_1: 0.24940891563892365  (0.24940891563892365)\n","     | > loss_disc_real_2: 0.2680346965789795  (0.2680346965789795)\n","     | > loss_disc_real_3: 0.2745967507362366  (0.2745967507362366)\n","     | > loss_disc_real_4: 0.2362816333770752  (0.2362816333770752)\n","     | > loss_disc_real_5: 0.2574180066585541  (0.2574180066585541)\n","     | > loss_0: 3.002713203430176  (3.002713203430176)\n","     | > grad_norm_0: tensor(0.6503, device='cuda:0')  (tensor(0.6503, device='cuda:0'))\n","     | > loss_gen: 1.5069222450256348  (1.5069222450256348)\n","     | > loss_kl: 3.1277389526367188  (3.1277389526367188)\n","     | > loss_feat: 0.4128202199935913  (0.4128202199935913)\n","     | > loss_mel: 20.569828033447266  (20.569828033447266)\n","     | > loss_duration: 1.579042911529541  (1.579042911529541)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 27.196352005004883  (27.196352005004883)\n","     | > grad_norm_1: tensor(81.5049, device='cuda:0')  (tensor(81.5049, device='cuda:0'))\n","     | > current_lr_0: 0.0001997751124671936 \n","     | > current_lr_1: 0.0001997751124671936 \n","     | > step_time: 2.5321  (2.532061815261841)\n","     | > loader_time: 1.9513  (1.9512815475463867)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.974080801010132  (2.974080801010132)\n","     | > loss_disc_real_0: 0.2459620088338852  (0.2459620088338852)\n","     | > loss_disc_real_1: 0.24018621444702148  (0.24018621444702148)\n","     | > loss_disc_real_2: 0.2627526819705963  (0.2627526819705963)\n","     | > loss_disc_real_3: 0.27147361636161804  (0.27147361636161804)\n","     | > loss_disc_real_4: 0.25554490089416504  (0.25554490089416504)\n","     | > loss_disc_real_5: 0.2560829520225525  (0.2560829520225525)\n","     | > loss_0: 2.974080801010132  (2.974080801010132)\n","     | > loss_gen: 1.5625224113464355  (1.5625224113464355)\n","     | > loss_kl: 3.0351743698120117  (3.0351743698120117)\n","     | > loss_feat: 0.42770063877105713  (0.42770063877105713)\n","     | > loss_mel: 22.057132720947266  (22.057132720947266)\n","     | > loss_duration: 1.625554084777832  (1.625554084777832)\n","     | > loss_1: 28.708084106445312  (28.708084106445312)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.24069738388061523 \u001b[0m(-0.0012295246124267578)\n","     | > avg_loss_disc:\u001b[92m 2.974080801010132 \u001b[0m(-0.0007655620574951172)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.2459620088338852 \u001b[0m(-0.0033279508352279663)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.24018621444702148 \u001b[0m(-0.007064461708068848)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2627526819705963 \u001b[0m(-0.004562497138977051)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.27147361636161804 \u001b[0m(+0.00444069504737854)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.25554490089416504 \u001b[0m(+0.02481110394001007)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.2560829520225525 \u001b[0m(-0.0034128129482269287)\n","     | > avg_loss_0:\u001b[92m 2.974080801010132 \u001b[0m(-0.0007655620574951172)\n","     | > avg_loss_gen:\u001b[91m 1.5625224113464355 \u001b[0m(+0.011465787887573242)\n","     | > avg_loss_kl:\u001b[91m 3.0351743698120117 \u001b[0m(+0.46381378173828125)\n","     | > avg_loss_feat:\u001b[92m 0.42770063877105713 \u001b[0m(-0.06893378496170044)\n","     | > avg_loss_mel:\u001b[92m 22.057132720947266 \u001b[0m(-0.367218017578125)\n","     | > avg_loss_duration:\u001b[91m 1.625554084777832 \u001b[0m(+0.016896486282348633)\n","     | > avg_loss_1:\u001b[91m 28.708084106445312 \u001b[0m(+0.05602455139160156)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 10/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:51:26) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.978076219558716  (2.978076219558716)\n","     | > loss_disc_real_0: 0.2526446282863617  (0.2526446282863617)\n","     | > loss_disc_real_1: 0.2127792239189148  (0.2127792239189148)\n","     | > loss_disc_real_2: 0.24960581958293915  (0.24960581958293915)\n","     | > loss_disc_real_3: 0.24691128730773926  (0.24691128730773926)\n","     | > loss_disc_real_4: 0.24739469587802887  (0.24739469587802887)\n","     | > loss_disc_real_5: 0.2692417800426483  (0.2692417800426483)\n","     | > loss_0: 2.978076219558716  (2.978076219558716)\n","     | > loss_gen: 1.5097167491912842  (1.5097167491912842)\n","     | > loss_kl: 3.0095016956329346  (3.0095016956329346)\n","     | > loss_feat: 0.3757304847240448  (0.3757304847240448)\n","     | > loss_mel: 21.30354881286621  (21.30354881286621)\n","     | > loss_duration: 1.6196620464324951  (1.6196620464324951)\n","     | > loss_1: 27.818159103393555  (27.818159103393555)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.23371243476867676 \u001b[0m(-0.0069849491119384766)\n","     | > avg_loss_disc:\u001b[91m 2.978076219558716 \u001b[0m(+0.003995418548583984)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.2526446282863617 \u001b[0m(+0.0066826194524765015)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.2127792239189148 \u001b[0m(-0.02740699052810669)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.24960581958293915 \u001b[0m(-0.013146862387657166)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.24691128730773926 \u001b[0m(-0.024562329053878784)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.24739469587802887 \u001b[0m(-0.00815020501613617)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2692417800426483 \u001b[0m(+0.013158828020095825)\n","     | > avg_loss_0:\u001b[91m 2.978076219558716 \u001b[0m(+0.003995418548583984)\n","     | > avg_loss_gen:\u001b[92m 1.5097167491912842 \u001b[0m(-0.05280566215515137)\n","     | > avg_loss_kl:\u001b[92m 3.0095016956329346 \u001b[0m(-0.02567267417907715)\n","     | > avg_loss_feat:\u001b[92m 0.3757304847240448 \u001b[0m(-0.05197015404701233)\n","     | > avg_loss_mel:\u001b[92m 21.30354881286621 \u001b[0m(-0.7535839080810547)\n","     | > avg_loss_duration:\u001b[92m 1.6196620464324951 \u001b[0m(-0.005892038345336914)\n","     | > avg_loss_1:\u001b[92m 27.818159103393555 \u001b[0m(-0.8899250030517578)\n","\n"," > BEST MODEL : tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000/best_model_1000122.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 11/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:52:04) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 21:52:15 -- STEP: 3/11 -- GLOBAL_STEP: 1000125\u001b[0m\n","     | > loss_disc: 3.002434253692627  (2.9935759703318277)\n","     | > loss_disc_real_0: 0.22488883137702942  (0.24772516886393228)\n","     | > loss_disc_real_1: 0.3177037835121155  (0.26429855823516846)\n","     | > loss_disc_real_2: 0.21036267280578613  (0.241604745388031)\n","     | > loss_disc_real_3: 0.21288610994815826  (0.24581141273180643)\n","     | > loss_disc_real_4: 0.17977078258991241  (0.2374661515156428)\n","     | > loss_disc_real_5: 0.23020890355110168  (0.24562289317448935)\n","     | > loss_0: 3.002434253692627  (2.9935759703318277)\n","     | > grad_norm_0: tensor(2.8029, device='cuda:0')  (tensor(2.0399, device='cuda:0'))\n","     | > loss_gen: 1.6985419988632202  (1.5824953317642212)\n","     | > loss_kl: 2.8761370182037354  (2.9091080029805503)\n","     | > loss_feat: 0.4596346318721771  (0.48344046870867413)\n","     | > loss_mel: 19.91522979736328  (20.15292231241862)\n","     | > loss_duration: 1.5617141723632812  (1.5478270451227825)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 26.51125717163086  (26.675792694091797)\n","     | > grad_norm_1: tensor(50.9991, device='cuda:0')  (tensor(69.0439, device='cuda:0'))\n","     | > current_lr_0: 0.00019972517181056292 \n","     | > current_lr_1: 0.00019972517181056292 \n","     | > step_time: 2.2402  (2.2617061932881675)\n","     | > loader_time: 0.0127  (0.013763427734375)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9512081146240234  (2.9512081146240234)\n","     | > loss_disc_real_0: 0.21229813992977142  (0.21229813992977142)\n","     | > loss_disc_real_1: 0.24250052869319916  (0.24250052869319916)\n","     | > loss_disc_real_2: 0.2666938006877899  (0.2666938006877899)\n","     | > loss_disc_real_3: 0.24351884424686432  (0.24351884424686432)\n","     | > loss_disc_real_4: 0.22887106239795685  (0.22887106239795685)\n","     | > loss_disc_real_5: 0.22492161393165588  (0.22492161393165588)\n","     | > loss_0: 2.9512081146240234  (2.9512081146240234)\n","     | > loss_gen: 1.4742798805236816  (1.4742798805236816)\n","     | > loss_kl: 2.9539389610290527  (2.9539389610290527)\n","     | > loss_feat: 0.5349346399307251  (0.5349346399307251)\n","     | > loss_mel: 20.138317108154297  (20.138317108154297)\n","     | > loss_duration: 1.598351001739502  (1.598351001739502)\n","     | > loss_1: 26.699819564819336  (26.699819564819336)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.23756051063537598 \u001b[0m(+0.0038480758666992188)\n","     | > avg_loss_disc:\u001b[92m 2.9512081146240234 \u001b[0m(-0.026868104934692383)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.21229813992977142 \u001b[0m(-0.04034648835659027)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.24250052869319916 \u001b[0m(+0.029721304774284363)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.2666938006877899 \u001b[0m(+0.01708798110485077)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.24351884424686432 \u001b[0m(-0.003392443060874939)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.22887106239795685 \u001b[0m(-0.01852363348007202)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.22492161393165588 \u001b[0m(-0.04432016611099243)\n","     | > avg_loss_0:\u001b[92m 2.9512081146240234 \u001b[0m(-0.026868104934692383)\n","     | > avg_loss_gen:\u001b[92m 1.4742798805236816 \u001b[0m(-0.03543686866760254)\n","     | > avg_loss_kl:\u001b[92m 2.9539389610290527 \u001b[0m(-0.055562734603881836)\n","     | > avg_loss_feat:\u001b[91m 0.5349346399307251 \u001b[0m(+0.1592041552066803)\n","     | > avg_loss_mel:\u001b[92m 20.138317108154297 \u001b[0m(-1.165231704711914)\n","     | > avg_loss_duration:\u001b[92m 1.598351001739502 \u001b[0m(-0.021311044692993164)\n","     | > avg_loss_1:\u001b[92m 26.699819564819336 \u001b[0m(-1.1183395385742188)\n","\n"," > BEST MODEL : tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000/best_model_1000133.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 12/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:52:42) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9611315727233887  (2.9611315727233887)\n","     | > loss_disc_real_0: 0.253280907869339  (0.253280907869339)\n","     | > loss_disc_real_1: 0.24915239214897156  (0.24915239214897156)\n","     | > loss_disc_real_2: 0.2583030164241791  (0.2583030164241791)\n","     | > loss_disc_real_3: 0.2525348365306854  (0.2525348365306854)\n","     | > loss_disc_real_4: 0.24076253175735474  (0.24076253175735474)\n","     | > loss_disc_real_5: 0.2428671270608902  (0.2428671270608902)\n","     | > loss_0: 2.9611315727233887  (2.9611315727233887)\n","     | > loss_gen: 1.5404728651046753  (1.5404728651046753)\n","     | > loss_kl: 2.93441104888916  (2.93441104888916)\n","     | > loss_feat: 0.49010738730430603  (0.49010738730430603)\n","     | > loss_mel: 21.099214553833008  (21.099214553833008)\n","     | > loss_duration: 1.5771011114120483  (1.5771011114120483)\n","     | > loss_1: 27.641305923461914  (27.641305923461914)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.23450636863708496 \u001b[0m(-0.0030541419982910156)\n","     | > avg_loss_disc:\u001b[91m 2.9611315727233887 \u001b[0m(+0.009923458099365234)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.253280907869339 \u001b[0m(+0.040982767939567566)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.24915239214897156 \u001b[0m(+0.0066518634557724)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2583030164241791 \u001b[0m(-0.00839078426361084)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.2525348365306854 \u001b[0m(+0.009015992283821106)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.24076253175735474 \u001b[0m(+0.011891469359397888)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2428671270608902 \u001b[0m(+0.017945513129234314)\n","     | > avg_loss_0:\u001b[91m 2.9611315727233887 \u001b[0m(+0.009923458099365234)\n","     | > avg_loss_gen:\u001b[91m 1.5404728651046753 \u001b[0m(+0.06619298458099365)\n","     | > avg_loss_kl:\u001b[92m 2.93441104888916 \u001b[0m(-0.019527912139892578)\n","     | > avg_loss_feat:\u001b[92m 0.49010738730430603 \u001b[0m(-0.04482725262641907)\n","     | > avg_loss_mel:\u001b[91m 21.099214553833008 \u001b[0m(+0.9608974456787109)\n","     | > avg_loss_duration:\u001b[92m 1.5771011114120483 \u001b[0m(-0.021249890327453613)\n","     | > avg_loss_1:\u001b[91m 27.641305923461914 \u001b[0m(+0.9414863586425781)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 13/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:53:18) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 21:53:37 -- STEP: 6/11 -- GLOBAL_STEP: 1000150\u001b[0m\n","     | > loss_disc: 2.9877700805664062  (2.975481390953064)\n","     | > loss_disc_real_0: 0.20732088387012482  (0.24190098295609155)\n","     | > loss_disc_real_1: 0.2263123095035553  (0.2490923578540484)\n","     | > loss_disc_real_2: 0.22546249628067017  (0.24882061531146368)\n","     | > loss_disc_real_3: 0.2284512221813202  (0.24498102813959122)\n","     | > loss_disc_real_4: 0.22697165608406067  (0.2514779021342595)\n","     | > loss_disc_real_5: 0.24343018233776093  (0.25384584814310074)\n","     | > loss_0: 2.9877700805664062  (2.975481390953064)\n","     | > grad_norm_0: tensor(1.7112, device='cuda:0')  (tensor(1.1224, device='cuda:0'))\n","     | > loss_gen: 1.6462931632995605  (1.5487483541170757)\n","     | > loss_kl: 2.698148012161255  (2.760114630063375)\n","     | > loss_feat: 0.49511438608169556  (0.49643195668856305)\n","     | > loss_mel: 19.960180282592773  (20.12578233083089)\n","     | > loss_duration: 1.6347792148590088  (1.5529061357180278)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 26.43451499938965  (26.483983357747395)\n","     | > grad_norm_1: tensor(53.3089, device='cuda:0')  (tensor(67.5493, device='cuda:0'))\n","     | > current_lr_0: 0.00019967524363831608 \n","     | > current_lr_1: 0.00019967524363831608 \n","     | > step_time: 2.8293  (2.4401506185531616)\n","     | > loader_time: 0.0191  (0.014554897944132486)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.953212261199951  (2.953212261199951)\n","     | > loss_disc_real_0: 0.27122023701667786  (0.27122023701667786)\n","     | > loss_disc_real_1: 0.24897970259189606  (0.24897970259189606)\n","     | > loss_disc_real_2: 0.25324636697769165  (0.25324636697769165)\n","     | > loss_disc_real_3: 0.23070240020751953  (0.23070240020751953)\n","     | > loss_disc_real_4: 0.2614424526691437  (0.2614424526691437)\n","     | > loss_disc_real_5: 0.25283220410346985  (0.25283220410346985)\n","     | > loss_0: 2.953212261199951  (2.953212261199951)\n","     | > loss_gen: 1.5716452598571777  (1.5716452598571777)\n","     | > loss_kl: 2.7293660640716553  (2.7293660640716553)\n","     | > loss_feat: 0.4182283878326416  (0.4182283878326416)\n","     | > loss_mel: 20.12697410583496  (20.12697410583496)\n","     | > loss_duration: 1.5883054733276367  (1.5883054733276367)\n","     | > loss_1: 26.434520721435547  (26.434520721435547)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.27585911750793457 \u001b[0m(+0.04135274887084961)\n","     | > avg_loss_disc:\u001b[92m 2.953212261199951 \u001b[0m(-0.0079193115234375)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.27122023701667786 \u001b[0m(+0.017939329147338867)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.24897970259189606 \u001b[0m(-0.0001726895570755005)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.25324636697769165 \u001b[0m(-0.005056649446487427)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.23070240020751953 \u001b[0m(-0.021832436323165894)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.2614424526691437 \u001b[0m(+0.02067992091178894)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.25283220410346985 \u001b[0m(+0.009965077042579651)\n","     | > avg_loss_0:\u001b[92m 2.953212261199951 \u001b[0m(-0.0079193115234375)\n","     | > avg_loss_gen:\u001b[91m 1.5716452598571777 \u001b[0m(+0.03117239475250244)\n","     | > avg_loss_kl:\u001b[92m 2.7293660640716553 \u001b[0m(-0.20504498481750488)\n","     | > avg_loss_feat:\u001b[92m 0.4182283878326416 \u001b[0m(-0.07187899947166443)\n","     | > avg_loss_mel:\u001b[92m 20.12697410583496 \u001b[0m(-0.9722404479980469)\n","     | > avg_loss_duration:\u001b[91m 1.5883054733276367 \u001b[0m(+0.011204361915588379)\n","     | > avg_loss_1:\u001b[92m 26.434520721435547 \u001b[0m(-1.2067852020263672)\n","\n"," > BEST MODEL : tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000/best_model_1000155.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 14/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:53:57) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.963582754135132  (2.963582754135132)\n","     | > loss_disc_real_0: 0.25922060012817383  (0.25922060012817383)\n","     | > loss_disc_real_1: 0.27870243787765503  (0.27870243787765503)\n","     | > loss_disc_real_2: 0.2258380651473999  (0.2258380651473999)\n","     | > loss_disc_real_3: 0.20407646894454956  (0.20407646894454956)\n","     | > loss_disc_real_4: 0.27199292182922363  (0.27199292182922363)\n","     | > loss_disc_real_5: 0.27293431758880615  (0.27293431758880615)\n","     | > loss_0: 2.963582754135132  (2.963582754135132)\n","     | > loss_gen: 1.5687824487686157  (1.5687824487686157)\n","     | > loss_kl: 2.662362575531006  (2.662362575531006)\n","     | > loss_feat: 0.5371770858764648  (0.5371770858764648)\n","     | > loss_mel: 20.511722564697266  (20.511722564697266)\n","     | > loss_duration: 1.5723991394042969  (1.5723991394042969)\n","     | > loss_1: 26.85244369506836  (26.85244369506836)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.25594019889831543 \u001b[0m(-0.01991891860961914)\n","     | > avg_loss_disc:\u001b[91m 2.963582754135132 \u001b[0m(+0.010370492935180664)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.25922060012817383 \u001b[0m(-0.011999636888504028)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.27870243787765503 \u001b[0m(+0.029722735285758972)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2258380651473999 \u001b[0m(-0.027408301830291748)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.20407646894454956 \u001b[0m(-0.02662593126296997)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.27199292182922363 \u001b[0m(+0.010550469160079956)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.27293431758880615 \u001b[0m(+0.020102113485336304)\n","     | > avg_loss_0:\u001b[91m 2.963582754135132 \u001b[0m(+0.010370492935180664)\n","     | > avg_loss_gen:\u001b[92m 1.5687824487686157 \u001b[0m(-0.0028628110885620117)\n","     | > avg_loss_kl:\u001b[92m 2.662362575531006 \u001b[0m(-0.06700348854064941)\n","     | > avg_loss_feat:\u001b[91m 0.5371770858764648 \u001b[0m(+0.11894869804382324)\n","     | > avg_loss_mel:\u001b[91m 20.511722564697266 \u001b[0m(+0.3847484588623047)\n","     | > avg_loss_duration:\u001b[92m 1.5723991394042969 \u001b[0m(-0.015906333923339844)\n","     | > avg_loss_1:\u001b[91m 26.85244369506836 \u001b[0m(+0.4179229736328125)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 15/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:54:33) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 21:55:01 -- STEP: 9/11 -- GLOBAL_STEP: 1000175\u001b[0m\n","     | > loss_disc: 3.0063841342926025  (2.9791838592953153)\n","     | > loss_disc_real_0: 0.19127139449119568  (0.23695426185925803)\n","     | > loss_disc_real_1: 0.2511248290538788  (0.2457493179374271)\n","     | > loss_disc_real_2: 0.1281471997499466  (0.25017036497592926)\n","     | > loss_disc_real_3: 0.2403651773929596  (0.24714682665136126)\n","     | > loss_disc_real_4: 0.18746381998062134  (0.24156288968192208)\n","     | > loss_disc_real_5: 0.20855875313282013  (0.2450577434566286)\n","     | > loss_0: 3.0063841342926025  (2.9791838592953153)\n","     | > grad_norm_0: tensor(4.6873, device='cuda:0')  (tensor(2.6544, device='cuda:0'))\n","     | > loss_gen: 1.722707986831665  (1.5628547536002264)\n","     | > loss_kl: 2.636500358581543  (2.711502446068658)\n","     | > loss_feat: 0.5363303422927856  (0.4959189295768738)\n","     | > loss_mel: 19.85691261291504  (20.006124920315212)\n","     | > loss_duration: 1.6052837371826172  (1.5614399645063612)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 26.35773468017578  (26.33784082200792)\n","     | > grad_norm_1: tensor(75.4570, device='cuda:0')  (tensor(70.3883, device='cuda:0'))\n","     | > current_lr_0: 0.00019962532794733217 \n","     | > current_lr_1: 0.00019962532794733217 \n","     | > step_time: 2.8599  (2.576321999231974)\n","     | > loader_time: 0.0184  (0.0166066222720676)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 3.001680374145508  (3.001680374145508)\n","     | > loss_disc_real_0: 0.28197726607322693  (0.28197726607322693)\n","     | > loss_disc_real_1: 0.22328519821166992  (0.22328519821166992)\n","     | > loss_disc_real_2: 0.3722989857196808  (0.3722989857196808)\n","     | > loss_disc_real_3: 0.22857172787189484  (0.22857172787189484)\n","     | > loss_disc_real_4: 0.3000507354736328  (0.3000507354736328)\n","     | > loss_disc_real_5: 0.28512123227119446  (0.28512123227119446)\n","     | > loss_0: 3.001680374145508  (3.001680374145508)\n","     | > loss_gen: 1.7301321029663086  (1.7301321029663086)\n","     | > loss_kl: 2.562873363494873  (2.562873363494873)\n","     | > loss_feat: 0.43450748920440674  (0.43450748920440674)\n","     | > loss_mel: 20.12100601196289  (20.12100601196289)\n","     | > loss_duration: 1.5736007690429688  (1.5736007690429688)\n","     | > loss_1: 26.422119140625  (26.422119140625)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.24525165557861328 \u001b[0m(-0.010688543319702148)\n","     | > avg_loss_disc:\u001b[91m 3.001680374145508 \u001b[0m(+0.03809762001037598)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.28197726607322693 \u001b[0m(+0.0227566659450531)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.22328519821166992 \u001b[0m(-0.05541723966598511)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.3722989857196808 \u001b[0m(+0.14646092057228088)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.22857172787189484 \u001b[0m(+0.024495258927345276)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.3000507354736328 \u001b[0m(+0.02805781364440918)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.28512123227119446 \u001b[0m(+0.012186914682388306)\n","     | > avg_loss_0:\u001b[91m 3.001680374145508 \u001b[0m(+0.03809762001037598)\n","     | > avg_loss_gen:\u001b[91m 1.7301321029663086 \u001b[0m(+0.16134965419769287)\n","     | > avg_loss_kl:\u001b[92m 2.562873363494873 \u001b[0m(-0.09948921203613281)\n","     | > avg_loss_feat:\u001b[92m 0.43450748920440674 \u001b[0m(-0.1026695966720581)\n","     | > avg_loss_mel:\u001b[92m 20.12100601196289 \u001b[0m(-0.390716552734375)\n","     | > avg_loss_duration:\u001b[91m 1.5736007690429688 \u001b[0m(+0.001201629638671875)\n","     | > avg_loss_1:\u001b[92m 26.422119140625 \u001b[0m(-0.4303245544433594)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 16/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:55:09) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.96980619430542  (2.96980619430542)\n","     | > loss_disc_real_0: 0.3119109869003296  (0.3119109869003296)\n","     | > loss_disc_real_1: 0.2792488932609558  (0.2792488932609558)\n","     | > loss_disc_real_2: 0.24221861362457275  (0.24221861362457275)\n","     | > loss_disc_real_3: 0.19776687026023865  (0.19776687026023865)\n","     | > loss_disc_real_4: 0.3076818883419037  (0.3076818883419037)\n","     | > loss_disc_real_5: 0.27387484908103943  (0.27387484908103943)\n","     | > loss_0: 2.96980619430542  (2.96980619430542)\n","     | > loss_gen: 1.6777739524841309  (1.6777739524841309)\n","     | > loss_kl: 3.0520172119140625  (3.0520172119140625)\n","     | > loss_feat: 0.5497138500213623  (0.5497138500213623)\n","     | > loss_mel: 20.070629119873047  (20.070629119873047)\n","     | > loss_duration: 1.5683307647705078  (1.5683307647705078)\n","     | > loss_1: 26.91846466064453  (26.91846466064453)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.24588751792907715 \u001b[0m(+0.0006358623504638672)\n","     | > avg_loss_disc:\u001b[92m 2.96980619430542 \u001b[0m(-0.03187417984008789)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.3119109869003296 \u001b[0m(+0.02993372082710266)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.2792488932609558 \u001b[0m(+0.05596369504928589)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.24221861362457275 \u001b[0m(-0.13008037209510803)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.19776687026023865 \u001b[0m(-0.03080485761165619)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.3076818883419037 \u001b[0m(+0.007631152868270874)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.27387484908103943 \u001b[0m(-0.01124638319015503)\n","     | > avg_loss_0:\u001b[92m 2.96980619430542 \u001b[0m(-0.03187417984008789)\n","     | > avg_loss_gen:\u001b[92m 1.6777739524841309 \u001b[0m(-0.052358150482177734)\n","     | > avg_loss_kl:\u001b[91m 3.0520172119140625 \u001b[0m(+0.48914384841918945)\n","     | > avg_loss_feat:\u001b[91m 0.5497138500213623 \u001b[0m(+0.11520636081695557)\n","     | > avg_loss_mel:\u001b[92m 20.070629119873047 \u001b[0m(-0.05037689208984375)\n","     | > avg_loss_duration:\u001b[92m 1.5683307647705078 \u001b[0m(-0.0052700042724609375)\n","     | > avg_loss_1:\u001b[91m 26.91846466064453 \u001b[0m(+0.49634552001953125)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 17/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:55:43) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 3.015507698059082  (3.015507698059082)\n","     | > loss_disc_real_0: 0.2415258288383484  (0.2415258288383484)\n","     | > loss_disc_real_1: 0.29010745882987976  (0.29010745882987976)\n","     | > loss_disc_real_2: 0.28196391463279724  (0.28196391463279724)\n","     | > loss_disc_real_3: 0.2976680397987366  (0.2976680397987366)\n","     | > loss_disc_real_4: 0.27847954630851746  (0.27847954630851746)\n","     | > loss_disc_real_5: 0.26244547963142395  (0.26244547963142395)\n","     | > loss_0: 3.015507698059082  (3.015507698059082)\n","     | > loss_gen: 1.6571427583694458  (1.6571427583694458)\n","     | > loss_kl: 2.614107847213745  (2.614107847213745)\n","     | > loss_feat: 0.6566329598426819  (0.6566329598426819)\n","     | > loss_mel: 20.536436080932617  (20.536436080932617)\n","     | > loss_duration: 1.5490978956222534  (1.5490978956222534)\n","     | > loss_1: 27.013416290283203  (27.013416290283203)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.2575843334197998 \u001b[0m(+0.011696815490722656)\n","     | > avg_loss_disc:\u001b[91m 3.015507698059082 \u001b[0m(+0.04570150375366211)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.2415258288383484 \u001b[0m(-0.0703851580619812)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.29010745882987976 \u001b[0m(+0.01085856556892395)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.28196391463279724 \u001b[0m(+0.03974530100822449)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.2976680397987366 \u001b[0m(+0.09990116953849792)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.27847954630851746 \u001b[0m(-0.02920234203338623)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.26244547963142395 \u001b[0m(-0.011429369449615479)\n","     | > avg_loss_0:\u001b[91m 3.015507698059082 \u001b[0m(+0.04570150375366211)\n","     | > avg_loss_gen:\u001b[92m 1.6571427583694458 \u001b[0m(-0.02063119411468506)\n","     | > avg_loss_kl:\u001b[92m 2.614107847213745 \u001b[0m(-0.4379093647003174)\n","     | > avg_loss_feat:\u001b[91m 0.6566329598426819 \u001b[0m(+0.10691910982131958)\n","     | > avg_loss_mel:\u001b[91m 20.536436080932617 \u001b[0m(+0.4658069610595703)\n","     | > avg_loss_duration:\u001b[92m 1.5490978956222534 \u001b[0m(-0.019232869148254395)\n","     | > avg_loss_1:\u001b[91m 27.013416290283203 \u001b[0m(+0.09495162963867188)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 18/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:56:19) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 21:56:25 -- STEP: 1/11 -- GLOBAL_STEP: 1000200\u001b[0m\n","     | > loss_disc: 2.9532036781311035  (2.9532036781311035)\n","     | > loss_disc_real_0: 0.2515808939933777  (0.2515808939933777)\n","     | > loss_disc_real_1: 0.21113575994968414  (0.21113575994968414)\n","     | > loss_disc_real_2: 0.2461690753698349  (0.2461690753698349)\n","     | > loss_disc_real_3: 0.2375015765428543  (0.2375015765428543)\n","     | > loss_disc_real_4: 0.1929379105567932  (0.1929379105567932)\n","     | > loss_disc_real_5: 0.22206048667430878  (0.22206048667430878)\n","     | > loss_0: 2.9532036781311035  (2.9532036781311035)\n","     | > grad_norm_0: tensor(2.0720, device='cuda:0')  (tensor(2.0720, device='cuda:0'))\n","     | > loss_gen: 1.4746098518371582  (1.4746098518371582)\n","     | > loss_kl: 2.6637911796569824  (2.6637911796569824)\n","     | > loss_feat: 0.5326917767524719  (0.5326917767524719)\n","     | > loss_mel: 20.053403854370117  (20.053403854370117)\n","     | > loss_duration: 1.5061836242675781  (1.5061836242675781)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 26.230680465698242  (26.230680465698242)\n","     | > grad_norm_1: tensor(96.0006, device='cuda:0')  (tensor(96.0006, device='cuda:0'))\n","     | > current_lr_0: 0.00019955047780639926 \n","     | > current_lr_1: 0.00019955047780639926 \n","     | > step_time: 2.2789  (2.278871536254883)\n","     | > loader_time: 0.0126  (0.01257634162902832)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.975888967514038  (2.975888967514038)\n","     | > loss_disc_real_0: 0.1557510793209076  (0.1557510793209076)\n","     | > loss_disc_real_1: 0.253383994102478  (0.253383994102478)\n","     | > loss_disc_real_2: 0.2347419112920761  (0.2347419112920761)\n","     | > loss_disc_real_3: 0.23632986843585968  (0.23632986843585968)\n","     | > loss_disc_real_4: 0.21206708252429962  (0.21206708252429962)\n","     | > loss_disc_real_5: 0.21443134546279907  (0.21443134546279907)\n","     | > loss_0: 2.975888967514038  (2.975888967514038)\n","     | > loss_gen: 1.3651424646377563  (1.3651424646377563)\n","     | > loss_kl: 2.788146495819092  (2.788146495819092)\n","     | > loss_feat: 0.588327169418335  (0.588327169418335)\n","     | > loss_mel: 20.717941284179688  (20.717941284179688)\n","     | > loss_duration: 1.540603756904602  (1.540603756904602)\n","     | > loss_1: 27.00016212463379  (27.00016212463379)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.25820326805114746 \u001b[0m(+0.0006189346313476562)\n","     | > avg_loss_disc:\u001b[92m 2.975888967514038 \u001b[0m(-0.039618730545043945)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.1557510793209076 \u001b[0m(-0.0857747495174408)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.253383994102478 \u001b[0m(-0.03672346472740173)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2347419112920761 \u001b[0m(-0.04722200334072113)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.23632986843585968 \u001b[0m(-0.06133817136287689)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.21206708252429962 \u001b[0m(-0.06641246378421783)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.21443134546279907 \u001b[0m(-0.04801413416862488)\n","     | > avg_loss_0:\u001b[92m 2.975888967514038 \u001b[0m(-0.039618730545043945)\n","     | > avg_loss_gen:\u001b[92m 1.3651424646377563 \u001b[0m(-0.29200029373168945)\n","     | > avg_loss_kl:\u001b[91m 2.788146495819092 \u001b[0m(+0.17403864860534668)\n","     | > avg_loss_feat:\u001b[92m 0.588327169418335 \u001b[0m(-0.06830579042434692)\n","     | > avg_loss_mel:\u001b[91m 20.717941284179688 \u001b[0m(+0.1815052032470703)\n","     | > avg_loss_duration:\u001b[92m 1.540603756904602 \u001b[0m(-0.008494138717651367)\n","     | > avg_loss_1:\u001b[92m 27.00016212463379 \u001b[0m(-0.013254165649414062)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 19/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:56:55) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9611682891845703  (2.9611682891845703)\n","     | > loss_disc_real_0: 0.35061249136924744  (0.35061249136924744)\n","     | > loss_disc_real_1: 0.23920011520385742  (0.23920011520385742)\n","     | > loss_disc_real_2: 0.2758055031299591  (0.2758055031299591)\n","     | > loss_disc_real_3: 0.2437323033809662  (0.2437323033809662)\n","     | > loss_disc_real_4: 0.29005324840545654  (0.29005324840545654)\n","     | > loss_disc_real_5: 0.3423522412776947  (0.3423522412776947)\n","     | > loss_0: 2.9611682891845703  (2.9611682891845703)\n","     | > loss_gen: 1.8368861675262451  (1.8368861675262451)\n","     | > loss_kl: 2.3139545917510986  (2.3139545917510986)\n","     | > loss_feat: 0.6879132390022278  (0.6879132390022278)\n","     | > loss_mel: 21.022539138793945  (21.022539138793945)\n","     | > loss_duration: 1.5464930534362793  (1.5464930534362793)\n","     | > loss_1: 27.407785415649414  (27.407785415649414)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.2528078556060791 \u001b[0m(-0.005395412445068359)\n","     | > avg_loss_disc:\u001b[92m 2.9611682891845703 \u001b[0m(-0.014720678329467773)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.35061249136924744 \u001b[0m(+0.19486141204833984)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.23920011520385742 \u001b[0m(-0.014183878898620605)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.2758055031299591 \u001b[0m(+0.041063591837882996)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.2437323033809662 \u001b[0m(+0.007402434945106506)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.29005324840545654 \u001b[0m(+0.07798616588115692)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.3423522412776947 \u001b[0m(+0.12792089581489563)\n","     | > avg_loss_0:\u001b[92m 2.9611682891845703 \u001b[0m(-0.014720678329467773)\n","     | > avg_loss_gen:\u001b[91m 1.8368861675262451 \u001b[0m(+0.47174370288848877)\n","     | > avg_loss_kl:\u001b[92m 2.3139545917510986 \u001b[0m(-0.47419190406799316)\n","     | > avg_loss_feat:\u001b[91m 0.6879132390022278 \u001b[0m(+0.09958606958389282)\n","     | > avg_loss_mel:\u001b[91m 21.022539138793945 \u001b[0m(+0.3045978546142578)\n","     | > avg_loss_duration:\u001b[91m 1.5464930534362793 \u001b[0m(+0.005889296531677246)\n","     | > avg_loss_1:\u001b[91m 27.407785415649414 \u001b[0m(+0.407623291015625)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 20/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:57:31) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 21:57:44 -- STEP: 4/11 -- GLOBAL_STEP: 1000225\u001b[0m\n","     | > loss_disc: 2.947099447250366  (2.9504634141921997)\n","     | > loss_disc_real_0: 0.24333757162094116  (0.2350991778075695)\n","     | > loss_disc_real_1: 0.18233539164066315  (0.23356619477272034)\n","     | > loss_disc_real_2: 0.23420196771621704  (0.2406335286796093)\n","     | > loss_disc_real_3: 0.19962269067764282  (0.23478062450885773)\n","     | > loss_disc_real_4: 0.26288068294525146  (0.24292486533522606)\n","     | > loss_disc_real_5: 0.2765723764896393  (0.24426427856087685)\n","     | > loss_0: 2.947099447250366  (2.9504634141921997)\n","     | > grad_norm_0: tensor(3.2243, device='cuda:0')  (tensor(3.6658, device='cuda:0'))\n","     | > loss_gen: 1.5816227197647095  (1.56606724858284)\n","     | > loss_kl: 2.314387321472168  (2.467740297317505)\n","     | > loss_feat: 0.5519448518753052  (0.5810218453407288)\n","     | > loss_mel: 18.7541561126709  (19.472856998443604)\n","     | > loss_duration: 1.452331781387329  (1.4788791835308075)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 24.654441833496094  (25.566565990447998)\n","     | > grad_norm_1: tensor(176.0347, device='cuda:0')  (tensor(104.4961, device='cuda:0'))\n","     | > current_lr_0: 0.00019950059330492385 \n","     | > current_lr_1: 0.00019950059330492385 \n","     | > step_time: 2.2304  (2.2397043704986572)\n","     | > loader_time: 0.0122  (0.013787806034088135)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.923241138458252  (2.923241138458252)\n","     | > loss_disc_real_0: 0.20132248103618622  (0.20132248103618622)\n","     | > loss_disc_real_1: 0.19959492981433868  (0.19959492981433868)\n","     | > loss_disc_real_2: 0.22044657170772552  (0.22044657170772552)\n","     | > loss_disc_real_3: 0.2476230412721634  (0.2476230412721634)\n","     | > loss_disc_real_4: 0.24177096784114838  (0.24177096784114838)\n","     | > loss_disc_real_5: 0.2497071623802185  (0.2497071623802185)\n","     | > loss_0: 2.923241138458252  (2.923241138458252)\n","     | > loss_gen: 1.4642889499664307  (1.4642889499664307)\n","     | > loss_kl: 2.838132858276367  (2.838132858276367)\n","     | > loss_feat: 0.7052615284919739  (0.7052615284919739)\n","     | > loss_mel: 19.154769897460938  (19.154769897460938)\n","     | > loss_duration: 1.541334867477417  (1.541334867477417)\n","     | > loss_1: 25.703786849975586  (25.703786849975586)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.2864551544189453 \u001b[0m(+0.03364729881286621)\n","     | > avg_loss_disc:\u001b[92m 2.923241138458252 \u001b[0m(-0.03792715072631836)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.20132248103618622 \u001b[0m(-0.14929001033306122)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.19959492981433868 \u001b[0m(-0.03960518538951874)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.22044657170772552 \u001b[0m(-0.05535893142223358)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.2476230412721634 \u001b[0m(+0.0038907378911972046)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.24177096784114838 \u001b[0m(-0.048282280564308167)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.2497071623802185 \u001b[0m(-0.0926450788974762)\n","     | > avg_loss_0:\u001b[92m 2.923241138458252 \u001b[0m(-0.03792715072631836)\n","     | > avg_loss_gen:\u001b[92m 1.4642889499664307 \u001b[0m(-0.37259721755981445)\n","     | > avg_loss_kl:\u001b[91m 2.838132858276367 \u001b[0m(+0.5241782665252686)\n","     | > avg_loss_feat:\u001b[91m 0.7052615284919739 \u001b[0m(+0.017348289489746094)\n","     | > avg_loss_mel:\u001b[92m 19.154769897460938 \u001b[0m(-1.8677692413330078)\n","     | > avg_loss_duration:\u001b[92m 1.541334867477417 \u001b[0m(-0.005158185958862305)\n","     | > avg_loss_1:\u001b[92m 25.703786849975586 \u001b[0m(-1.7039985656738281)\n","\n"," > BEST MODEL : tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000/best_model_1000232.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 21/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:58:10) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.900135040283203  (2.900135040283203)\n","     | > loss_disc_real_0: 0.1651858538389206  (0.1651858538389206)\n","     | > loss_disc_real_1: 0.2283727079629898  (0.2283727079629898)\n","     | > loss_disc_real_2: 0.28214961290359497  (0.28214961290359497)\n","     | > loss_disc_real_3: 0.20407341420650482  (0.20407341420650482)\n","     | > loss_disc_real_4: 0.25957199931144714  (0.25957199931144714)\n","     | > loss_disc_real_5: 0.24376876652240753  (0.24376876652240753)\n","     | > loss_0: 2.900135040283203  (2.900135040283203)\n","     | > loss_gen: 1.5030425786972046  (1.5030425786972046)\n","     | > loss_kl: 2.429964542388916  (2.429964542388916)\n","     | > loss_feat: 0.6080994009971619  (0.6080994009971619)\n","     | > loss_mel: 20.12226104736328  (20.12226104736328)\n","     | > loss_duration: 1.525954246520996  (1.525954246520996)\n","     | > loss_1: 26.189319610595703  (26.189319610595703)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.2628023624420166 \u001b[0m(-0.02365279197692871)\n","     | > avg_loss_disc:\u001b[92m 2.900135040283203 \u001b[0m(-0.023106098175048828)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.1651858538389206 \u001b[0m(-0.036136627197265625)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.2283727079629898 \u001b[0m(+0.028777778148651123)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.28214961290359497 \u001b[0m(+0.061703041195869446)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.20407341420650482 \u001b[0m(-0.04354962706565857)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.25957199931144714 \u001b[0m(+0.017801031470298767)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.24376876652240753 \u001b[0m(-0.005938395857810974)\n","     | > avg_loss_0:\u001b[92m 2.900135040283203 \u001b[0m(-0.023106098175048828)\n","     | > avg_loss_gen:\u001b[91m 1.5030425786972046 \u001b[0m(+0.038753628730773926)\n","     | > avg_loss_kl:\u001b[92m 2.429964542388916 \u001b[0m(-0.40816831588745117)\n","     | > avg_loss_feat:\u001b[92m 0.6080994009971619 \u001b[0m(-0.09716212749481201)\n","     | > avg_loss_mel:\u001b[91m 20.12226104736328 \u001b[0m(+0.9674911499023438)\n","     | > avg_loss_duration:\u001b[92m 1.525954246520996 \u001b[0m(-0.015380620956420898)\n","     | > avg_loss_1:\u001b[91m 26.189319610595703 \u001b[0m(+0.4855327606201172)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 22/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:58:45) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 21:59:08 -- STEP: 7/11 -- GLOBAL_STEP: 1000250\u001b[0m\n","     | > loss_disc: 2.923074722290039  (2.9376085826328824)\n","     | > loss_disc_real_0: 0.19517600536346436  (0.242719795022692)\n","     | > loss_disc_real_1: 0.23133055865764618  (0.24567189386912755)\n","     | > loss_disc_real_2: 0.2508324980735779  (0.24475979379245213)\n","     | > loss_disc_real_3: 0.20954419672489166  (0.24281962428774154)\n","     | > loss_disc_real_4: 0.225522980093956  (0.24130448060376303)\n","     | > loss_disc_real_5: 0.22432798147201538  (0.24398689823491232)\n","     | > loss_0: 2.923074722290039  (2.9376085826328824)\n","     | > grad_norm_0: tensor(3.5110, device='cuda:0')  (tensor(2.5398, device='cuda:0'))\n","     | > loss_gen: 1.6157846450805664  (1.5711890629359655)\n","     | > loss_kl: 2.5299062728881836  (2.6331005777631487)\n","     | > loss_feat: 0.7536935210227966  (0.6340986745698112)\n","     | > loss_mel: 19.711030960083008  (19.555923461914062)\n","     | > loss_duration: 1.5779461860656738  (1.5149920327322823)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 26.18836212158203  (25.909304210117885)\n","     | > grad_norm_1: tensor(51.9620, device='cuda:0')  (tensor(74.7287, device='cuda:0'))\n","     | > current_lr_0: 0.00019945072127379438 \n","     | > current_lr_1: 0.00019945072127379438 \n","     | > step_time: 2.8244  (2.4970591408865794)\n","     | > loader_time: 0.0176  (0.015270914350237166)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.949491500854492  (2.949491500854492)\n","     | > loss_disc_real_0: 0.2222655713558197  (0.2222655713558197)\n","     | > loss_disc_real_1: 0.2143416851758957  (0.2143416851758957)\n","     | > loss_disc_real_2: 0.22838565707206726  (0.22838565707206726)\n","     | > loss_disc_real_3: 0.2676297128200531  (0.2676297128200531)\n","     | > loss_disc_real_4: 0.24717603623867035  (0.24717603623867035)\n","     | > loss_disc_real_5: 0.25676965713500977  (0.25676965713500977)\n","     | > loss_0: 2.949491500854492  (2.949491500854492)\n","     | > loss_gen: 1.5088788270950317  (1.5088788270950317)\n","     | > loss_kl: 2.9724714756011963  (2.9724714756011963)\n","     | > loss_feat: 0.4353451728820801  (0.4353451728820801)\n","     | > loss_mel: 17.78003692626953  (17.78003692626953)\n","     | > loss_duration: 1.5210031270980835  (1.5210031270980835)\n","     | > loss_1: 24.217735290527344  (24.217735290527344)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.2675642967224121 \u001b[0m(+0.004761934280395508)\n","     | > avg_loss_disc:\u001b[91m 2.949491500854492 \u001b[0m(+0.04935646057128906)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.2222655713558197 \u001b[0m(+0.05707971751689911)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.2143416851758957 \u001b[0m(-0.014031022787094116)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.22838565707206726 \u001b[0m(-0.05376395583152771)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.2676297128200531 \u001b[0m(+0.06355629861354828)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.24717603623867035 \u001b[0m(-0.012395963072776794)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.25676965713500977 \u001b[0m(+0.013000890612602234)\n","     | > avg_loss_0:\u001b[91m 2.949491500854492 \u001b[0m(+0.04935646057128906)\n","     | > avg_loss_gen:\u001b[91m 1.5088788270950317 \u001b[0m(+0.0058362483978271484)\n","     | > avg_loss_kl:\u001b[91m 2.9724714756011963 \u001b[0m(+0.5425069332122803)\n","     | > avg_loss_feat:\u001b[92m 0.4353451728820801 \u001b[0m(-0.1727542281150818)\n","     | > avg_loss_mel:\u001b[92m 17.78003692626953 \u001b[0m(-2.34222412109375)\n","     | > avg_loss_duration:\u001b[92m 1.5210031270980835 \u001b[0m(-0.004951119422912598)\n","     | > avg_loss_1:\u001b[92m 24.217735290527344 \u001b[0m(-1.9715843200683594)\n","\n"," > BEST MODEL : tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000/best_model_1000254.pth\n","\n","\u001b[4m\u001b[1m > EPOCH: 23/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 21:59:24) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9729480743408203  (2.9729480743408203)\n","     | > loss_disc_real_0: 0.2638668119907379  (0.2638668119907379)\n","     | > loss_disc_real_1: 0.22421015799045563  (0.22421015799045563)\n","     | > loss_disc_real_2: 0.265964150428772  (0.265964150428772)\n","     | > loss_disc_real_3: 0.2550843060016632  (0.2550843060016632)\n","     | > loss_disc_real_4: 0.27924785017967224  (0.27924785017967224)\n","     | > loss_disc_real_5: 0.2427794635295868  (0.2427794635295868)\n","     | > loss_0: 2.9729480743408203  (2.9729480743408203)\n","     | > loss_gen: 1.5908828973770142  (1.5908828973770142)\n","     | > loss_kl: 2.4342660903930664  (2.4342660903930664)\n","     | > loss_feat: 0.6682901382446289  (0.6682901382446289)\n","     | > loss_mel: 20.083959579467773  (20.083959579467773)\n","     | > loss_duration: 1.5139918327331543  (1.5139918327331543)\n","     | > loss_1: 26.291391372680664  (26.291391372680664)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.2610599994659424 \u001b[0m(-0.0065042972564697266)\n","     | > avg_loss_disc:\u001b[91m 2.9729480743408203 \u001b[0m(+0.023456573486328125)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.2638668119907379 \u001b[0m(+0.04160124063491821)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.22421015799045563 \u001b[0m(+0.009868472814559937)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.265964150428772 \u001b[0m(+0.03757849335670471)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.2550843060016632 \u001b[0m(-0.012545406818389893)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.27924785017967224 \u001b[0m(+0.03207181394100189)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.2427794635295868 \u001b[0m(-0.013990193605422974)\n","     | > avg_loss_0:\u001b[91m 2.9729480743408203 \u001b[0m(+0.023456573486328125)\n","     | > avg_loss_gen:\u001b[91m 1.5908828973770142 \u001b[0m(+0.08200407028198242)\n","     | > avg_loss_kl:\u001b[92m 2.4342660903930664 \u001b[0m(-0.5382053852081299)\n","     | > avg_loss_feat:\u001b[91m 0.6682901382446289 \u001b[0m(+0.23294496536254883)\n","     | > avg_loss_mel:\u001b[91m 20.083959579467773 \u001b[0m(+2.303922653198242)\n","     | > avg_loss_duration:\u001b[92m 1.5139918327331543 \u001b[0m(-0.007011294364929199)\n","     | > avg_loss_1:\u001b[91m 26.291391372680664 \u001b[0m(+2.0736560821533203)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 24/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:00:01) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 22:00:30 -- STEP: 10/11 -- GLOBAL_STEP: 1000275\u001b[0m\n","     | > loss_disc: 2.9287760257720947  (2.925837588310242)\n","     | > loss_disc_real_0: 0.23370961844921112  (0.2373005270957947)\n","     | > loss_disc_real_1: 0.25236475467681885  (0.24996980428695678)\n","     | > loss_disc_real_2: 0.23805485665798187  (0.2483074262738228)\n","     | > loss_disc_real_3: 0.26489225029945374  (0.24332501143217086)\n","     | > loss_disc_real_4: 0.2680051028728485  (0.24360248446464539)\n","     | > loss_disc_real_5: 0.29813143610954285  (0.24791834652423858)\n","     | > loss_0: 2.9287760257720947  (2.925837588310242)\n","     | > grad_norm_0: tensor(1.4617, device='cuda:0')  (tensor(2.7434, device='cuda:0'))\n","     | > loss_gen: 1.5655648708343506  (1.5837005615234374)\n","     | > loss_kl: 2.4937708377838135  (2.5388707160949706)\n","     | > loss_feat: 0.676768958568573  (0.7163149356842041)\n","     | > loss_mel: 19.244293212890625  (19.439899444580078)\n","     | > loss_duration: 1.54876708984375  (1.5282397627830506)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 25.529165267944336  (25.807025146484374)\n","     | > grad_norm_1: tensor(58.8068, device='cuda:0')  (tensor(59.0403, device='cuda:0'))\n","     | > current_lr_0: 0.00019940086170989343 \n","     | > current_lr_1: 0.00019940086170989343 \n","     | > step_time: 1.666  (2.493972730636597)\n","     | > loader_time: 0.009  (0.015714406967163086)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.875318765640259  (2.875318765640259)\n","     | > loss_disc_real_0: 0.2244967222213745  (0.2244967222213745)\n","     | > loss_disc_real_1: 0.22760678827762604  (0.22760678827762604)\n","     | > loss_disc_real_2: 0.27258315682411194  (0.27258315682411194)\n","     | > loss_disc_real_3: 0.2136019468307495  (0.2136019468307495)\n","     | > loss_disc_real_4: 0.23117414116859436  (0.23117414116859436)\n","     | > loss_disc_real_5: 0.2218470424413681  (0.2218470424413681)\n","     | > loss_0: 2.875318765640259  (2.875318765640259)\n","     | > loss_gen: 1.5361058712005615  (1.5361058712005615)\n","     | > loss_kl: 2.8795676231384277  (2.8795676231384277)\n","     | > loss_feat: 0.810554027557373  (0.810554027557373)\n","     | > loss_mel: 19.62078094482422  (19.62078094482422)\n","     | > loss_duration: 1.5030514001846313  (1.5030514001846313)\n","     | > loss_1: 26.350059509277344  (26.350059509277344)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.2618863582611084 \u001b[0m(+0.0008263587951660156)\n","     | > avg_loss_disc:\u001b[92m 2.875318765640259 \u001b[0m(-0.09762930870056152)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.2244967222213745 \u001b[0m(-0.0393700897693634)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.22760678827762604 \u001b[0m(+0.00339663028717041)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.27258315682411194 \u001b[0m(+0.006619006395339966)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.2136019468307495 \u001b[0m(-0.041482359170913696)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.23117414116859436 \u001b[0m(-0.04807370901107788)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.2218470424413681 \u001b[0m(-0.02093242108821869)\n","     | > avg_loss_0:\u001b[92m 2.875318765640259 \u001b[0m(-0.09762930870056152)\n","     | > avg_loss_gen:\u001b[92m 1.5361058712005615 \u001b[0m(-0.05477702617645264)\n","     | > avg_loss_kl:\u001b[91m 2.8795676231384277 \u001b[0m(+0.44530153274536133)\n","     | > avg_loss_feat:\u001b[91m 0.810554027557373 \u001b[0m(+0.14226388931274414)\n","     | > avg_loss_mel:\u001b[92m 19.62078094482422 \u001b[0m(-0.4631786346435547)\n","     | > avg_loss_duration:\u001b[92m 1.5030514001846313 \u001b[0m(-0.01094043254852295)\n","     | > avg_loss_1:\u001b[91m 26.350059509277344 \u001b[0m(+0.05866813659667969)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 25/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:00:37) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9824137687683105  (2.9824137687683105)\n","     | > loss_disc_real_0: 0.32873237133026123  (0.32873237133026123)\n","     | > loss_disc_real_1: 0.2725124955177307  (0.2725124955177307)\n","     | > loss_disc_real_2: 0.260123074054718  (0.260123074054718)\n","     | > loss_disc_real_3: 0.24274396896362305  (0.24274396896362305)\n","     | > loss_disc_real_4: 0.2350095808506012  (0.2350095808506012)\n","     | > loss_disc_real_5: 0.2346155196428299  (0.2346155196428299)\n","     | > loss_0: 2.9824137687683105  (2.9824137687683105)\n","     | > loss_gen: 1.6214238405227661  (1.6214238405227661)\n","     | > loss_kl: 2.6024625301361084  (2.6024625301361084)\n","     | > loss_feat: 0.6049642562866211  (0.6049642562866211)\n","     | > loss_mel: 20.112728118896484  (20.112728118896484)\n","     | > loss_duration: 1.5180131196975708  (1.5180131196975708)\n","     | > loss_1: 26.459590911865234  (26.459590911865234)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.2656548023223877 \u001b[0m(+0.003768444061279297)\n","     | > avg_loss_disc:\u001b[91m 2.9824137687683105 \u001b[0m(+0.10709500312805176)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.32873237133026123 \u001b[0m(+0.10423564910888672)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.2725124955177307 \u001b[0m(+0.044905707240104675)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.260123074054718 \u001b[0m(-0.012460082769393921)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.24274396896362305 \u001b[0m(+0.029142022132873535)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.2350095808506012 \u001b[0m(+0.003835439682006836)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2346155196428299 \u001b[0m(+0.012768477201461792)\n","     | > avg_loss_0:\u001b[91m 2.9824137687683105 \u001b[0m(+0.10709500312805176)\n","     | > avg_loss_gen:\u001b[91m 1.6214238405227661 \u001b[0m(+0.08531796932220459)\n","     | > avg_loss_kl:\u001b[92m 2.6024625301361084 \u001b[0m(-0.27710509300231934)\n","     | > avg_loss_feat:\u001b[92m 0.6049642562866211 \u001b[0m(-0.20558977127075195)\n","     | > avg_loss_mel:\u001b[91m 20.112728118896484 \u001b[0m(+0.4919471740722656)\n","     | > avg_loss_duration:\u001b[91m 1.5180131196975708 \u001b[0m(+0.014961719512939453)\n","     | > avg_loss_1:\u001b[91m 26.459590911865234 \u001b[0m(+0.10953140258789062)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 26/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:01:14) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9637811183929443  (2.9637811183929443)\n","     | > loss_disc_real_0: 0.31308889389038086  (0.31308889389038086)\n","     | > loss_disc_real_1: 0.2665185332298279  (0.2665185332298279)\n","     | > loss_disc_real_2: 0.2906396687030792  (0.2906396687030792)\n","     | > loss_disc_real_3: 0.2534014880657196  (0.2534014880657196)\n","     | > loss_disc_real_4: 0.3051079213619232  (0.3051079213619232)\n","     | > loss_disc_real_5: 0.2649035155773163  (0.2649035155773163)\n","     | > loss_0: 2.9637811183929443  (2.9637811183929443)\n","     | > loss_gen: 1.7649986743927002  (1.7649986743927002)\n","     | > loss_kl: 3.1735377311706543  (3.1735377311706543)\n","     | > loss_feat: 0.652828574180603  (0.652828574180603)\n","     | > loss_mel: 19.470895767211914  (19.470895767211914)\n","     | > loss_duration: 1.5134583711624146  (1.5134583711624146)\n","     | > loss_1: 26.575719833374023  (26.575719833374023)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.262282133102417 \u001b[0m(-0.003372669219970703)\n","     | > avg_loss_disc:\u001b[92m 2.9637811183929443 \u001b[0m(-0.01863265037536621)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.31308889389038086 \u001b[0m(-0.01564347743988037)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.2665185332298279 \u001b[0m(-0.005993962287902832)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.2906396687030792 \u001b[0m(+0.030516594648361206)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.2534014880657196 \u001b[0m(+0.010657519102096558)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.3051079213619232 \u001b[0m(+0.07009834051132202)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2649035155773163 \u001b[0m(+0.03028799593448639)\n","     | > avg_loss_0:\u001b[92m 2.9637811183929443 \u001b[0m(-0.01863265037536621)\n","     | > avg_loss_gen:\u001b[91m 1.7649986743927002 \u001b[0m(+0.14357483386993408)\n","     | > avg_loss_kl:\u001b[91m 3.1735377311706543 \u001b[0m(+0.5710752010345459)\n","     | > avg_loss_feat:\u001b[91m 0.652828574180603 \u001b[0m(+0.047864317893981934)\n","     | > avg_loss_mel:\u001b[92m 19.470895767211914 \u001b[0m(-0.6418323516845703)\n","     | > avg_loss_duration:\u001b[92m 1.5134583711624146 \u001b[0m(-0.00455474853515625)\n","     | > avg_loss_1:\u001b[91m 26.575719833374023 \u001b[0m(+0.11612892150878906)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 27/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:01:49) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 22:01:58 -- STEP: 2/11 -- GLOBAL_STEP: 1000300\u001b[0m\n","     | > loss_disc: 2.910715341567993  (2.9136147499084473)\n","     | > loss_disc_real_0: 0.2210160195827484  (0.2189764678478241)\n","     | > loss_disc_real_1: 0.23947057127952576  (0.24932514131069183)\n","     | > loss_disc_real_2: 0.23066282272338867  (0.23904679715633392)\n","     | > loss_disc_real_3: 0.22055697441101074  (0.23905527591705322)\n","     | > loss_disc_real_4: 0.19355179369449615  (0.2288493886590004)\n","     | > loss_disc_real_5: 0.2955645024776459  (0.2529628500342369)\n","     | > loss_0: 2.910715341567993  (2.9136147499084473)\n","     | > grad_norm_0: tensor(2.1862, device='cuda:0')  (tensor(2.2116, device='cuda:0'))\n","     | > loss_gen: 1.6097166538238525  (1.5739630460739136)\n","     | > loss_kl: 2.555311679840088  (2.53728187084198)\n","     | > loss_feat: 0.8019027709960938  (0.8065866529941559)\n","     | > loss_mel: 19.780864715576172  (19.493772506713867)\n","     | > loss_duration: 1.4385900497436523  (1.462453007698059)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 26.186386108398438  (25.87405776977539)\n","     | > grad_norm_1: tensor(63.7963, device='cuda:0')  (tensor(74.8605, device='cuda:0'))\n","     | > current_lr_0: 0.00019932609573327815 \n","     | > current_lr_1: 0.00019932609573327815 \n","     | > step_time: 2.2443  (2.2495559453964233)\n","     | > loader_time: 0.0141  (0.013423919677734375)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.912461042404175  (2.912461042404175)\n","     | > loss_disc_real_0: 0.22622466087341309  (0.22622466087341309)\n","     | > loss_disc_real_1: 0.19870823621749878  (0.19870823621749878)\n","     | > loss_disc_real_2: 0.2749604880809784  (0.2749604880809784)\n","     | > loss_disc_real_3: 0.2625865638256073  (0.2625865638256073)\n","     | > loss_disc_real_4: 0.2874128818511963  (0.2874128818511963)\n","     | > loss_disc_real_5: 0.270067423582077  (0.270067423582077)\n","     | > loss_0: 2.912461042404175  (2.912461042404175)\n","     | > loss_gen: 1.640678882598877  (1.640678882598877)\n","     | > loss_kl: 2.2640388011932373  (2.2640388011932373)\n","     | > loss_feat: 0.7313413619995117  (0.7313413619995117)\n","     | > loss_mel: 19.880847930908203  (19.880847930908203)\n","     | > loss_duration: 1.5257899761199951  (1.5257899761199951)\n","     | > loss_1: 26.042695999145508  (26.042695999145508)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.2610173225402832 \u001b[0m(-0.001264810562133789)\n","     | > avg_loss_disc:\u001b[92m 2.912461042404175 \u001b[0m(-0.05132007598876953)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.22622466087341309 \u001b[0m(-0.08686423301696777)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.19870823621749878 \u001b[0m(-0.0678102970123291)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2749604880809784 \u001b[0m(-0.01567918062210083)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.2625865638256073 \u001b[0m(+0.009185075759887695)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.2874128818511963 \u001b[0m(-0.01769503951072693)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.270067423582077 \u001b[0m(+0.005163908004760742)\n","     | > avg_loss_0:\u001b[92m 2.912461042404175 \u001b[0m(-0.05132007598876953)\n","     | > avg_loss_gen:\u001b[92m 1.640678882598877 \u001b[0m(-0.12431979179382324)\n","     | > avg_loss_kl:\u001b[92m 2.2640388011932373 \u001b[0m(-0.909498929977417)\n","     | > avg_loss_feat:\u001b[91m 0.7313413619995117 \u001b[0m(+0.07851278781890869)\n","     | > avg_loss_mel:\u001b[91m 19.880847930908203 \u001b[0m(+0.40995216369628906)\n","     | > avg_loss_duration:\u001b[91m 1.5257899761199951 \u001b[0m(+0.012331604957580566)\n","     | > avg_loss_1:\u001b[92m 26.042695999145508 \u001b[0m(-0.5330238342285156)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 28/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:02:26) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9814772605895996  (2.9814772605895996)\n","     | > loss_disc_real_0: 0.3047644793987274  (0.3047644793987274)\n","     | > loss_disc_real_1: 0.29663804173469543  (0.29663804173469543)\n","     | > loss_disc_real_2: 0.3150409162044525  (0.3150409162044525)\n","     | > loss_disc_real_3: 0.33992013335227966  (0.33992013335227966)\n","     | > loss_disc_real_4: 0.300812304019928  (0.300812304019928)\n","     | > loss_disc_real_5: 0.3458592891693115  (0.3458592891693115)\n","     | > loss_0: 2.9814772605895996  (2.9814772605895996)\n","     | > loss_gen: 2.021421432495117  (2.021421432495117)\n","     | > loss_kl: 2.8268823623657227  (2.8268823623657227)\n","     | > loss_feat: 0.726891279220581  (0.726891279220581)\n","     | > loss_mel: 18.19141960144043  (18.19141960144043)\n","     | > loss_duration: 1.5303337574005127  (1.5303337574005127)\n","     | > loss_1: 25.29694938659668  (25.29694938659668)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.26983094215393066 \u001b[0m(+0.008813619613647461)\n","     | > avg_loss_disc:\u001b[91m 2.9814772605895996 \u001b[0m(+0.0690162181854248)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.3047644793987274 \u001b[0m(+0.07853981852531433)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.29663804173469543 \u001b[0m(+0.09792980551719666)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.3150409162044525 \u001b[0m(+0.04008042812347412)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.33992013335227966 \u001b[0m(+0.07733356952667236)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.300812304019928 \u001b[0m(+0.01339942216873169)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.3458592891693115 \u001b[0m(+0.0757918655872345)\n","     | > avg_loss_0:\u001b[91m 2.9814772605895996 \u001b[0m(+0.0690162181854248)\n","     | > avg_loss_gen:\u001b[91m 2.021421432495117 \u001b[0m(+0.38074254989624023)\n","     | > avg_loss_kl:\u001b[91m 2.8268823623657227 \u001b[0m(+0.5628435611724854)\n","     | > avg_loss_feat:\u001b[92m 0.726891279220581 \u001b[0m(-0.004450082778930664)\n","     | > avg_loss_mel:\u001b[92m 18.19141960144043 \u001b[0m(-1.6894283294677734)\n","     | > avg_loss_duration:\u001b[91m 1.5303337574005127 \u001b[0m(+0.004543781280517578)\n","     | > avg_loss_1:\u001b[92m 25.29694938659668 \u001b[0m(-0.7457466125488281)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 29/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:03:02) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 22:03:18 -- STEP: 5/11 -- GLOBAL_STEP: 1000325\u001b[0m\n","     | > loss_disc: 2.9777750968933105  (2.9535614490509032)\n","     | > loss_disc_real_0: 0.224771648645401  (0.22745420634746552)\n","     | > loss_disc_real_1: 0.19565188884735107  (0.23274147510528564)\n","     | > loss_disc_real_2: 0.21095803380012512  (0.24051829278469086)\n","     | > loss_disc_real_3: 0.28345242142677307  (0.24084776937961577)\n","     | > loss_disc_real_4: 0.20997917652130127  (0.23468801379203796)\n","     | > loss_disc_real_5: 0.1946670413017273  (0.23656972050666808)\n","     | > loss_0: 2.9777750968933105  (2.9535614490509032)\n","     | > grad_norm_0: tensor(5.0518, device='cuda:0')  (tensor(5.4872, device='cuda:0'))\n","     | > loss_gen: 1.8427734375  (1.6175453424453736)\n","     | > loss_kl: 2.4919426441192627  (2.4329051971435547)\n","     | > loss_feat: 0.9329222440719604  (0.8077190756797791)\n","     | > loss_mel: 20.337255477905273  (19.696233367919923)\n","     | > loss_duration: 1.5554087162017822  (1.477308988571167)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 27.160301208496094  (26.031712341308594)\n","     | > grad_norm_1: tensor(62.3895, device='cuda:0')  (tensor(85.8416, device='cuda:0'))\n","     | > current_lr_0: 0.00019927626732381507 \n","     | > current_lr_1: 0.00019927626732381507 \n","     | > step_time: 2.8363  (2.378785562515259)\n","     | > loader_time: 0.0183  (0.014412975311279297)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 3.008446216583252  (3.008446216583252)\n","     | > loss_disc_real_0: 0.2706240117549896  (0.2706240117549896)\n","     | > loss_disc_real_1: 0.27644556760787964  (0.27644556760787964)\n","     | > loss_disc_real_2: 0.2663685381412506  (0.2663685381412506)\n","     | > loss_disc_real_3: 0.25604379177093506  (0.25604379177093506)\n","     | > loss_disc_real_4: 0.24161994457244873  (0.24161994457244873)\n","     | > loss_disc_real_5: 0.2573011517524719  (0.2573011517524719)\n","     | > loss_0: 3.008446216583252  (3.008446216583252)\n","     | > loss_gen: 1.6599363088607788  (1.6599363088607788)\n","     | > loss_kl: 2.720855474472046  (2.720855474472046)\n","     | > loss_feat: 0.9789307713508606  (0.9789307713508606)\n","     | > loss_mel: 20.34297752380371  (20.34297752380371)\n","     | > loss_duration: 1.526612639427185  (1.526612639427185)\n","     | > loss_1: 27.229312896728516  (27.229312896728516)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.27335500717163086 \u001b[0m(+0.0035240650177001953)\n","     | > avg_loss_disc:\u001b[91m 3.008446216583252 \u001b[0m(+0.026968955993652344)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.2706240117549896 \u001b[0m(-0.03414046764373779)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.27644556760787964 \u001b[0m(-0.020192474126815796)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2663685381412506 \u001b[0m(-0.048672378063201904)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.25604379177093506 \u001b[0m(-0.0838763415813446)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.24161994457244873 \u001b[0m(-0.05919235944747925)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.2573011517524719 \u001b[0m(-0.0885581374168396)\n","     | > avg_loss_0:\u001b[91m 3.008446216583252 \u001b[0m(+0.026968955993652344)\n","     | > avg_loss_gen:\u001b[92m 1.6599363088607788 \u001b[0m(-0.3614851236343384)\n","     | > avg_loss_kl:\u001b[92m 2.720855474472046 \u001b[0m(-0.10602688789367676)\n","     | > avg_loss_feat:\u001b[91m 0.9789307713508606 \u001b[0m(+0.25203949213027954)\n","     | > avg_loss_mel:\u001b[91m 20.34297752380371 \u001b[0m(+2.1515579223632812)\n","     | > avg_loss_duration:\u001b[92m 1.526612639427185 \u001b[0m(-0.0037211179733276367)\n","     | > avg_loss_1:\u001b[91m 27.229312896728516 \u001b[0m(+1.932363510131836)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 30/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:03:38) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9115514755249023  (2.9115514755249023)\n","     | > loss_disc_real_0: 0.1984894722700119  (0.1984894722700119)\n","     | > loss_disc_real_1: 0.26650533080101013  (0.26650533080101013)\n","     | > loss_disc_real_2: 0.2622983753681183  (0.2622983753681183)\n","     | > loss_disc_real_3: 0.2466466724872589  (0.2466466724872589)\n","     | > loss_disc_real_4: 0.2930765450000763  (0.2930765450000763)\n","     | > loss_disc_real_5: 0.24172236025333405  (0.24172236025333405)\n","     | > loss_0: 2.9115514755249023  (2.9115514755249023)\n","     | > loss_gen: 1.6253306865692139  (1.6253306865692139)\n","     | > loss_kl: 2.308079242706299  (2.308079242706299)\n","     | > loss_feat: 0.748001217842102  (0.748001217842102)\n","     | > loss_mel: 19.583860397338867  (19.583860397338867)\n","     | > loss_duration: 1.5392040014266968  (1.5392040014266968)\n","     | > loss_1: 25.804473876953125  (25.804473876953125)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.2651345729827881 \u001b[0m(-0.008220434188842773)\n","     | > avg_loss_disc:\u001b[92m 2.9115514755249023 \u001b[0m(-0.09689474105834961)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.1984894722700119 \u001b[0m(-0.07213453948497772)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.26650533080101013 \u001b[0m(-0.009940236806869507)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2622983753681183 \u001b[0m(-0.004070162773132324)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.2466466724872589 \u001b[0m(-0.009397119283676147)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.2930765450000763 \u001b[0m(+0.051456600427627563)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.24172236025333405 \u001b[0m(-0.015578791499137878)\n","     | > avg_loss_0:\u001b[92m 2.9115514755249023 \u001b[0m(-0.09689474105834961)\n","     | > avg_loss_gen:\u001b[92m 1.6253306865692139 \u001b[0m(-0.03460562229156494)\n","     | > avg_loss_kl:\u001b[92m 2.308079242706299 \u001b[0m(-0.41277623176574707)\n","     | > avg_loss_feat:\u001b[92m 0.748001217842102 \u001b[0m(-0.23092955350875854)\n","     | > avg_loss_mel:\u001b[92m 19.583860397338867 \u001b[0m(-0.7591171264648438)\n","     | > avg_loss_duration:\u001b[91m 1.5392040014266968 \u001b[0m(+0.012591361999511719)\n","     | > avg_loss_1:\u001b[92m 25.804473876953125 \u001b[0m(-1.4248390197753906)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 31/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:04:14) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 22:04:39 -- STEP: 8/11 -- GLOBAL_STEP: 1000350\u001b[0m\n","     | > loss_disc: 2.9416110515594482  (2.930147260427475)\n","     | > loss_disc_real_0: 0.21829605102539062  (0.24106758646667004)\n","     | > loss_disc_real_1: 0.26728829741477966  (0.24773027189075947)\n","     | > loss_disc_real_2: 0.27273085713386536  (0.2488051149994135)\n","     | > loss_disc_real_3: 0.23997251689434052  (0.24378922954201698)\n","     | > loss_disc_real_4: 0.27448251843452454  (0.24373763985931873)\n","     | > loss_disc_real_5: 0.27429017424583435  (0.25001117028295994)\n","     | > loss_0: 2.9416110515594482  (2.930147260427475)\n","     | > grad_norm_0: tensor(2.4003, device='cuda:0')  (tensor(2.4284, device='cuda:0'))\n","     | > loss_gen: 1.601588249206543  (1.5847783386707306)\n","     | > loss_kl: 2.414311170578003  (2.5199569761753082)\n","     | > loss_feat: 0.7672911882400513  (0.7953999191522598)\n","     | > loss_mel: 19.114578247070312  (19.528666257858276)\n","     | > loss_duration: 1.5534815788269043  (1.5094560980796814)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 25.451251983642578  (25.938257694244385)\n","     | > grad_norm_1: tensor(80.5482, device='cuda:0')  (tensor(99.4732, device='cuda:0'))\n","     | > current_lr_0: 0.00019922645137067577 \n","     | > current_lr_1: 0.00019922645137067577 \n","     | > step_time: 2.8573  (2.5518771409988403)\n","     | > loader_time: 0.0202  (0.016261011362075806)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.8757622241973877  (2.8757622241973877)\n","     | > loss_disc_real_0: 0.2140822857618332  (0.2140822857618332)\n","     | > loss_disc_real_1: 0.2591323256492615  (0.2591323256492615)\n","     | > loss_disc_real_2: 0.25874805450439453  (0.25874805450439453)\n","     | > loss_disc_real_3: 0.19525468349456787  (0.19525468349456787)\n","     | > loss_disc_real_4: 0.24360467493534088  (0.24360467493534088)\n","     | > loss_disc_real_5: 0.23699025809764862  (0.23699025809764862)\n","     | > loss_0: 2.8757622241973877  (2.8757622241973877)\n","     | > loss_gen: 1.5575470924377441  (1.5575470924377441)\n","     | > loss_kl: 2.9261274337768555  (2.9261274337768555)\n","     | > loss_feat: 0.8896982669830322  (0.8896982669830322)\n","     | > loss_mel: 21.88294792175293  (21.88294792175293)\n","     | > loss_duration: 1.5466477870941162  (1.5466477870941162)\n","     | > loss_1: 28.802968978881836  (28.802968978881836)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.2729206085205078 \u001b[0m(+0.0077860355377197266)\n","     | > avg_loss_disc:\u001b[92m 2.8757622241973877 \u001b[0m(-0.03578925132751465)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.2140822857618332 \u001b[0m(+0.015592813491821289)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.2591323256492615 \u001b[0m(-0.007373005151748657)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.25874805450439453 \u001b[0m(-0.003550320863723755)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.19525468349456787 \u001b[0m(-0.05139198899269104)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.24360467493534088 \u001b[0m(-0.04947187006473541)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.23699025809764862 \u001b[0m(-0.004732102155685425)\n","     | > avg_loss_0:\u001b[92m 2.8757622241973877 \u001b[0m(-0.03578925132751465)\n","     | > avg_loss_gen:\u001b[92m 1.5575470924377441 \u001b[0m(-0.06778359413146973)\n","     | > avg_loss_kl:\u001b[91m 2.9261274337768555 \u001b[0m(+0.6180481910705566)\n","     | > avg_loss_feat:\u001b[91m 0.8896982669830322 \u001b[0m(+0.14169704914093018)\n","     | > avg_loss_mel:\u001b[91m 21.88294792175293 \u001b[0m(+2.2990875244140625)\n","     | > avg_loss_duration:\u001b[91m 1.5466477870941162 \u001b[0m(+0.007443785667419434)\n","     | > avg_loss_1:\u001b[91m 28.802968978881836 \u001b[0m(+2.998495101928711)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 32/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:04:50) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9634180068969727  (2.9634180068969727)\n","     | > loss_disc_real_0: 0.29247361421585083  (0.29247361421585083)\n","     | > loss_disc_real_1: 0.27351313829421997  (0.27351313829421997)\n","     | > loss_disc_real_2: 0.27040553092956543  (0.27040553092956543)\n","     | > loss_disc_real_3: 0.26582589745521545  (0.26582589745521545)\n","     | > loss_disc_real_4: 0.26617103815078735  (0.26617103815078735)\n","     | > loss_disc_real_5: 0.29616352915763855  (0.29616352915763855)\n","     | > loss_0: 2.9634180068969727  (2.9634180068969727)\n","     | > loss_gen: 1.7478927373886108  (1.7478927373886108)\n","     | > loss_kl: 2.3084537982940674  (2.3084537982940674)\n","     | > loss_feat: 0.5880008935928345  (0.5880008935928345)\n","     | > loss_mel: 20.904382705688477  (20.904382705688477)\n","     | > loss_duration: 1.53668212890625  (1.53668212890625)\n","     | > loss_1: 27.085412979125977  (27.085412979125977)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.2723073959350586 \u001b[0m(-0.0006132125854492188)\n","     | > avg_loss_disc:\u001b[91m 2.9634180068969727 \u001b[0m(+0.08765578269958496)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.29247361421585083 \u001b[0m(+0.07839132845401764)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.27351313829421997 \u001b[0m(+0.014380812644958496)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.27040553092956543 \u001b[0m(+0.011657476425170898)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.26582589745521545 \u001b[0m(+0.07057121396064758)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.26617103815078735 \u001b[0m(+0.022566363215446472)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.29616352915763855 \u001b[0m(+0.05917327105998993)\n","     | > avg_loss_0:\u001b[91m 2.9634180068969727 \u001b[0m(+0.08765578269958496)\n","     | > avg_loss_gen:\u001b[91m 1.7478927373886108 \u001b[0m(+0.1903456449508667)\n","     | > avg_loss_kl:\u001b[92m 2.3084537982940674 \u001b[0m(-0.6176736354827881)\n","     | > avg_loss_feat:\u001b[92m 0.5880008935928345 \u001b[0m(-0.30169737339019775)\n","     | > avg_loss_mel:\u001b[92m 20.904382705688477 \u001b[0m(-0.9785652160644531)\n","     | > avg_loss_duration:\u001b[92m 1.53668212890625 \u001b[0m(-0.009965658187866211)\n","     | > avg_loss_1:\u001b[92m 27.085412979125977 \u001b[0m(-1.7175559997558594)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 33/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:05:26) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9506936073303223  (2.9506936073303223)\n","     | > loss_disc_real_0: 0.2709423303604126  (0.2709423303604126)\n","     | > loss_disc_real_1: 0.2959557771682739  (0.2959557771682739)\n","     | > loss_disc_real_2: 0.30024468898773193  (0.30024468898773193)\n","     | > loss_disc_real_3: 0.2571697533130646  (0.2571697533130646)\n","     | > loss_disc_real_4: 0.2745305299758911  (0.2745305299758911)\n","     | > loss_disc_real_5: 0.2800584137439728  (0.2800584137439728)\n","     | > loss_0: 2.9506936073303223  (2.9506936073303223)\n","     | > loss_gen: 1.783839464187622  (1.783839464187622)\n","     | > loss_kl: 2.8754265308380127  (2.8754265308380127)\n","     | > loss_feat: 0.7102001309394836  (0.7102001309394836)\n","     | > loss_mel: 18.761505126953125  (18.761505126953125)\n","     | > loss_duration: 1.5466930866241455  (1.5466930866241455)\n","     | > loss_1: 25.67766571044922  (25.67766571044922)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.26798152923583984 \u001b[0m(-0.00432586669921875)\n","     | > avg_loss_disc:\u001b[92m 2.9506936073303223 \u001b[0m(-0.01272439956665039)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.2709423303604126 \u001b[0m(-0.021531283855438232)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.2959557771682739 \u001b[0m(+0.022442638874053955)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.30024468898773193 \u001b[0m(+0.029839158058166504)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.2571697533130646 \u001b[0m(-0.008656144142150879)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.2745305299758911 \u001b[0m(+0.00835949182510376)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.2800584137439728 \u001b[0m(-0.01610511541366577)\n","     | > avg_loss_0:\u001b[92m 2.9506936073303223 \u001b[0m(-0.01272439956665039)\n","     | > avg_loss_gen:\u001b[91m 1.783839464187622 \u001b[0m(+0.03594672679901123)\n","     | > avg_loss_kl:\u001b[91m 2.8754265308380127 \u001b[0m(+0.5669727325439453)\n","     | > avg_loss_feat:\u001b[91m 0.7102001309394836 \u001b[0m(+0.12219923734664917)\n","     | > avg_loss_mel:\u001b[92m 18.761505126953125 \u001b[0m(-2.1428775787353516)\n","     | > avg_loss_duration:\u001b[91m 1.5466930866241455 \u001b[0m(+0.010010957717895508)\n","     | > avg_loss_1:\u001b[92m 25.67766571044922 \u001b[0m(-1.4077472686767578)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 34/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:06:03) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 22:06:07 -- STEP: 0/11 -- GLOBAL_STEP: 1000375\u001b[0m\n","     | > loss_disc: 2.9596633911132812  (2.9596633911132812)\n","     | > loss_disc_real_0: 0.23302142322063446  (0.23302142322063446)\n","     | > loss_disc_real_1: 0.28811657428741455  (0.28811657428741455)\n","     | > loss_disc_real_2: 0.29331663250923157  (0.29331663250923157)\n","     | > loss_disc_real_3: 0.25336992740631104  (0.25336992740631104)\n","     | > loss_disc_real_4: 0.27937403321266174  (0.27937403321266174)\n","     | > loss_disc_real_5: 0.27837318181991577  (0.27837318181991577)\n","     | > loss_0: 2.9596633911132812  (2.9596633911132812)\n","     | > grad_norm_0: tensor(2.1024, device='cuda:0')  (tensor(2.1024, device='cuda:0'))\n","     | > loss_gen: 1.6569756269454956  (1.6569756269454956)\n","     | > loss_kl: 2.34672474861145  (2.34672474861145)\n","     | > loss_feat: 0.8553303480148315  (0.8553303480148315)\n","     | > loss_mel: 19.540794372558594  (19.540794372558594)\n","     | > loss_duration: 1.4672682285308838  (1.4672682285308838)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 25.86709213256836  (25.86709213256836)\n","     | > grad_norm_1: tensor(47.8446, device='cuda:0')  (tensor(47.8446, device='cuda:0'))\n","     | > current_lr_0: 0.00019915175078976256 \n","     | > current_lr_1: 0.00019915175078976256 \n","     | > step_time: 2.5231  (2.5230631828308105)\n","     | > loader_time: 1.939  (1.9390099048614502)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9365506172180176  (2.9365506172180176)\n","     | > loss_disc_real_0: 0.2605668604373932  (0.2605668604373932)\n","     | > loss_disc_real_1: 0.2800184190273285  (0.2800184190273285)\n","     | > loss_disc_real_2: 0.2558065354824066  (0.2558065354824066)\n","     | > loss_disc_real_3: 0.255400151014328  (0.255400151014328)\n","     | > loss_disc_real_4: 0.24137522280216217  (0.24137522280216217)\n","     | > loss_disc_real_5: 0.23552684485912323  (0.23552684485912323)\n","     | > loss_0: 2.9365506172180176  (2.9365506172180176)\n","     | > loss_gen: 1.6119986772537231  (1.6119986772537231)\n","     | > loss_kl: 3.063183069229126  (3.063183069229126)\n","     | > loss_feat: 0.5712215900421143  (0.5712215900421143)\n","     | > loss_mel: 19.549741744995117  (19.549741744995117)\n","     | > loss_duration: 1.5408897399902344  (1.5408897399902344)\n","     | > loss_1: 26.3370361328125  (26.3370361328125)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.27729201316833496 \u001b[0m(+0.009310483932495117)\n","     | > avg_loss_disc:\u001b[92m 2.9365506172180176 \u001b[0m(-0.014142990112304688)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.2605668604373932 \u001b[0m(-0.01037546992301941)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.2800184190273285 \u001b[0m(-0.015937358140945435)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2558065354824066 \u001b[0m(-0.04443815350532532)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.255400151014328 \u001b[0m(-0.0017696022987365723)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.24137522280216217 \u001b[0m(-0.03315530717372894)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.23552684485912323 \u001b[0m(-0.04453156888484955)\n","     | > avg_loss_0:\u001b[92m 2.9365506172180176 \u001b[0m(-0.014142990112304688)\n","     | > avg_loss_gen:\u001b[92m 1.6119986772537231 \u001b[0m(-0.17184078693389893)\n","     | > avg_loss_kl:\u001b[91m 3.063183069229126 \u001b[0m(+0.18775653839111328)\n","     | > avg_loss_feat:\u001b[92m 0.5712215900421143 \u001b[0m(-0.13897854089736938)\n","     | > avg_loss_mel:\u001b[91m 19.549741744995117 \u001b[0m(+0.7882366180419922)\n","     | > avg_loss_duration:\u001b[92m 1.5408897399902344 \u001b[0m(-0.005803346633911133)\n","     | > avg_loss_1:\u001b[91m 26.3370361328125 \u001b[0m(+0.6593704223632812)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 35/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:06:39) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.888699531555176  (2.888699531555176)\n","     | > loss_disc_real_0: 0.2097964584827423  (0.2097964584827423)\n","     | > loss_disc_real_1: 0.24692553281784058  (0.24692553281784058)\n","     | > loss_disc_real_2: 0.19846728444099426  (0.19846728444099426)\n","     | > loss_disc_real_3: 0.212082639336586  (0.212082639336586)\n","     | > loss_disc_real_4: 0.20351439714431763  (0.20351439714431763)\n","     | > loss_disc_real_5: 0.23981279134750366  (0.23981279134750366)\n","     | > loss_0: 2.888699531555176  (2.888699531555176)\n","     | > loss_gen: 1.4452937841415405  (1.4452937841415405)\n","     | > loss_kl: 2.3857221603393555  (2.3857221603393555)\n","     | > loss_feat: 0.9825959801673889  (0.9825959801673889)\n","     | > loss_mel: 21.42742347717285  (21.42742347717285)\n","     | > loss_duration: 1.532580018043518  (1.532580018043518)\n","     | > loss_1: 27.77361488342285  (27.77361488342285)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.29258036613464355 \u001b[0m(+0.015288352966308594)\n","     | > avg_loss_disc:\u001b[92m 2.888699531555176 \u001b[0m(-0.0478510856628418)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.2097964584827423 \u001b[0m(-0.05077040195465088)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.24692553281784058 \u001b[0m(-0.033092886209487915)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.19846728444099426 \u001b[0m(-0.057339251041412354)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.212082639336586 \u001b[0m(-0.043317511677742004)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.20351439714431763 \u001b[0m(-0.03786082565784454)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.23981279134750366 \u001b[0m(+0.004285946488380432)\n","     | > avg_loss_0:\u001b[92m 2.888699531555176 \u001b[0m(-0.0478510856628418)\n","     | > avg_loss_gen:\u001b[92m 1.4452937841415405 \u001b[0m(-0.16670489311218262)\n","     | > avg_loss_kl:\u001b[92m 2.3857221603393555 \u001b[0m(-0.6774609088897705)\n","     | > avg_loss_feat:\u001b[91m 0.9825959801673889 \u001b[0m(+0.41137439012527466)\n","     | > avg_loss_mel:\u001b[91m 21.42742347717285 \u001b[0m(+1.8776817321777344)\n","     | > avg_loss_duration:\u001b[92m 1.532580018043518 \u001b[0m(-0.008309721946716309)\n","     | > avg_loss_1:\u001b[91m 27.77361488342285 \u001b[0m(+1.4365787506103516)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 36/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:07:15) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 22:07:27 -- STEP: 3/11 -- GLOBAL_STEP: 1000400\u001b[0m\n","     | > loss_disc: 2.9615559577941895  (2.968012015024821)\n","     | > loss_disc_real_0: 0.11601090431213379  (0.2275938093662262)\n","     | > loss_disc_real_1: 0.23656651377677917  (0.24461005131403604)\n","     | > loss_disc_real_2: 0.19304654002189636  (0.2539350688457489)\n","     | > loss_disc_real_3: 0.21971087157726288  (0.2622507760922114)\n","     | > loss_disc_real_4: 0.20919114351272583  (0.25251771012942)\n","     | > loss_disc_real_5: 0.24325580894947052  (0.24813224375247955)\n","     | > loss_0: 2.9615559577941895  (2.968012015024821)\n","     | > grad_norm_0: tensor(22.1550, device='cuda:0')  (tensor(13.5804, device='cuda:0'))\n","     | > loss_gen: 1.6500684022903442  (1.6031891504923503)\n","     | > loss_kl: 2.477536916732788  (2.4413010279337564)\n","     | > loss_feat: 0.9173552393913269  (0.8313706715901693)\n","     | > loss_mel: 19.30944061279297  (19.2782408396403)\n","     | > loss_duration: 1.471733808517456  (1.4620782534281414)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 25.826133728027344  (25.61617914835612)\n","     | > grad_norm_1: tensor(109.1146, device='cuda:0')  (tensor(81.3505, device='cuda:0'))\n","     | > current_lr_0: 0.0001991019659638112 \n","     | > current_lr_1: 0.0001991019659638112 \n","     | > step_time: 2.263  (2.2733558813730874)\n","     | > loader_time: 0.014  (0.014121611913045248)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9283437728881836  (2.9283437728881836)\n","     | > loss_disc_real_0: 0.28247949481010437  (0.28247949481010437)\n","     | > loss_disc_real_1: 0.27456265687942505  (0.27456265687942505)\n","     | > loss_disc_real_2: 0.2343599498271942  (0.2343599498271942)\n","     | > loss_disc_real_3: 0.2206781804561615  (0.2206781804561615)\n","     | > loss_disc_real_4: 0.23956631124019623  (0.23956631124019623)\n","     | > loss_disc_real_5: 0.2652316391468048  (0.2652316391468048)\n","     | > loss_0: 2.9283437728881836  (2.9283437728881836)\n","     | > loss_gen: 1.634516716003418  (1.634516716003418)\n","     | > loss_kl: 2.719149112701416  (2.719149112701416)\n","     | > loss_feat: 0.9332974553108215  (0.9332974553108215)\n","     | > loss_mel: 20.425430297851562  (20.425430297851562)\n","     | > loss_duration: 1.5519698858261108  (1.5519698858261108)\n","     | > loss_1: 27.26436424255371  (27.26436424255371)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.2772970199584961 \u001b[0m(-0.015283346176147461)\n","     | > avg_loss_disc:\u001b[91m 2.9283437728881836 \u001b[0m(+0.03964424133300781)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.28247949481010437 \u001b[0m(+0.07268303632736206)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.27456265687942505 \u001b[0m(+0.027637124061584473)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.2343599498271942 \u001b[0m(+0.03589266538619995)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.2206781804561615 \u001b[0m(+0.0085955411195755)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.23956631124019623 \u001b[0m(+0.0360519140958786)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2652316391468048 \u001b[0m(+0.025418847799301147)\n","     | > avg_loss_0:\u001b[91m 2.9283437728881836 \u001b[0m(+0.03964424133300781)\n","     | > avg_loss_gen:\u001b[91m 1.634516716003418 \u001b[0m(+0.18922293186187744)\n","     | > avg_loss_kl:\u001b[91m 2.719149112701416 \u001b[0m(+0.33342695236206055)\n","     | > avg_loss_feat:\u001b[92m 0.9332974553108215 \u001b[0m(-0.04929852485656738)\n","     | > avg_loss_mel:\u001b[92m 20.425430297851562 \u001b[0m(-1.001993179321289)\n","     | > avg_loss_duration:\u001b[91m 1.5519698858261108 \u001b[0m(+0.019389867782592773)\n","     | > avg_loss_1:\u001b[92m 27.26436424255371 \u001b[0m(-0.5092506408691406)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 37/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:07:52) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9492106437683105  (2.9492106437683105)\n","     | > loss_disc_real_0: 0.2619536519050598  (0.2619536519050598)\n","     | > loss_disc_real_1: 0.3167840242385864  (0.3167840242385864)\n","     | > loss_disc_real_2: 0.22456373274326324  (0.22456373274326324)\n","     | > loss_disc_real_3: 0.28813210129737854  (0.28813210129737854)\n","     | > loss_disc_real_4: 0.3037955164909363  (0.3037955164909363)\n","     | > loss_disc_real_5: 0.2912972867488861  (0.2912972867488861)\n","     | > loss_0: 2.9492106437683105  (2.9492106437683105)\n","     | > loss_gen: 1.7864220142364502  (1.7864220142364502)\n","     | > loss_kl: 2.4650373458862305  (2.4650373458862305)\n","     | > loss_feat: 0.6487987041473389  (0.6487987041473389)\n","     | > loss_mel: 18.956520080566406  (18.956520080566406)\n","     | > loss_duration: 1.5295352935791016  (1.5295352935791016)\n","     | > loss_1: 25.386314392089844  (25.386314392089844)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.27607226371765137 \u001b[0m(-0.0012247562408447266)\n","     | > avg_loss_disc:\u001b[91m 2.9492106437683105 \u001b[0m(+0.020866870880126953)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.2619536519050598 \u001b[0m(-0.020525842905044556)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.3167840242385864 \u001b[0m(+0.04222136735916138)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.22456373274326324 \u001b[0m(-0.00979621708393097)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.28813210129737854 \u001b[0m(+0.06745392084121704)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.3037955164909363 \u001b[0m(+0.06422920525074005)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2912972867488861 \u001b[0m(+0.0260656476020813)\n","     | > avg_loss_0:\u001b[91m 2.9492106437683105 \u001b[0m(+0.020866870880126953)\n","     | > avg_loss_gen:\u001b[91m 1.7864220142364502 \u001b[0m(+0.15190529823303223)\n","     | > avg_loss_kl:\u001b[92m 2.4650373458862305 \u001b[0m(-0.25411176681518555)\n","     | > avg_loss_feat:\u001b[92m 0.6487987041473389 \u001b[0m(-0.28449875116348267)\n","     | > avg_loss_mel:\u001b[92m 18.956520080566406 \u001b[0m(-1.4689102172851562)\n","     | > avg_loss_duration:\u001b[92m 1.5295352935791016 \u001b[0m(-0.022434592247009277)\n","     | > avg_loss_1:\u001b[92m 25.386314392089844 \u001b[0m(-1.8780498504638672)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 38/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:08:27) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 22:08:47 -- STEP: 6/11 -- GLOBAL_STEP: 1000425\u001b[0m\n","     | > loss_disc: 2.969076156616211  (2.927014112472534)\n","     | > loss_disc_real_0: 0.29863783717155457  (0.23899311075607935)\n","     | > loss_disc_real_1: 0.2843315601348877  (0.24478204300006232)\n","     | > loss_disc_real_2: 0.21671220660209656  (0.2524191364645958)\n","     | > loss_disc_real_3: 0.25932931900024414  (0.24570236603418985)\n","     | > loss_disc_real_4: 0.24653831124305725  (0.2450841764609019)\n","     | > loss_disc_real_5: 0.2653302848339081  (0.2530851165453593)\n","     | > loss_0: 2.969076156616211  (2.927014112472534)\n","     | > grad_norm_0: tensor(8.3751, device='cuda:0')  (tensor(3.8757, device='cuda:0'))\n","     | > loss_gen: 1.5054755210876465  (1.5799594918886821)\n","     | > loss_kl: 2.3998780250549316  (2.4087465604146323)\n","     | > loss_feat: 0.733899712562561  (0.7814321319262186)\n","     | > loss_mel: 19.16238784790039  (19.23807144165039)\n","     | > loss_duration: 1.5773000717163086  (1.486033062140147)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 25.37894058227539  (25.494242668151855)\n","     | > grad_norm_1: tensor(92.2717, device='cuda:0')  (tensor(83.5332, device='cuda:0'))\n","     | > current_lr_0: 0.00019905219358328844 \n","     | > current_lr_1: 0.00019905219358328844 \n","     | > step_time: 2.8463  (2.461753805478414)\n","     | > loader_time: 0.0189  (0.015381415685017904)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9055824279785156  (2.9055824279785156)\n","     | > loss_disc_real_0: 0.22639939188957214  (0.22639939188957214)\n","     | > loss_disc_real_1: 0.2542871832847595  (0.2542871832847595)\n","     | > loss_disc_real_2: 0.2685108780860901  (0.2685108780860901)\n","     | > loss_disc_real_3: 0.17002829909324646  (0.17002829909324646)\n","     | > loss_disc_real_4: 0.22337043285369873  (0.22337043285369873)\n","     | > loss_disc_real_5: 0.23627707362174988  (0.23627707362174988)\n","     | > loss_0: 2.9055824279785156  (2.9055824279785156)\n","     | > loss_gen: 1.4960826635360718  (1.4960826635360718)\n","     | > loss_kl: 2.5035502910614014  (2.5035502910614014)\n","     | > loss_feat: 0.766718327999115  (0.766718327999115)\n","     | > loss_mel: 20.49451446533203  (20.49451446533203)\n","     | > loss_duration: 1.5098562240600586  (1.5098562240600586)\n","     | > loss_1: 26.770721435546875  (26.770721435546875)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.27691125869750977 \u001b[0m(+0.0008389949798583984)\n","     | > avg_loss_disc:\u001b[92m 2.9055824279785156 \u001b[0m(-0.04362821578979492)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.22639939188957214 \u001b[0m(-0.03555426001548767)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.2542871832847595 \u001b[0m(-0.062496840953826904)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.2685108780860901 \u001b[0m(+0.04394714534282684)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.17002829909324646 \u001b[0m(-0.11810380220413208)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.22337043285369873 \u001b[0m(-0.08042508363723755)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.23627707362174988 \u001b[0m(-0.05502021312713623)\n","     | > avg_loss_0:\u001b[92m 2.9055824279785156 \u001b[0m(-0.04362821578979492)\n","     | > avg_loss_gen:\u001b[92m 1.4960826635360718 \u001b[0m(-0.2903393507003784)\n","     | > avg_loss_kl:\u001b[91m 2.5035502910614014 \u001b[0m(+0.0385129451751709)\n","     | > avg_loss_feat:\u001b[91m 0.766718327999115 \u001b[0m(+0.11791962385177612)\n","     | > avg_loss_mel:\u001b[91m 20.49451446533203 \u001b[0m(+1.537994384765625)\n","     | > avg_loss_duration:\u001b[92m 1.5098562240600586 \u001b[0m(-0.01967906951904297)\n","     | > avg_loss_1:\u001b[91m 26.770721435546875 \u001b[0m(+1.3844070434570312)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 39/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:09:04) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.953375816345215  (2.953375816345215)\n","     | > loss_disc_real_0: 0.3081103563308716  (0.3081103563308716)\n","     | > loss_disc_real_1: 0.25861504673957825  (0.25861504673957825)\n","     | > loss_disc_real_2: 0.3080260455608368  (0.3080260455608368)\n","     | > loss_disc_real_3: 0.2478923797607422  (0.2478923797607422)\n","     | > loss_disc_real_4: 0.23435017466545105  (0.23435017466545105)\n","     | > loss_disc_real_5: 0.23336075246334076  (0.23336075246334076)\n","     | > loss_0: 2.953375816345215  (2.953375816345215)\n","     | > loss_gen: 1.670918345451355  (1.670918345451355)\n","     | > loss_kl: 2.282931327819824  (2.282931327819824)\n","     | > loss_feat: 0.5671153664588928  (0.5671153664588928)\n","     | > loss_mel: 19.0150146484375  (19.0150146484375)\n","     | > loss_duration: 1.5094023942947388  (1.5094023942947388)\n","     | > loss_1: 25.045381546020508  (25.045381546020508)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.321258544921875 \u001b[0m(+0.044347286224365234)\n","     | > avg_loss_disc:\u001b[91m 2.953375816345215 \u001b[0m(+0.04779338836669922)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.3081103563308716 \u001b[0m(+0.08171096444129944)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.25861504673957825 \u001b[0m(+0.004327863454818726)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.3080260455608368 \u001b[0m(+0.039515167474746704)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.2478923797607422 \u001b[0m(+0.07786408066749573)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.23435017466545105 \u001b[0m(+0.01097974181175232)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.23336075246334076 \u001b[0m(-0.0029163211584091187)\n","     | > avg_loss_0:\u001b[91m 2.953375816345215 \u001b[0m(+0.04779338836669922)\n","     | > avg_loss_gen:\u001b[91m 1.670918345451355 \u001b[0m(+0.1748356819152832)\n","     | > avg_loss_kl:\u001b[92m 2.282931327819824 \u001b[0m(-0.22061896324157715)\n","     | > avg_loss_feat:\u001b[92m 0.5671153664588928 \u001b[0m(-0.19960296154022217)\n","     | > avg_loss_mel:\u001b[92m 19.0150146484375 \u001b[0m(-1.4794998168945312)\n","     | > avg_loss_duration:\u001b[92m 1.5094023942947388 \u001b[0m(-0.0004538297653198242)\n","     | > avg_loss_1:\u001b[92m 25.045381546020508 \u001b[0m(-1.7253398895263672)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 40/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:09:40) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 22:10:08 -- STEP: 9/11 -- GLOBAL_STEP: 1000450\u001b[0m\n","     | > loss_disc: 2.9362380504608154  (2.9280508624182806)\n","     | > loss_disc_real_0: 0.23475486040115356  (0.23333397010962167)\n","     | > loss_disc_real_1: 0.23935233056545258  (0.2482453402545717)\n","     | > loss_disc_real_2: 0.22203558683395386  (0.24913395941257477)\n","     | > loss_disc_real_3: 0.21154284477233887  (0.24727513558334774)\n","     | > loss_disc_real_4: 0.22435864806175232  (0.2493748383389579)\n","     | > loss_disc_real_5: 0.23078195750713348  (0.25198884970611996)\n","     | > loss_0: 2.9362380504608154  (2.9280508624182806)\n","     | > grad_norm_0: tensor(1.6633, device='cuda:0')  (tensor(8.5005, device='cuda:0'))\n","     | > loss_gen: 1.59573233127594  (1.5969291130701702)\n","     | > loss_kl: 2.524975061416626  (2.460177183151245)\n","     | > loss_feat: 0.7710795402526855  (0.8275054825676812)\n","     | > loss_mel: 19.018447875976562  (19.535588794284397)\n","     | > loss_duration: 1.5589041709899902  (1.507649262746175)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 25.469139099121094  (25.9278498755561)\n","     | > grad_norm_1: tensor(61.3633, device='cuda:0')  (tensor(63.7461, device='cuda:0'))\n","     | > current_lr_0: 0.00019900243364508313 \n","     | > current_lr_1: 0.00019900243364508313 \n","     | > step_time: 2.8555  (2.5807578563690186)\n","     | > loader_time: 0.0193  (0.01671123504638672)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.8706915378570557  (2.8706915378570557)\n","     | > loss_disc_real_0: 0.15404176712036133  (0.15404176712036133)\n","     | > loss_disc_real_1: 0.211138054728508  (0.211138054728508)\n","     | > loss_disc_real_2: 0.2301768660545349  (0.2301768660545349)\n","     | > loss_disc_real_3: 0.22743557393550873  (0.22743557393550873)\n","     | > loss_disc_real_4: 0.19037872552871704  (0.19037872552871704)\n","     | > loss_disc_real_5: 0.21216899156570435  (0.21216899156570435)\n","     | > loss_0: 2.8706915378570557  (2.8706915378570557)\n","     | > loss_gen: 1.4079673290252686  (1.4079673290252686)\n","     | > loss_kl: 2.3697447776794434  (2.3697447776794434)\n","     | > loss_feat: 1.288819432258606  (1.288819432258606)\n","     | > loss_mel: 21.148855209350586  (21.148855209350586)\n","     | > loss_duration: 1.5287034511566162  (1.5287034511566162)\n","     | > loss_1: 27.744089126586914  (27.744089126586914)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.2835822105407715 \u001b[0m(-0.037676334381103516)\n","     | > avg_loss_disc:\u001b[92m 2.8706915378570557 \u001b[0m(-0.08268427848815918)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.15404176712036133 \u001b[0m(-0.15406858921051025)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.211138054728508 \u001b[0m(-0.04747699201107025)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2301768660545349 \u001b[0m(-0.07784917950630188)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.22743557393550873 \u001b[0m(-0.02045680582523346)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.19037872552871704 \u001b[0m(-0.04397144913673401)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.21216899156570435 \u001b[0m(-0.021191760897636414)\n","     | > avg_loss_0:\u001b[92m 2.8706915378570557 \u001b[0m(-0.08268427848815918)\n","     | > avg_loss_gen:\u001b[92m 1.4079673290252686 \u001b[0m(-0.2629510164260864)\n","     | > avg_loss_kl:\u001b[91m 2.3697447776794434 \u001b[0m(+0.08681344985961914)\n","     | > avg_loss_feat:\u001b[91m 1.288819432258606 \u001b[0m(+0.7217040657997131)\n","     | > avg_loss_mel:\u001b[91m 21.148855209350586 \u001b[0m(+2.133840560913086)\n","     | > avg_loss_duration:\u001b[91m 1.5287034511566162 \u001b[0m(+0.01930105686187744)\n","     | > avg_loss_1:\u001b[91m 27.744089126586914 \u001b[0m(+2.6987075805664062)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 41/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:10:16) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.811593532562256  (2.811593532562256)\n","     | > loss_disc_real_0: 0.2764272391796112  (0.2764272391796112)\n","     | > loss_disc_real_1: 0.2539478838443756  (0.2539478838443756)\n","     | > loss_disc_real_2: 0.2589520215988159  (0.2589520215988159)\n","     | > loss_disc_real_3: 0.23438772559165955  (0.23438772559165955)\n","     | > loss_disc_real_4: 0.1893817037343979  (0.1893817037343979)\n","     | > loss_disc_real_5: 0.2641570568084717  (0.2641570568084717)\n","     | > loss_0: 2.811593532562256  (2.811593532562256)\n","     | > loss_gen: 1.7052619457244873  (1.7052619457244873)\n","     | > loss_kl: 2.227313280105591  (2.227313280105591)\n","     | > loss_feat: 0.9799294471740723  (0.9799294471740723)\n","     | > loss_mel: 22.318695068359375  (22.318695068359375)\n","     | > loss_duration: 1.5572251081466675  (1.5572251081466675)\n","     | > loss_1: 28.788423538208008  (28.788423538208008)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.2796897888183594 \u001b[0m(-0.0038924217224121094)\n","     | > avg_loss_disc:\u001b[92m 2.811593532562256 \u001b[0m(-0.059098005294799805)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.2764272391796112 \u001b[0m(+0.12238547205924988)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.2539478838443756 \u001b[0m(+0.042809829115867615)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.2589520215988159 \u001b[0m(+0.028775155544281006)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.23438772559165955 \u001b[0m(+0.006952151656150818)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.1893817037343979 \u001b[0m(-0.0009970217943191528)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2641570568084717 \u001b[0m(+0.051988065242767334)\n","     | > avg_loss_0:\u001b[92m 2.811593532562256 \u001b[0m(-0.059098005294799805)\n","     | > avg_loss_gen:\u001b[91m 1.7052619457244873 \u001b[0m(+0.29729461669921875)\n","     | > avg_loss_kl:\u001b[92m 2.227313280105591 \u001b[0m(-0.14243149757385254)\n","     | > avg_loss_feat:\u001b[92m 0.9799294471740723 \u001b[0m(-0.3088899850845337)\n","     | > avg_loss_mel:\u001b[91m 22.318695068359375 \u001b[0m(+1.169839859008789)\n","     | > avg_loss_duration:\u001b[91m 1.5572251081466675 \u001b[0m(+0.02852165699005127)\n","     | > avg_loss_1:\u001b[91m 28.788423538208008 \u001b[0m(+1.0443344116210938)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 42/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:10:53) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9680442810058594  (2.9680442810058594)\n","     | > loss_disc_real_0: 0.1433924436569214  (0.1433924436569214)\n","     | > loss_disc_real_1: 0.17463360726833344  (0.17463360726833344)\n","     | > loss_disc_real_2: 0.21702855825424194  (0.21702855825424194)\n","     | > loss_disc_real_3: 0.218495711684227  (0.218495711684227)\n","     | > loss_disc_real_4: 0.19396644830703735  (0.19396644830703735)\n","     | > loss_disc_real_5: 0.23244646191596985  (0.23244646191596985)\n","     | > loss_0: 2.9680442810058594  (2.9680442810058594)\n","     | > loss_gen: 1.2789040803909302  (1.2789040803909302)\n","     | > loss_kl: 2.3975892066955566  (2.3975892066955566)\n","     | > loss_feat: 1.143836498260498  (1.143836498260498)\n","     | > loss_mel: 20.18553352355957  (20.18553352355957)\n","     | > loss_duration: 1.5182746648788452  (1.5182746648788452)\n","     | > loss_1: 26.524137496948242  (26.524137496948242)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.2915771007537842 \u001b[0m(+0.011887311935424805)\n","     | > avg_loss_disc:\u001b[91m 2.9680442810058594 \u001b[0m(+0.15645074844360352)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.1433924436569214 \u001b[0m(-0.13303479552268982)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.17463360726833344 \u001b[0m(-0.07931427657604218)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.21702855825424194 \u001b[0m(-0.041923463344573975)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.218495711684227 \u001b[0m(-0.015892013907432556)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.19396644830703735 \u001b[0m(+0.004584744572639465)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.23244646191596985 \u001b[0m(-0.03171059489250183)\n","     | > avg_loss_0:\u001b[91m 2.9680442810058594 \u001b[0m(+0.15645074844360352)\n","     | > avg_loss_gen:\u001b[92m 1.2789040803909302 \u001b[0m(-0.42635786533355713)\n","     | > avg_loss_kl:\u001b[91m 2.3975892066955566 \u001b[0m(+0.17027592658996582)\n","     | > avg_loss_feat:\u001b[91m 1.143836498260498 \u001b[0m(+0.16390705108642578)\n","     | > avg_loss_mel:\u001b[92m 20.18553352355957 \u001b[0m(-2.1331615447998047)\n","     | > avg_loss_duration:\u001b[92m 1.5182746648788452 \u001b[0m(-0.038950443267822266)\n","     | > avg_loss_1:\u001b[92m 26.524137496948242 \u001b[0m(-2.2642860412597656)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 43/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:11:28) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 22:11:35 -- STEP: 1/11 -- GLOBAL_STEP: 1000475\u001b[0m\n","     | > loss_disc: 2.941687822341919  (2.941687822341919)\n","     | > loss_disc_real_0: 0.22325025498867035  (0.22325025498867035)\n","     | > loss_disc_real_1: 0.2615182399749756  (0.2615182399749756)\n","     | > loss_disc_real_2: 0.24220414459705353  (0.24220414459705353)\n","     | > loss_disc_real_3: 0.21879622340202332  (0.21879622340202332)\n","     | > loss_disc_real_4: 0.27744531631469727  (0.27744531631469727)\n","     | > loss_disc_real_5: 0.27434080839157104  (0.27434080839157104)\n","     | > loss_0: 2.941687822341919  (2.941687822341919)\n","     | > grad_norm_0: tensor(1.7976, device='cuda:0')  (tensor(1.7976, device='cuda:0'))\n","     | > loss_gen: 1.6549761295318604  (1.6549761295318604)\n","     | > loss_kl: 2.2549386024475098  (2.2549386024475098)\n","     | > loss_feat: 0.828174889087677  (0.828174889087677)\n","     | > loss_mel: 19.226192474365234  (19.226192474365234)\n","     | > loss_duration: 1.4601719379425049  (1.4601719379425049)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 25.424453735351562  (25.424453735351562)\n","     | > grad_norm_1: tensor(125.9748, device='cuda:0')  (tensor(125.9748, device='cuda:0'))\n","     | > current_lr_0: 0.0001989278170603166 \n","     | > current_lr_1: 0.0001989278170603166 \n","     | > step_time: 2.2751  (2.275146961212158)\n","     | > loader_time: 0.0164  (0.01643991470336914)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9445440769195557  (2.9445440769195557)\n","     | > loss_disc_real_0: 0.21496514976024628  (0.21496514976024628)\n","     | > loss_disc_real_1: 0.21832357347011566  (0.21832357347011566)\n","     | > loss_disc_real_2: 0.29069170355796814  (0.29069170355796814)\n","     | > loss_disc_real_3: 0.2816174328327179  (0.2816174328327179)\n","     | > loss_disc_real_4: 0.2612808346748352  (0.2612808346748352)\n","     | > loss_disc_real_5: 0.2515016794204712  (0.2515016794204712)\n","     | > loss_0: 2.9445440769195557  (2.9445440769195557)\n","     | > loss_gen: 1.6035394668579102  (1.6035394668579102)\n","     | > loss_kl: 2.56213116645813  (2.56213116645813)\n","     | > loss_feat: 0.5182756185531616  (0.5182756185531616)\n","     | > loss_mel: 18.8487606048584  (18.8487606048584)\n","     | > loss_duration: 1.542540192604065  (1.542540192604065)\n","     | > loss_1: 25.075246810913086  (25.075246810913086)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.29820966720581055 \u001b[0m(+0.006632566452026367)\n","     | > avg_loss_disc:\u001b[92m 2.9445440769195557 \u001b[0m(-0.02350020408630371)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.21496514976024628 \u001b[0m(+0.07157270610332489)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.21832357347011566 \u001b[0m(+0.04368996620178223)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.29069170355796814 \u001b[0m(+0.0736631453037262)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.2816174328327179 \u001b[0m(+0.0631217211484909)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.2612808346748352 \u001b[0m(+0.06731438636779785)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2515016794204712 \u001b[0m(+0.019055217504501343)\n","     | > avg_loss_0:\u001b[92m 2.9445440769195557 \u001b[0m(-0.02350020408630371)\n","     | > avg_loss_gen:\u001b[91m 1.6035394668579102 \u001b[0m(+0.32463538646698)\n","     | > avg_loss_kl:\u001b[91m 2.56213116645813 \u001b[0m(+0.16454195976257324)\n","     | > avg_loss_feat:\u001b[92m 0.5182756185531616 \u001b[0m(-0.6255608797073364)\n","     | > avg_loss_mel:\u001b[92m 18.8487606048584 \u001b[0m(-1.3367729187011719)\n","     | > avg_loss_duration:\u001b[91m 1.542540192604065 \u001b[0m(+0.024265527725219727)\n","     | > avg_loss_1:\u001b[92m 25.075246810913086 \u001b[0m(-1.4488906860351562)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 44/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:12:05) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.893850803375244  (2.893850803375244)\n","     | > loss_disc_real_0: 0.22675758600234985  (0.22675758600234985)\n","     | > loss_disc_real_1: 0.23831361532211304  (0.23831361532211304)\n","     | > loss_disc_real_2: 0.2647506892681122  (0.2647506892681122)\n","     | > loss_disc_real_3: 0.2141135334968567  (0.2141135334968567)\n","     | > loss_disc_real_4: 0.2362142950296402  (0.2362142950296402)\n","     | > loss_disc_real_5: 0.2247578352689743  (0.2247578352689743)\n","     | > loss_0: 2.893850803375244  (2.893850803375244)\n","     | > loss_gen: 1.5327500104904175  (1.5327500104904175)\n","     | > loss_kl: 2.598464250564575  (2.598464250564575)\n","     | > loss_feat: 0.6897335648536682  (0.6897335648536682)\n","     | > loss_mel: 19.43561553955078  (19.43561553955078)\n","     | > loss_duration: 1.537217378616333  (1.537217378616333)\n","     | > loss_1: 25.793781280517578  (25.793781280517578)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.29337120056152344 \u001b[0m(-0.004838466644287109)\n","     | > avg_loss_disc:\u001b[92m 2.893850803375244 \u001b[0m(-0.05069327354431152)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.22675758600234985 \u001b[0m(+0.011792436242103577)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.23831361532211304 \u001b[0m(+0.019990041851997375)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.2647506892681122 \u001b[0m(-0.025941014289855957)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.2141135334968567 \u001b[0m(-0.0675038993358612)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.2362142950296402 \u001b[0m(-0.025066539645195007)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.2247578352689743 \u001b[0m(-0.026743844151496887)\n","     | > avg_loss_0:\u001b[92m 2.893850803375244 \u001b[0m(-0.05069327354431152)\n","     | > avg_loss_gen:\u001b[92m 1.5327500104904175 \u001b[0m(-0.07078945636749268)\n","     | > avg_loss_kl:\u001b[91m 2.598464250564575 \u001b[0m(+0.03633308410644531)\n","     | > avg_loss_feat:\u001b[91m 0.6897335648536682 \u001b[0m(+0.1714579463005066)\n","     | > avg_loss_mel:\u001b[91m 19.43561553955078 \u001b[0m(+0.5868549346923828)\n","     | > avg_loss_duration:\u001b[92m 1.537217378616333 \u001b[0m(-0.005322813987731934)\n","     | > avg_loss_1:\u001b[91m 25.793781280517578 \u001b[0m(+0.7185344696044922)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 45/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:12:41) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 22:12:54 -- STEP: 4/11 -- GLOBAL_STEP: 1000500\u001b[0m\n","     | > loss_disc: 2.90297269821167  (2.9075305461883545)\n","     | > loss_disc_real_0: 0.3078432083129883  (0.24424893409013748)\n","     | > loss_disc_real_1: 0.2456101030111313  (0.24778848141431808)\n","     | > loss_disc_real_2: 0.2750941216945648  (0.25412480905652046)\n","     | > loss_disc_real_3: 0.25688669085502625  (0.2464529573917389)\n","     | > loss_disc_real_4: 0.25304195284843445  (0.24717522040009499)\n","     | > loss_disc_real_5: 0.2471601963043213  (0.24726620689034462)\n","     | > loss_0: 2.90297269821167  (2.9075305461883545)\n","     | > grad_norm_0: tensor(16.4263, device='cuda:0')  (tensor(9.0490, device='cuda:0'))\n","     | > loss_gen: 1.5549687147140503  (1.6524129211902618)\n","     | > loss_kl: 2.4303677082061768  (2.378179371356964)\n","     | > loss_feat: 0.9830048084259033  (0.8878410458564758)\n","     | > loss_mel: 18.455854415893555  (19.12064027786255)\n","     | > loss_duration: 1.4133822917938232  (1.4372180998325348)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 24.837575912475586  (25.4762921333313)\n","     | > grad_norm_1: tensor(83.6520, device='cuda:0')  (tensor(100.3537, device='cuda:0'))\n","     | > current_lr_0: 0.00019887808821429862 \n","     | > current_lr_1: 0.00019887808821429862 \n","     | > step_time: 2.2585  (2.2522332072257996)\n","     | > loader_time: 0.0119  (0.012465476989746094)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.9158849716186523  (2.9158849716186523)\n","     | > loss_disc_real_0: 0.22851350903511047  (0.22851350903511047)\n","     | > loss_disc_real_1: 0.2322104424238205  (0.2322104424238205)\n","     | > loss_disc_real_2: 0.256068617105484  (0.256068617105484)\n","     | > loss_disc_real_3: 0.2440624237060547  (0.2440624237060547)\n","     | > loss_disc_real_4: 0.2856384217739105  (0.2856384217739105)\n","     | > loss_disc_real_5: 0.2508305609226227  (0.2508305609226227)\n","     | > loss_0: 2.9158849716186523  (2.9158849716186523)\n","     | > loss_gen: 1.6148326396942139  (1.6148326396942139)\n","     | > loss_kl: 2.705035924911499  (2.705035924911499)\n","     | > loss_feat: 0.9163942337036133  (0.9163942337036133)\n","     | > loss_mel: 20.255756378173828  (20.255756378173828)\n","     | > loss_duration: 1.5187873840332031  (1.5187873840332031)\n","     | > loss_1: 27.010805130004883  (27.010805130004883)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.28635382652282715 \u001b[0m(-0.007017374038696289)\n","     | > avg_loss_disc:\u001b[91m 2.9158849716186523 \u001b[0m(+0.022034168243408203)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.22851350903511047 \u001b[0m(+0.0017559230327606201)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.2322104424238205 \u001b[0m(-0.0061031728982925415)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.256068617105484 \u001b[0m(-0.008682072162628174)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.2440624237060547 \u001b[0m(+0.029948890209197998)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.2856384217739105 \u001b[0m(+0.049424126744270325)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2508305609226227 \u001b[0m(+0.026072725653648376)\n","     | > avg_loss_0:\u001b[91m 2.9158849716186523 \u001b[0m(+0.022034168243408203)\n","     | > avg_loss_gen:\u001b[91m 1.6148326396942139 \u001b[0m(+0.08208262920379639)\n","     | > avg_loss_kl:\u001b[91m 2.705035924911499 \u001b[0m(+0.10657167434692383)\n","     | > avg_loss_feat:\u001b[91m 0.9163942337036133 \u001b[0m(+0.22666066884994507)\n","     | > avg_loss_mel:\u001b[91m 20.255756378173828 \u001b[0m(+0.8201408386230469)\n","     | > avg_loss_duration:\u001b[92m 1.5187873840332031 \u001b[0m(-0.018429994583129883)\n","     | > avg_loss_1:\u001b[91m 27.010805130004883 \u001b[0m(+1.2170238494873047)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 46/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:13:18) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.749082565307617  (2.749082565307617)\n","     | > loss_disc_real_0: 0.16068699955940247  (0.16068699955940247)\n","     | > loss_disc_real_1: 0.2373971939086914  (0.2373971939086914)\n","     | > loss_disc_real_2: 0.24348942935466766  (0.24348942935466766)\n","     | > loss_disc_real_3: 0.24934348464012146  (0.24934348464012146)\n","     | > loss_disc_real_4: 0.2677389085292816  (0.2677389085292816)\n","     | > loss_disc_real_5: 0.2537563741207123  (0.2537563741207123)\n","     | > loss_0: 2.749082565307617  (2.749082565307617)\n","     | > loss_gen: 1.7123454809188843  (1.7123454809188843)\n","     | > loss_kl: 2.2541823387145996  (2.2541823387145996)\n","     | > loss_feat: 1.1386280059814453  (1.1386280059814453)\n","     | > loss_mel: 19.253372192382812  (19.253372192382812)\n","     | > loss_duration: 1.5226554870605469  (1.5226554870605469)\n","     | > loss_1: 25.881183624267578  (25.881183624267578)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.29354429244995117 \u001b[0m(+0.0071904659271240234)\n","     | > avg_loss_disc:\u001b[92m 2.749082565307617 \u001b[0m(-0.16680240631103516)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.16068699955940247 \u001b[0m(-0.06782650947570801)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.2373971939086914 \u001b[0m(+0.005186751484870911)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.24348942935466766 \u001b[0m(-0.012579187750816345)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.24934348464012146 \u001b[0m(+0.0052810609340667725)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.2677389085292816 \u001b[0m(-0.017899513244628906)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2537563741207123 \u001b[0m(+0.0029258131980895996)\n","     | > avg_loss_0:\u001b[92m 2.749082565307617 \u001b[0m(-0.16680240631103516)\n","     | > avg_loss_gen:\u001b[91m 1.7123454809188843 \u001b[0m(+0.09751284122467041)\n","     | > avg_loss_kl:\u001b[92m 2.2541823387145996 \u001b[0m(-0.4508535861968994)\n","     | > avg_loss_feat:\u001b[91m 1.1386280059814453 \u001b[0m(+0.22223377227783203)\n","     | > avg_loss_mel:\u001b[92m 19.253372192382812 \u001b[0m(-1.0023841857910156)\n","     | > avg_loss_duration:\u001b[91m 1.5226554870605469 \u001b[0m(+0.00386810302734375)\n","     | > avg_loss_1:\u001b[92m 25.881183624267578 \u001b[0m(-1.1296215057373047)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 47/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:13:54) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 22:14:16 -- STEP: 7/11 -- GLOBAL_STEP: 1000525\u001b[0m\n","     | > loss_disc: 2.925136089324951  (2.9005325521741594)\n","     | > loss_disc_real_0: 0.24283716082572937  (0.22825202345848083)\n","     | > loss_disc_real_1: 0.281160444021225  (0.24665809742041997)\n","     | > loss_disc_real_2: 0.24992112815380096  (0.25173682400158476)\n","     | > loss_disc_real_3: 0.2522388994693756  (0.2485127363886152)\n","     | > loss_disc_real_4: 0.28793659806251526  (0.2522968522139958)\n","     | > loss_disc_real_5: 0.23537996411323547  (0.2450111678668431)\n","     | > loss_0: 2.925136089324951  (2.9005325521741594)\n","     | > grad_norm_0: tensor(4.9693, device='cuda:0')  (tensor(8.6381, device='cuda:0'))\n","     | > loss_gen: 1.4361727237701416  (1.6244501726967948)\n","     | > loss_kl: 2.3043134212493896  (2.3986759526388988)\n","     | > loss_feat: 0.9758095741271973  (0.9666292837687901)\n","     | > loss_mel: 19.367145538330078  (19.184444427490234)\n","     | > loss_duration: 1.5502880811691284  (1.4861985445022583)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 25.63372802734375  (25.660397938319615)\n","     | > grad_norm_1: tensor(58.5498, device='cuda:0')  (tensor(75.6957, device='cuda:0'))\n","     | > current_lr_0: 0.00019882837179971516 \n","     | > current_lr_1: 0.00019882837179971516 \n","     | > step_time: 2.8124  (2.495438746043614)\n","     | > loader_time: 0.0193  (0.01630054201398577)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.900740146636963  (2.900740146636963)\n","     | > loss_disc_real_0: 0.16303333640098572  (0.16303333640098572)\n","     | > loss_disc_real_1: 0.28557682037353516  (0.28557682037353516)\n","     | > loss_disc_real_2: 0.24273481965065002  (0.24273481965065002)\n","     | > loss_disc_real_3: 0.25052115321159363  (0.25052115321159363)\n","     | > loss_disc_real_4: 0.3121476173400879  (0.3121476173400879)\n","     | > loss_disc_real_5: 0.2660349905490875  (0.2660349905490875)\n","     | > loss_0: 2.900740146636963  (2.900740146636963)\n","     | > loss_gen: 1.6469101905822754  (1.6469101905822754)\n","     | > loss_kl: 2.565465211868286  (2.565465211868286)\n","     | > loss_feat: 0.7763609886169434  (0.7763609886169434)\n","     | > loss_mel: 19.073396682739258  (19.073396682739258)\n","     | > loss_duration: 1.5150096416473389  (1.5150096416473389)\n","     | > loss_1: 25.57714080810547  (25.57714080810547)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.28702831268310547 \u001b[0m(-0.006515979766845703)\n","     | > avg_loss_disc:\u001b[91m 2.900740146636963 \u001b[0m(+0.1516575813293457)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.16303333640098572 \u001b[0m(+0.002346336841583252)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.28557682037353516 \u001b[0m(+0.04817962646484375)\n","     | > avg_loss_disc_real_2:\u001b[92m 0.24273481965065002 \u001b[0m(-0.0007546097040176392)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.25052115321159363 \u001b[0m(+0.001177668571472168)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.3121476173400879 \u001b[0m(+0.044408708810806274)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.2660349905490875 \u001b[0m(+0.012278616428375244)\n","     | > avg_loss_0:\u001b[91m 2.900740146636963 \u001b[0m(+0.1516575813293457)\n","     | > avg_loss_gen:\u001b[92m 1.6469101905822754 \u001b[0m(-0.06543529033660889)\n","     | > avg_loss_kl:\u001b[91m 2.565465211868286 \u001b[0m(+0.3112828731536865)\n","     | > avg_loss_feat:\u001b[92m 0.7763609886169434 \u001b[0m(-0.36226701736450195)\n","     | > avg_loss_mel:\u001b[92m 19.073396682739258 \u001b[0m(-0.1799755096435547)\n","     | > avg_loss_duration:\u001b[92m 1.5150096416473389 \u001b[0m(-0.007645845413208008)\n","     | > avg_loss_1:\u001b[92m 25.57714080810547 \u001b[0m(-0.3040428161621094)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 48/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:14:30) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.915459632873535  (2.915459632873535)\n","     | > loss_disc_real_0: 0.2646695077419281  (0.2646695077419281)\n","     | > loss_disc_real_1: 0.28635352849960327  (0.28635352849960327)\n","     | > loss_disc_real_2: 0.25925302505493164  (0.25925302505493164)\n","     | > loss_disc_real_3: 0.3027876615524292  (0.3027876615524292)\n","     | > loss_disc_real_4: 0.3173648715019226  (0.3173648715019226)\n","     | > loss_disc_real_5: 0.31851285696029663  (0.31851285696029663)\n","     | > loss_0: 2.915459632873535  (2.915459632873535)\n","     | > loss_gen: 1.9279940128326416  (1.9279940128326416)\n","     | > loss_kl: 2.1148970127105713  (2.1148970127105713)\n","     | > loss_feat: 0.856626570224762  (0.856626570224762)\n","     | > loss_mel: 20.21913719177246  (20.21913719177246)\n","     | > loss_duration: 1.5135136842727661  (1.5135136842727661)\n","     | > loss_1: 26.63216781616211  (26.63216781616211)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[91m 0.2931082248687744 \u001b[0m(+0.006079912185668945)\n","     | > avg_loss_disc:\u001b[91m 2.915459632873535 \u001b[0m(+0.014719486236572266)\n","     | > avg_loss_disc_real_0:\u001b[91m 0.2646695077419281 \u001b[0m(+0.10163617134094238)\n","     | > avg_loss_disc_real_1:\u001b[91m 0.28635352849960327 \u001b[0m(+0.0007767081260681152)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.25925302505493164 \u001b[0m(+0.016518205404281616)\n","     | > avg_loss_disc_real_3:\u001b[91m 0.3027876615524292 \u001b[0m(+0.05226650834083557)\n","     | > avg_loss_disc_real_4:\u001b[91m 0.3173648715019226 \u001b[0m(+0.005217254161834717)\n","     | > avg_loss_disc_real_5:\u001b[91m 0.31851285696029663 \u001b[0m(+0.052477866411209106)\n","     | > avg_loss_0:\u001b[91m 2.915459632873535 \u001b[0m(+0.014719486236572266)\n","     | > avg_loss_gen:\u001b[91m 1.9279940128326416 \u001b[0m(+0.2810838222503662)\n","     | > avg_loss_kl:\u001b[92m 2.1148970127105713 \u001b[0m(-0.45056819915771484)\n","     | > avg_loss_feat:\u001b[91m 0.856626570224762 \u001b[0m(+0.0802655816078186)\n","     | > avg_loss_mel:\u001b[91m 20.21913719177246 \u001b[0m(+1.1457405090332031)\n","     | > avg_loss_duration:\u001b[92m 1.5135136842727661 \u001b[0m(-0.001495957374572754)\n","     | > avg_loss_1:\u001b[91m 26.63216781616211 \u001b[0m(+1.0550270080566406)\n","\n","\n","\u001b[4m\u001b[1m > EPOCH: 49/50\u001b[0m\n"," --> tts_train_dir/vits_ljspeech_finetune-June-21-2024_09+44PM-0000000\n","\n","\u001b[1m > TRAINING (2024-06-21 22:15:06) \u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m   --> TIME: 2024-06-21 22:15:36 -- STEP: 10/11 -- GLOBAL_STEP: 1000550\u001b[0m\n","     | > loss_disc: 2.8978729248046875  (2.901462507247925)\n","     | > loss_disc_real_0: 0.25610893964767456  (0.22764645367860795)\n","     | > loss_disc_real_1: 0.23149965703487396  (0.2459159627556801)\n","     | > loss_disc_real_2: 0.2186523824930191  (0.24464178830385208)\n","     | > loss_disc_real_3: 0.23276552557945251  (0.24311942458152772)\n","     | > loss_disc_real_4: 0.20496951043605804  (0.2417787343263626)\n","     | > loss_disc_real_5: 0.23974119126796722  (0.24506862610578536)\n","     | > loss_0: 2.8978729248046875  (2.901462507247925)\n","     | > grad_norm_0: tensor(8.5199, device='cuda:0')  (tensor(14.1735, device='cuda:0'))\n","     | > loss_gen: 1.6351901292800903  (1.6166274428367615)\n","     | > loss_kl: 2.2370336055755615  (2.3003985404968263)\n","     | > loss_feat: 0.8607609272003174  (0.8972192645072937)\n","     | > loss_mel: 18.87346649169922  (19.062764358520507)\n","     | > loss_duration: 1.5351322889328003  (1.5005584955215454)\n","     | > amp_scaler: 512.0  (512.0)\n","     | > loss_1: 25.141582489013672  (25.37756805419922)\n","     | > grad_norm_1: tensor(115.1825, device='cuda:0')  (tensor(69.8423, device='cuda:0'))\n","     | > current_lr_0: 0.00019877866781345852 \n","     | > current_lr_1: 0.00019877866781345852 \n","     | > step_time: 1.7055  (2.4957547426223754)\n","     | > loader_time: 0.0091  (0.015634751319885253)\n","\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","\u001b[1m > EVALUATION \u001b[0m\n","\n","\u001b[1m   --> STEP: 0\u001b[0m\n","     | > loss_disc: 2.887284994125366  (2.887284994125366)\n","     | > loss_disc_real_0: 0.22588634490966797  (0.22588634490966797)\n","     | > loss_disc_real_1: 0.2592792809009552  (0.2592792809009552)\n","     | > loss_disc_real_2: 0.3070552349090576  (0.3070552349090576)\n","     | > loss_disc_real_3: 0.24967201054096222  (0.24967201054096222)\n","     | > loss_disc_real_4: 0.2611086964607239  (0.2611086964607239)\n","     | > loss_disc_real_5: 0.23603639006614685  (0.23603639006614685)\n","     | > loss_0: 2.887284994125366  (2.887284994125366)\n","     | > loss_gen: 1.6858785152435303  (1.6858785152435303)\n","     | > loss_kl: 2.139411211013794  (2.139411211013794)\n","     | > loss_feat: 0.9319995641708374  (0.9319995641708374)\n","     | > loss_mel: 19.579309463500977  (19.579309463500977)\n","     | > loss_duration: 1.5070953369140625  (1.5070953369140625)\n","     | > loss_1: 25.84369468688965  (25.84369468688965)\n","\n"]},{"name":"stdout","output_type":"stream","text":[" | > Synthesizing test sentences.\n"]},{"name":"stderr","output_type":"stream","text":["\n","  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n","     | > avg_loader_time:\u001b[92m 0.2888026237487793 \u001b[0m(-0.004305601119995117)\n","     | > avg_loss_disc:\u001b[92m 2.887284994125366 \u001b[0m(-0.028174638748168945)\n","     | > avg_loss_disc_real_0:\u001b[92m 0.22588634490966797 \u001b[0m(-0.03878316283226013)\n","     | > avg_loss_disc_real_1:\u001b[92m 0.2592792809009552 \u001b[0m(-0.02707424759864807)\n","     | > avg_loss_disc_real_2:\u001b[91m 0.3070552349090576 \u001b[0m(+0.04780220985412598)\n","     | > avg_loss_disc_real_3:\u001b[92m 0.24967201054096222 \u001b[0m(-0.05311565101146698)\n","     | > avg_loss_disc_real_4:\u001b[92m 0.2611086964607239 \u001b[0m(-0.05625617504119873)\n","     | > avg_loss_disc_real_5:\u001b[92m 0.23603639006614685 \u001b[0m(-0.08247646689414978)\n","     | > avg_loss_0:\u001b[92m 2.887284994125366 \u001b[0m(-0.028174638748168945)\n","     | > avg_loss_gen:\u001b[92m 1.6858785152435303 \u001b[0m(-0.24211549758911133)\n","     | > avg_loss_kl:\u001b[91m 2.139411211013794 \u001b[0m(+0.024514198303222656)\n","     | > avg_loss_feat:\u001b[91m 0.9319995641708374 \u001b[0m(+0.07537299394607544)\n","     | > avg_loss_mel:\u001b[92m 19.579309463500977 \u001b[0m(-0.6398277282714844)\n","     | > avg_loss_duration:\u001b[92m 1.5070953369140625 \u001b[0m(-0.006418347358703613)\n","     | > avg_loss_1:\u001b[92m 25.84369468688965 \u001b[0m(-0.7884731292724609)\n","\n"]}],"source":["# start the training process\n","trainer.fit()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5228410,"sourceId":8715008,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
